{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "plt.ion()   # interactive mode\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "The problem we're going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
    "There are 75 validation images for each class. Usually, this is a very\n",
    "small dataset to generalize upon, if trained from scratch. Since we\n",
    "are using transfer learning, we should be able to generalize reasonably\n",
    "well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n",
    "\n",
    "\n",
    "Its a cat bees dataset, constructing a transformation pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Training Function , the scheduler is lr=0.001, decays by 0.1 every 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_weight_initialization(model,pretrained_model,alpha=1):\n",
    "    \n",
    "    model_state_dict=model.state_dict()\n",
    "    pretrained_model_state_dict=pretrained_model.state_dict()\n",
    "    for layer in model_state_dict.keys():\n",
    "        \n",
    "        if layer=='fc.weight' or layer=='fc.bias':\n",
    "            print(\"skipping\")\n",
    "        else:\n",
    "            model_state_dict[layer]=(model_state_dict[layer]+alpha*pretrained_model_state_dict[layer])/(1+alpha)\n",
    "        \n",
    "    #reload the state_dict of model\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, pretrained_model, criterion, optimizer, scheduler, num_epochs=50,alpha=1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                print('model is training, goign to refresh its resnet memory')\n",
    "                print('alpha is',alpha)\n",
    "                model=cyclic_weight_initialization(model,pretrained_model,alpha)\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #print(inputs.size())\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            print('{} Rajat Best_Acc: {:.4f} Epoch_Acc: {:.4f}'.format(\n",
    "                phase, best_acc, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                \n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            #collect losses\n",
    "            if phase=='train':\n",
    "                train_losses.append(epoch_loss)\n",
    "            if phase=='val':\n",
    "                val_losses.append(epoch_loss)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,train_losses,val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the model predictions\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Generic function to display predictions for a few images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            print(\"modi\",inputs.size())\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def plot_losses(train_loss,val_loss):\n",
    "    df = pd.DataFrame(list(zip([i for i in range(0,len(train_losses))],train_loss,val_loss)), \n",
    "               columns =['epoch', 'train_loss','val_loss']) \n",
    "    list_data=[df.train_loss,df.val_loss]\n",
    "    plots=sns.lineplot(data=list_data)\n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_output(model,train_loss,val_loss,experiment_name):\n",
    "    model_dump_path=experiment_name+'.pt'\n",
    "    torch.save(model.state_dict(),model_dump_path)\n",
    "    csv_dump_path=experiment_name+'.csv'\n",
    "    df = pd.DataFrame(list(zip(train_loss,val_loss)), \n",
    "           columns =[ 'train_loss','val_loss'])\n",
    "    df.to_csv(csv_dump_path)\n",
    "    list_data=[df.train_loss,df.val_loss]\n",
    "    plot_dump_path=experiment_name+'.png'\n",
    "    plots=sns.lineplot(data=list_data)\n",
    "    fig=plots.get_figure()\n",
    "    fig.savefig(plot_dump_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E1. Train whole model, LR scheduler, 100 epochs, resnet18 \n",
    "----------------------------------------------------------------------------\n",
    "Resnet18, train the whole model\n",
    "\n",
    "Best val Acc: 0.960784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5127 Acc: 0.7090\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.7090\n",
      "val Loss: 0.2231 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3606 Acc: 0.8443\n",
      "train Rajat Best_Acc: 0.9281 Epoch_Acc: 0.8443\n",
      "val Loss: 0.2014 Acc: 0.9020\n",
      "val Rajat Best_Acc: 0.9281 Epoch_Acc: 0.9020\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2961 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9281 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1486 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9281 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2745 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3173 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1678 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2847 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bbc43c4551ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m---> 17\u001b[0;31m                        num_epochs=500)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdump_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'alpha-1-cyclicweight_resnet18_lrscheduler_wholenetwork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-52fbfc778c57>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, pretrained_model, criterion, optimizer, scheduler, num_epochs, alpha)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;31m#print(inputs.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    739\u001b[0m         raise ValueError(\n\u001b[1;32m    740\u001b[0m             \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n\u001b[0;32m--> 741\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpuenv/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "pretrained_model=models.resnet18(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet18_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5597 Acc: 0.6844\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6844\n",
      "val Loss: 0.1940 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2785 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1749 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2946 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1685 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3431 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1433 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1930 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1501 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1761 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2135 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1637 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2595 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1677 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2632 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1632 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2752 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1689 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2736 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1705 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2652 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1724 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2799 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1761 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2114 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2847 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1748 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2740 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1725 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1685 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3010 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2340 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2921 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1670 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2612 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1880 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1678 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1603 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2688 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1669 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2342 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1754 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2775 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1736 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2314 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1716 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1729 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2454 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2771 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1671 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1711 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3166 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1660 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2772 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1802 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2171 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.2009 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2831 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1602 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2498 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1756 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1999 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1706 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2630 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2783 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1629 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2403 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1663 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1722 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2667 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1763 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2462 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1715 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2567 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1644 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2402 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1784 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1732 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2924 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1681 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2707 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1651 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2701 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1754 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1679 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2282 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1793 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2712 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1639 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1615 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1670 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2484 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2764 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1727 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1752 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2617 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2131 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1654 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1677 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3351 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1715 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1849 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2428 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1723 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2562 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1730 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2735 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1934 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2281 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2267 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1694 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2563 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1663 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2460 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1775 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2085 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1712 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2670 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1670 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2192 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1685 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2445 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1643 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1981 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1675 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2252 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1655 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2515 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1629 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2668 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1701 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2778 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1823 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2229 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1739 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2243 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1668 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2464 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1668 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2756 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2548 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1600 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2126 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1746 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2827 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1664 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1834 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2046 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1703 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2870 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2954 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2445 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1709 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2320 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2905 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1763 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2163 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1751 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2218 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1686 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1812 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2760 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1803 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2476 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1737 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1697 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2326 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1652 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3040 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1756 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2937 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1616 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1694 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2543 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1625 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1656 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2144 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1714 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2509 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1690 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1999 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1741 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1681 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2855 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1730 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2398 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1812 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3315 Acc: 0.8361\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8361\n",
      "val Loss: 0.1642 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2491 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1822 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2717 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1742 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2817 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1607 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2545 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1791 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2667 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1681 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2208 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1596 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2762 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1620 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1672 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2868 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1783 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1706 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2776 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1729 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2583 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1668 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2212 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1743 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2067 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1965 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2847 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1730 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2115 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1833 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3252 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1664 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2945 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1677 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3001 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1909 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1871 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2053 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1711 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2683 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2675 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1682 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2392 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1803 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2609 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1605 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1723 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2455 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1815 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2789 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2325 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1724 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2205 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1743 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2215 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1679 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2769 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1675 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1597 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1765 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2589 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1783 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1793 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2701 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1785 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2396 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1751 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2888 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2273 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1825 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3283 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1771 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2178 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1618 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2786 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1654 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1613 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2872 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2425 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1803 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1799 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1622 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2957 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2643 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1591 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1640 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1993 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2426 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1677 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1780 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2194 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1627 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2079 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2511 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1648 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2436 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1743 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1946 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1648 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2701 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2698 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1733 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1877 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1921 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1681 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2647 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2233 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1686 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2053 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1723 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2544 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1688 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1628 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2249 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1934 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2549 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1736 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1669 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2495 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1639 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2746 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1658 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2557 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1775 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2815 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1646 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2397 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1807 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2499 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1622 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2783 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1641 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2903 Acc: 0.8443\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8443\n",
      "val Loss: 0.1704 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1847 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1762 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2718 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1752 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1644 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1859 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1793 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1810 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1637 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2871 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1988 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1798 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2695 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1716 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2175 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1688 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2546 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1707 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2613 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1828 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1665 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2907 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2265 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1702 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2646 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1636 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2707 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1715 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2698 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1612 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2761 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2928 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1802 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2921 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1773 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2508 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1696 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2554 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1732 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1683 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2648 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1744 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2934 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1698 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1698 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2348 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1715 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2667 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1661 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1665 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2732 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1797 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2534 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1651 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2413 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1630 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1731 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2996 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2428 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2566 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1853 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2721 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1661 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2734 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1594 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3040 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1689 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2588 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1651 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2523 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1909 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2503 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1657 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1891 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1574 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2450 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1682 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1626 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2524 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1776 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2230 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1728 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2454 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1656 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2650 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1685 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2447 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1677 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2871 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1645 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1699 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2351 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1691 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2489 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2264 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1690 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2358 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3462 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1740 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2487 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1599 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3174 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1538 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1743 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2418 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1623 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3047 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1696 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1640 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2849 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2582 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1808 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3211 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1896 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2474 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1684 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1757 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1717 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1758 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1756 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2693 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1696 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2597 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1647 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2691 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1647 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2012 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1751 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2013 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1683 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2292 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1746 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2150 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1684 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1688 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2569 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1699 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1645 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2222 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1610 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2710 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1739 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2515 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1604 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1709 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1707 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1842 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2224 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1626 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1951 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1615 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1628 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2477 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1790 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2708 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1617 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1637 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1757 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1645 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1844 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2528 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1630 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1667 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2406 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1814 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2746 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1652 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2615 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2501 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1696 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1822 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1747 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2293 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1709 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2166 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1785 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1833 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2956 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2549 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1665 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2816 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1659 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2653 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1683 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2963 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1623 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1768 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2369 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1794 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1877 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1615 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3002 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1716 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2735 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2641 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2629 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1707 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2658 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1651 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2867 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1679 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2615 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1602 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2038 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1670 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2961 Acc: 0.8484\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8484\n",
      "val Loss: 0.1705 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2936 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1795 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2585 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1755 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2695 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1692 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1684 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2015 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1663 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1731 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1690 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2123 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1673 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2451 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1753 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2716 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2275 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1683 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2459 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1676 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2329 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1713 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2249 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1714 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1721 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1693 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2556 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1717 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1695 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2747 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1709 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1796 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1759 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2617 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1677 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2368 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1843 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3011 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1793 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1780 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1699 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1753 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1636 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2945 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1831 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2578 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1684 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2128 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1641 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2326 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1684 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2443 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1604 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2688 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1687 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1579 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1690 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2243 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1698 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2359 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1708 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2364 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1772 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2490 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1732 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2509 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1744 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2541 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1738 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2565 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1657 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2819 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1734 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2090 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1838 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1650 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1707 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1772 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2421 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2400 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1677 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2361 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1646 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3580 Acc: 0.8238\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8238\n",
      "val Loss: 0.1667 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1710 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1692 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2416 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1711 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2599 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1744 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2398 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3030 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1751 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2548 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1897 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1732 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2565 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1673 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1614 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2855 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1672 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2466 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1789 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1755 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2548 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1929 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1789 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2385 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1782 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3304 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2091 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1874 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2786 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1856 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1732 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2465 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1613 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2230 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1659 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1818 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.2069 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2169 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1782 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1615 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2575 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1571 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2640 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1685 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2489 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1657 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1753 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2886 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1703 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1700 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1682 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2830 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1687 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2329 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1606 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2775 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1703 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1815 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1743 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2468 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1735 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2455 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1653 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2673 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1930 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2994 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2872 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1676 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2532 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1654 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1890 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1656 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1696 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2630 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1670 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2854 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1766 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2885 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1744 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2144 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2217 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1796 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2992 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2679 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1585 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2785 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1606 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1764 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1765 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2332 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1809 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2729 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1708 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1671 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2316 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1714 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2416 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1650 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1620 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1657 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2835 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1857 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1914 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2348 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1784 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2036 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1707 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1672 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2258 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1620 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2620 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1688 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2359 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1657 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1655 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1779 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2545 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1682 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2910 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1624 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1808 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1709 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1838 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1767 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2377 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1794 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1675 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2298 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2498 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1767 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2199 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1679 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2619 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1748 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2592 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1744 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1685 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2854 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1783 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1971 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1768 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2601 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1618 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1650 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1640 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2266 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2041 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1697 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2857 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2571 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1651 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2753 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1668 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2071 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1705 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1651 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3011 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1681 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2647 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1637 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2294 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1705 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2267 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1717 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 13m 19s\n",
      "Best val Acc: 0.973856\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "pretrained_model=models.resnet18(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet18_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
    "minute.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.4662 Acc: 0.7459\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.7459\n",
      "val Loss: 0.2515 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2523 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9085 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1936 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9085 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1428 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9216 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2999 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1219 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2810 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1130 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1624 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1178 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2403 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1244 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1141 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2589 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1204 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1235 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1286 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3112 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1217 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1361 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1988 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1381 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1318 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1323 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2617 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1369 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2801 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2371 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2496 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2366 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2465 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1379 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1350 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1331 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2452 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1319 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1268 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3039 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1280 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2464 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1350 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1364 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1349 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1307 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2510 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1343 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3021 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1296 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2373 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1378 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1416 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1382 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1428 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1474 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2099 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1290 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1317 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1352 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2513 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1381 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2515 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1387 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1354 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2411 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1326 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2310 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1312 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1323 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2139 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1375 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2044 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1278 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2434 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1362 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1300 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1361 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2019 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1331 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2728 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1271 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2433 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1319 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1817 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1339 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2346 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1356 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1454 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2320 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1384 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1673 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1329 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1902 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1407 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2442 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1300 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2368 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2738 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2035 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1340 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2324 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1304 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1307 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1615 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1433 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1347 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1350 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1381 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2031 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1368 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2342 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1356 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2640 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1281 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1327 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1847 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2619 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1339 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1351 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1356 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2050 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1330 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2808 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1406 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2242 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1315 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2691 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1298 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2484 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1313 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2111 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1472 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2397 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1970 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2295 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1315 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2129 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2273 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1271 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2310 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1297 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1404 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2116 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1330 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1304 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1449 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1675 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1388 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2217 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1361 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2715 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2393 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1372 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2414 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1466 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2705 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1406 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2536 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1295 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1347 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1329 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1344 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2031 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2247 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2008 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1726 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1517 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2352 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1287 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1966 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1415 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1391 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2307 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1335 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2167 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1337 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2621 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1360 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1336 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2894 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1297 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1871 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1254 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2200 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2632 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2523 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2049 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1278 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3011 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1290 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2366 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1379 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2740 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1320 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2594 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1355 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1337 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2019 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1371 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2073 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1242 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1432 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1879 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1275 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1340 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2710 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1469 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3179 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1370 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2971 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1360 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2873 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1392 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2299 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1397 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1380 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2575 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1346 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1353 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2238 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2561 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1377 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2629 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1395 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2312 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1293 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2148 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1357 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2620 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1300 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3248 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1447 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2179 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1325 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2257 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2670 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1316 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2239 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1353 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1541 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2496 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1384 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1383 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2088 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1387 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1319 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2427 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1329 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2658 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1336 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2325 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1394 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1957 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1281 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1325 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2419 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1262 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1322 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1293 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2658 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1375 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2254 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1302 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2809 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1257 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1940 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1366 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2072 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1334 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1395 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1312 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1440 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2584 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1478 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2386 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2670 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1318 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1375 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2528 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1382 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2212 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2184 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2468 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1341 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2794 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1263 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1885 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1366 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2598 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2124 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1297 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2464 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1305 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2619 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1348 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1417 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2832 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2385 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1405 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2375 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1300 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1277 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1364 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2029 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1411 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1351 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2386 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1350 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2141 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2431 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1314 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1987 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1315 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2411 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1312 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2277 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1405 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2274 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2536 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1343 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2196 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2538 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1311 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2220 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1349 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2411 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1296 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2462 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1309 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2300 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1325 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2450 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1357 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2438 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1282 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1350 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2374 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2335 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2090 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1340 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2162 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1247 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2344 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1383 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1324 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2346 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1352 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2659 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1287 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2081 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1333 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1303 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2822 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1375 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1952 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1392 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1351 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2056 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1308 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2924 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1276 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2781 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1337 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2449 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1358 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2509 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1306 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2313 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1284 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1339 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1914 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1363 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1372 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2471 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2432 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1404 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2593 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1445 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2808 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1307 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1928 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1336 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1362 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2640 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1355 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2162 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1306 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2555 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2827 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1370 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1314 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2228 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1425 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2603 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2429 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1373 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2295 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1625 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1321 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2076 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1300 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1339 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1269 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2760 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2593 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2271 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2768 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2119 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1371 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2801 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1405 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1870 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1345 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2357 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1307 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2156 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1269 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2723 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1307 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1362 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2386 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1308 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2687 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1395 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2490 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2744 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1422 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2193 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1325 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1321 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2034 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1306 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2442 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1332 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1390 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1392 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2555 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1535 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1315 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1824 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1351 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2904 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1373 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2173 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2072 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1327 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1285 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1277 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1302 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1495 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2383 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1400 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1353 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1262 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1266 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1393 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1462 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2283 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1321 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1262 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2517 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1313 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1373 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2610 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1419 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2308 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2461 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1354 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1318 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2817 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1383 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1950 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1358 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1369 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2826 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2304 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2825 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2585 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1872 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2862 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1340 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2203 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2632 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1341 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1381 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2593 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1460 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2097 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1311 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2854 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2196 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1424 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1487 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2654 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1361 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1432 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2081 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1314 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2181 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1345 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2675 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1442 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2300 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1363 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1316 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1372 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1345 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1318 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1387 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1388 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2079 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1334 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1297 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1317 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2763 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1405 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2467 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1387 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1345 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1347 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2642 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1354 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2823 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1489 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1277 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2208 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1276 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1305 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2003 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1249 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1327 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2184 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1302 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2113 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1317 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2711 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1388 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2436 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1339 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2703 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1469 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3015 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1327 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2910 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1344 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2380 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1417 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1346 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1382 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2479 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2424 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2695 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1403 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1419 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2263 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1309 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1392 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2183 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2673 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1361 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2621 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1396 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2103 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1253 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2480 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1320 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1303 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2424 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1988 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1366 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2133 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2333 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1277 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2277 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1355 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1910 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1315 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2371 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1389 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2370 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1406 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2325 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1294 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1269 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1391 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2576 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1465 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2183 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1370 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2540 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1376 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2441 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1459 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2211 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1324 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1460 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2447 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1364 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1385 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1926 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1434 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2812 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1347 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1394 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2159 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1371 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2702 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1408 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2601 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1431 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2551 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1367 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2644 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1395 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1300 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1311 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2867 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2077 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1381 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2060 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1350 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2272 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1369 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2198 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1398 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2711 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1296 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1809 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1281 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1343 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2648 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1261 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1398 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1963 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1360 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1334 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2272 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2716 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1389 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1392 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2434 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1301 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1404 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2078 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1415 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2271 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1310 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1357 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2773 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1279 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2504 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1431 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1407 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1267 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2766 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1263 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2649 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1333 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1423 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1368 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2682 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1291 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2113 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1403 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2328 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1324 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2005 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1338 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1391 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2433 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1343 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1827 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1343 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1291 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2753 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2770 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1290 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1303 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1395 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1284 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2628 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1457 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2517 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1311 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2233 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1375 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2408 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1360 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2437 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1289 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1337 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2478 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1363 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2644 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1288 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2149 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1301 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2546 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1314 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1357 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1253 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2393 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1370 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1402 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2613 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1306 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2047 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1399 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2425 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2689 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1327 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3147 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1295 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 16m 37s\n",
      "Best val Acc: 0.973856\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "pretrained_model=models.resnet34(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet34_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5950 Acc: 0.6516\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6516\n",
      "val Loss: 0.2180 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3332 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8525\n",
      "val Loss: 0.2323 Acc: 0.8824\n",
      "val Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8824\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3136 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1263 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9216 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2099 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1317 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3190 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2829 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1340 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1994 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1881 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1505 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1516 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2147 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1553 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2272 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2044 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1544 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2218 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1521 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1432 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2114 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1435 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2674 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1561 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2093 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1710 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2249 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1555 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2274 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1492 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2058 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1569 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2460 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1458 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2487 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1434 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1710 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1425 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2224 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1528 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1679 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1497 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1543 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2371 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1547 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1518 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1552 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2761 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1483 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1634 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2061 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1471 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1443 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2439 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1578 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1605 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2143 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1647 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2178 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1452 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1943 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1464 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2356 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1592 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2133 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1751 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1902 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1508 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1447 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1571 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2102 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1593 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1650 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1473 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1585 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2305 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1668 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1786 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2153 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1593 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2726 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1437 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2416 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1578 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2193 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1471 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2259 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1482 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1559 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1883 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1538 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2346 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1696 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2223 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1422 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2474 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1588 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1518 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1476 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2236 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2708 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1576 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2654 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1579 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2567 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1572 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2308 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1505 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1843 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1578 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1564 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1509 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1589 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1532 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1425 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2833 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1443 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1570 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2320 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1894 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1925 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1646 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2194 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1446 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1776 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1688 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1441 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1606 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1993 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1654 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2393 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1539 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1611 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2075 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1506 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2729 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1492 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1862 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1452 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1749 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1545 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1550 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1481 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1935 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1472 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2075 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1488 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1895 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1475 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1436 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1848 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1576 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1498 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1492 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2542 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1510 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1654 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1891 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1509 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1960 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1526 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1483 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2335 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1630 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1680 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1528 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2441 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1594 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2039 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1542 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1977 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1421 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2559 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1547 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1836 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2084 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1416 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1595 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2314 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1427 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1919 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1435 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1467 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2913 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1558 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1524 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2071 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1567 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2256 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1555 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2237 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1582 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1795 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1541 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1732 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1489 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1439 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1578 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1831 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1523 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1582 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1481 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2404 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2344 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1833 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1489 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1606 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1427 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1812 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1526 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1985 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1612 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1531 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2413 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1546 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2576 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1488 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2275 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1563 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1920 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2712 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1474 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2133 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1565 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1562 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1705 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1536 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1609 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1479 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2724 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1520 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2006 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1594 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1708 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1563 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2359 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1444 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2598 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1538 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2048 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2422 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1667 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1582 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1489 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2282 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1490 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1489 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2175 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1448 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1784 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1474 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1391 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1671 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1465 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1733 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1559 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2326 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1531 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2450 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1951 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1676 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2115 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2236 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1494 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2399 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1588 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2290 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1509 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1977 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2331 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1525 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2460 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1561 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1534 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1698 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2826 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1586 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2858 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1572 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2020 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1585 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1565 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1576 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2274 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1528 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2529 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1551 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2281 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1459 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2976 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2473 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1530 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2417 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1526 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2080 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1510 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2131 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1520 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1523 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2111 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1483 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2113 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1398 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2242 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1514 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2528 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1686 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2710 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1595 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1518 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2222 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1640 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2343 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1532 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2198 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1406 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1917 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2687 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1510 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2417 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1505 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1511 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1492 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1613 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2208 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1581 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1958 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1563 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2300 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1584 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1825 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2112 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1828 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2432 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1443 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1842 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1436 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1586 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2427 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1598 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2178 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2047 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1468 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1467 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2329 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1458 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1561 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2034 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1532 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1424 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1607 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2691 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1640 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2084 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1660 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2045 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2305 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1446 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2153 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1534 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1469 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1726 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1471 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2395 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1520 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1530 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1916 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1500 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1477 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2483 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1622 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1918 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1529 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2404 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1663 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1563 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1571 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2126 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1584 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1554 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2119 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1538 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1797 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1559 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1710 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1478 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1552 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1456 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1639 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1763 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2238 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1472 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1551 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1858 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2112 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1480 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2331 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1544 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1644 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2102 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1442 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1493 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1810 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1662 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2423 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1558 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2613 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1519 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2110 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1524 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2055 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1552 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1567 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2894 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1531 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2297 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1503 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1643 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1938 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1425 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1864 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1576 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1792 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1599 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1569 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1517 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1806 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1539 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2634 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1601 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1790 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1557 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2364 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1655 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2181 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1554 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1477 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2875 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1556 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1521 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2439 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1618 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2161 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1540 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1928 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1468 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1465 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1469 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2548 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1494 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2340 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1528 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1862 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1960 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1410 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2604 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1490 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2243 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1607 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2321 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1935 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1495 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2673 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1611 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1422 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1507 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1728 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1483 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1450 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1883 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1652 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2147 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1503 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1562 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2446 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1454 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2137 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1474 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2138 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2010 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1577 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1580 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1424 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2123 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1589 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2560 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1647 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1512 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2211 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1631 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2215 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1518 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2627 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1402 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1916 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2473 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1531 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3027 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1464 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1453 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2293 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1620 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1536 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1502 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2407 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1598 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1992 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1668 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1429 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1511 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1605 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1946 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1587 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2063 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1584 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2381 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1645 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2257 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1514 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1512 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1623 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1766 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1527 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2254 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2085 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1452 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1983 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1560 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1525 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1778 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1626 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2030 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1516 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1719 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1501 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1647 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1445 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1950 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1613 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1467 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2576 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1596 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1539 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2070 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1544 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1553 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1544 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1480 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2090 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1535 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1980 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1562 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1412 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2333 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1610 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1730 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1577 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2009 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2351 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1637 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1510 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2236 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1451 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1897 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1595 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2585 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1460 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2577 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1561 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2157 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1622 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1539 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1641 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1587 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1665 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2242 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1447 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2545 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1441 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2944 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1457 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1497 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2654 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1548 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1963 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1592 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2090 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1554 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1458 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1770 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1556 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1730 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1517 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1462 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1905 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1541 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2538 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1563 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1812 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1413 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1509 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1898 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1693 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1524 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1624 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1491 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1463 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1914 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1416 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2599 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1492 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2104 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1932 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1482 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1550 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2296 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1383 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1460 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2410 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1702 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1905 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1456 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1831 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1479 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2277 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1488 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2517 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1652 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1763 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1439 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2763 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1590 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1865 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1501 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2053 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1760 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1477 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1971 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1485 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1824 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1525 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1420 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1637 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1599 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1960 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1591 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1767 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1546 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1892 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2335 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1509 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1532 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2162 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2115 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1601 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2199 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1550 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2419 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1482 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2331 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1495 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1740 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1414 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2034 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1459 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1623 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1537 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1510 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1575 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2690 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2250 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1481 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2120 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1580 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1532 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1475 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1664 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1568 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2015 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2111 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1615 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2488 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2062 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1525 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1527 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1587 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1411 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1534 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1536 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2558 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1657 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2112 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1538 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1518 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2030 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1553 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1503 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1727 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1509 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1455 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1529 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1532 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2056 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1574 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1509 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 21m 19s\n",
      "Best val Acc: 0.960784\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xUVfr48c+ZmVSSQAoESCAJEEroEJoUO4IoYC+gomvvurqWXV11dd1196f7dUVd17p2REFUpKgg0nsLLQFCEmoKkEbqnN8fJ4GUSTIpkzCT5/165ZXMnTsz52Zmnnvuc5rSWiOEEML9WVq6AEIIIZqGBHQhhPAQEtCFEMJDSEAXQggPIQFdCCE8hK2lXjgsLExHR0e31MsLIYRb2rBhQ4bWur2j+1osoEdHR7N+/fqWenkhhHBLSqkDNd0nKRchhPAQEtCFEMJDSEAXQggP4VQOXSk1Afg/wAq8q7X+m4N9rgWeAzSwRWt9YxOWUwjhBoqLi0lLS6OgoKCli+L2fH19iYyMxMvLy+nH1BnQlVJWYCZwMZAGrFNKzdNa76iwTyzwFDBaa31cKdWh3qUXQri9tLQ0AgMDiY6ORinV0sVxW1prMjMzSUtLIyYmxunHOZNyGQ4kaa33aa2LgC+AKVX2uQOYqbU+XlaYY06XQAjhMQoKCggNDZVg3khKKUJDQ+t9peNMQI8AUivcTivbVlFPoKdSaoVSanVZisZRIe9USq1XSq1PT0+vV0GFEO5BgnnTaMj/0ZmA7uhZq865awNigfOAG4B3lVLtqj1I63e01vFa6/j27R32i6/TuuQs/rFwF3a7TPsrhBAVORPQ04AuFW5HAocc7POt1rpYa70f2I0J8E1uS+oJZi7ZS25RiSueXggh3JYzAX0dEKuUilFKeQPXA/Oq7DMXOB9AKRWGScHsa8qClgv0Ne24uQUS0IUQlZ04cYI333yz3o+79NJLOXHiRL0fN2PGDGbPnl3vx7lKnQFda10C3A8sBHYCs7TWCUqpF5RSk8t2WwhkKqV2AEuAx7XWma4ocICP6cKTIwFdCFFFTQG9tLS01sfNnz+fdu2qZYndjlP90LXW84H5VbY9W+FvDTxa9uNSAeU19MJiV7+UEKIRnv8ugR2Hspv0OeM6B/Hny/vWeP+TTz7J3r17GTRoEF5eXgQEBNCpUyc2b97Mjh07mDp1KqmpqRQUFPDQQw9x5513AmfmlsrNzWXixImMGTOGlStXEhERwbfffoufn1+dZfv555957LHHKCkpYdiwYbz11lv4+Pjw5JNPMm/ePGw2G+PHj+ef//wnX331Fc8//zxWq5W2bduybNmyJvn/tNjkXA1VnnKRGroQoqq//e1vbN++nc2bN7N06VImTZrE9u3bT/flfv/99wkJCeHUqVMMGzaMq666itDQ0ErPkZiYyOeff85///tfrr32Wr7++mumT59e6+sWFBQwY8YMfv75Z3r27MnNN9/MW2+9xc0338ycOXPYtWsXSqnTaZ0XXniBhQsXEhER0aBUT03cL6D7SEAXwh3UVpNuLsOHD680MOf1119nzpw5AKSmppKYmFgtoMfExDBo0CAAhg4dSnJycp2vs3v3bmJiYujZsycAt9xyCzNnzuT+++/H19eX22+/nUmTJnHZZZcBMHr0aGbMmMG1117LlVde2RSHCrjhXC6BviaHnlsoAV0IUbs2bdqc/nvp0qX89NNPrFq1ii1btjB48GCHA3d8fHxO/221WikpqTvWmKxzdTabjbVr13LVVVcxd+5cJkwwQ3TefvttXnzxRVJTUxk0aBCZmU3T5Oh2NfSA0ykXyaELISoLDAwkJyfH4X0nT54kODgYf39/du3axerVq5vsdXv37k1ycjJJSUn06NGDjz/+mHPPPZfc3Fzy8/O59NJLGTlyJD169ABg7969jBgxghEjRvDdd9+Rmppa7UqhIdwuoPt7WVFKui0KIaoLDQ1l9OjR9OvXDz8/P8LDw0/fN2HCBN5++20GDBhAr169GDlyZJO9rq+vLx988AHXXHPN6UbRu+++m6ysLKZMmUJBQQFaa1577TUAHn/8cRITE9Fac+GFFzJw4MAmKYeq6VLB1eLj43VDVyzq/9xCrh4aeVbk6IQQZ+zcuZM+ffq0dDE8hqP/p1Jqg9Y63tH+bpdDB9MwKo2iQghRmdulXMA0jErKRQjRXO677z5WrFhRadtDDz3Erbfe2kIlcswtA3qAr40cGVgkhGgmM2fObOkiOMUtUy4BPjapoQshRBVuGdADfW3kSD90IYSoxH0DutTQhRCiEjcN6NIoKoQQVbllQA/wsXGquJTiUntLF0UI4cYCAgJqvC85OZl+/fo1Y2kaz20DOkCe5NGFEOI0t+y2WHEK3Xb+3i1cGiFEjT6Y5Hj7rT+Y3z8+CUe2Vb9/wsvQaQBs+hQ2f1b9cTV44okniIqK4t577wXgueeeQynFsmXLOH78OMXFxbz44otMmTKlXodRUFDAPffcw/r167HZbLz66qucf/75JCQkcOutt1JUVITdbufrr7+mc+fOXHvttaSlpVFaWsozzzzDddddV6/Xayi3D+hCCFHu+uuv5+GHHz4d0GfNmsWCBQt45JFHCAoKIiMjg5EjRzJ58mSUUk4/b3k/9G3btrFr1y7Gjx/Pnj17ePvtt3nooYeYNm0aRUVFlJaWMn/+fDp37swPP5iTz8mTJ5v+QGvgpgFdptAVwi3UUaNm4t9qv3/wNPPjpMGDB3Ps2DEOHTpEeno6wcHBdOrUiUceeYRly5ZhsVg4ePAgR48epWPHjk4/7/Lly3nggQcAM7NiVFQUe/bsYdSoUbz00kukpaVx5ZVXEhsbS//+/Xnsscd44oknuOyyyxg7dqzTr9NYbp1Dlyl0hRBVXX311cyePZsvv/yS66+/nk8//ZT09HQ2bNjA5s2bCQ8PdzgPem1qmsTwxhtvZN68efj5+XHJJZfwyy+/0LNnTzZs2ED//v156qmneOGFF5risJziljX0M+uKSg1dCFHZ9ddfzx133EFGRga//vors2bNokOHDnh5ebFkyRIOHDhQ7+ccN24cn376KRdccAF79uwhJSWFXr16sW/fPrp168aDDz7Ivn372Lp1K7179yYkJITp06cTEBDAhx9+2PQHWQO3DOiSQxdC1KRv377k5OQQERFBp06dmDZtGpdffjnx8fEMGjSI3r171/s57733Xu6++2769++PzWbjww8/xMfHhy+//JJPPvkELy8vOnbsyLPPPsu6det4/PHHsVgseHl58dZbb7ngKB1zy/nQTxWV0ufZBTwxoTf3nNe9iUsmhGgomQ+9abWK+dB9vSzYLIpcmXFRCCFOc8uUi1LKTKErKRchRCNt27aNm266qdI2Hx8f1qxZ00Ilaji3DOggU+gKcbbSWterj3dL69+/P5s3b27pYlTTkHS4W6ZcwPRFlyl0hTi7+Pr6kpmZ2aBgJM7QWpOZmYmvr2+9Hue2NXSzrqjk0IU4m0RGRpKWlkZ6enpLF8Xt+fr6EhkZWa/HuG9A97VxNKd+gwOEEK7l5eVFTExMSxej1XLblIs0igohRGXuG9ClUVQIISpx24Ae6OslNXQhhKjAjQO6jaJSO4UlpS1dFCGEOCu4dUAHJO0ihBBlnAroSqkJSqndSqkkpdSTDu6foZRKV0ptLvu5vemLWtmZKXQloAshBDjRbVEpZQVmAhcDacA6pdQ8rfWOKrt+qbW+3wVldKg8oMsUukIIYThTQx8OJGmt92mti4AvgPotyOcC5asWZcvgIiGEAJwL6BFAaoXbaWXbqrpKKbVVKTVbKdXF0RMppe5USq1XSq1v7EgyyaELIURlzgR0R7PsVJ2o4TsgWms9APgJ+MjRE2mt39Fax2ut49u3b1+/klYRKKsWCSFEJc4E9DSgYo07EjhUcQetdabWurDs5n+BoU1TvJpJo6gQQlTmTEBfB8QqpWKUUt7A9cC8ijsopTpVuDkZ2Nl0RXRM1hUVQojK6uzlorUuUUrdDywErMD7WusEpdQLwHqt9TzgQaXUZKAEyAJmuLDMAPjYrHjbLNIoKoQQZZyabVFrPR+YX2XbsxX+fgp4qmmLVrdAmc9FCCFOc9uRomAaRiXlIoQQhlsHdJlCVwghznDvgC4pFyGEOM2tA3qgr5c0igohRBn3Dug+kkMXQohy7h3QpVFUCCFOc+uAXt4oqnXVmQiEEKL1ce+A7uNFqV1TUGxv6aIIIUSLc+uAXj5BV440jAohhIcEdMmjCyGEZwR06YsuhBBuHtADfMyqRTJaVAgh3D6gl0+hKzl0IYRw64BennLJlhq6EEJ4RkCXHLoQQrh5QD+TcpGALoQQbh3QbVYLfl5W6YcuhBC4eUAHM/xfauhCCOEBAT3Q1yaNokIIgScEdFnkQgghAE8I6L5eknIRQgg8IKAH+NikUVQIIfCAgB7oKykXIYQADwjo5YtcCCFEa+f2AT3Qx0ZuUQl2u6xaJIRo3dw/oPt6oTXkF5e2dFGEEKJFuX1AD5BVi4QQAvCAgC4TdAkhhOH2Ab18gi4ZLSqEaO3cPqCfrqHL4CIhRCvnAQHdLEMnKRchRGvn9gG9POUijaJCiNbO7QO6pFyEEMJwKqArpSYopXYrpZKUUk/Wst/VSimtlIpvuiLWro23NIoKIQQ4EdCVUlZgJjARiANuUErFOdgvEHgQWNPUhayNxaIIkCl0hRDCqRr6cCBJa71Pa10EfAFMcbDfX4BXgIImLJ9TAn1lxkUhhHAmoEcAqRVup5VtO00pNRjoorX+vrYnUkrdqZRar5Ran56eXu/C1iTAR5ahE0IIZwK6crDt9ExYSikL8Brw+7qeSGv9jtY6Xmsd3759e+dLWYdAWVdUCCGcCuhpQJcKtyOBQxVuBwL9gKVKqWRgJDCvORtGA3y9pFFUCNHqORPQ1wGxSqkYpZQ3cD0wr/xOrfVJrXWY1jpaax0NrAYma63Xu6TEDph1RSWHLoRo3eoM6FrrEuB+YCGwE5iltU5QSr2glJrs6gI6I1AWuRBCCGzO7KS1ng/Mr7Lt2Rr2Pa/xxaofaRQVQggPGCkKZj6X/KJSSmXVIiFEK+YRAT1A5kQXQgjPCOiB5RN0FUrDqBCi9fKMgH56GTqpoQshWi+PCOgBMuOiEEJ4RkCXRS6EEMJDAvqZdUUlhy6EaL08IqDLIhdCCOFhAV0aRYUQrZlHBHQ/LytWi5IcuhCiVfOIgK6UkuH/QohWzyMCOpiGUWkUFUK0Zh4T0AN9ZV1RIUTr5lEBXRpFhRCtmccEdMmhCyFaO48J6IG+XhLQhRCtmscE9ABfGznSKCqEaMU8JqAH+kgOXQjRunlOQPe1UVhip6jE3tJFEUKIFuExAb18gi7JowshWiuPCegyha4QorXzmIBevsiFjBYVQrRWHhPQ2/mZGvrOw9ktXBIhhGgZHhPQh0QFM7BLO174bgcpmfktXRwhhGh2HhPQvawW3rhhMErBfZ9tpLCktKWLJIQQzcpjAjpAlxB//nnNQLYdPMnL83e1dHGEEKJZeVRABxjftyO/GxPDhyuT+XHb4ZYujhBCNBuPC+gAT0zozcAu7fjD7K0NyqdrrWWAkhDC7XhkQPe2NS6f/srC3Vz6+m+U2rWLSiiEEE3PIwM6VM6n//WHnfV67JbUEyQdy2Xp7mMuKp0QQjQ9jw3ocCaf/tGqA/UKzilZJk3z6ZoUVxVNCCGanEcHdDD5dF8vC8sTM5zav6jEzqETpwj0sbFk9zFSs6RPuxDCPXh8QPe2WYgKaUOyk42jh06cwq7hjnHdUMAX66SWLoRwDx4f0AGiw/xJzsxzat8DZTXyETEhXNA7nC/XpUqPFyGEW3AqoCulJiildiulkpRSTzq4/26l1Dal1Gal1HKlVFzTF7XhokPbkJKZ71SvlfL8eVRoG6aN7EpGbhGLdhxxdRGFEKLR6gzoSikrMBOYCMQBNzgI2J9prftrrQcBrwCvNnlJGyEqtA1FpXYOnzxV574pmXl42yx0CPTh3Nj2RAb78cnqA81QSiGEaBxnaujDgSSt9T6tdRHwBTCl4g5a64pTHLYBzqoO3NFh/gAccCKPfiAzn64h/lgsCotFceOIrqzel0XSsVxXF1MIIRrFmYAeAaRWuJ1Wtq0SpdR9Sqm9mBr6g46eSCl1p1JqvVJqfXp6ekPK2yDRoW0AnMqjp2SZgF7u2vgueFkVn66RWroQ4uzmTEBXDrZVq4FrrWdqrbsDTwB/cvREWut3tNbxWuv49u3b16+kjdAxyBcfm4XkjNoDuta6WkAPC/BhQr9OfL0hjVNFMoOjEOLs5UxATwO6VLgdCRyqZf8vgKmNKVRTs1gUUaH+dXZdzMwrIr+olKhQ/0rbp43oSnZBCd9tre2whRCiZTkT0NcBsUqpGKWUN3A9MK/iDkqp2Ao3JwGJTVfEphEV2oYDdaRcynPsFWvoYLow9ugQICNHhRBntToDuta6BLgfWAjsBGZprROUUi8opSaX7Xa/UipBKbUZeBS4xWUlbqCYsDYcyMzHXkvXxdTTXRYrB3SlFNNGdGVL6gm2Hzzp0nIKIURDOdUPXWs9X2vdU2vdXWv9Utm2Z7XW88r+fkhr3VdrPUhrfb7WOsGVhW6IqFB/CkvsHMkuqHGf8hp6ZLB/tfuuHBKJr5dFGkeFEGetVjFSFCr0dKmlYTQlK5+OQb74elmr3dfWz4vJAzszd9MhcgtLXFZOIYRoqNYT0MPKuy7W3DCakpVXLX9e0VVDIjlVXMqvu5uvy6UQQjir1QT0TkG+eNsstTaMpmTl0zW05oA+NCqYYH8vFstUAEKIs1CrCegWi6JriD/7a0i5FBSXcjS7sNYaus1q4YLe4fyy6xjFpTJhl2h+Wmuuf2cVb/+6t6WLIs5CrSagg8mj1zT8v6YeLlWN7xtOdkEJ6/ZnNXn5hKjL/ow8Vu/LYu6mgy1dFHEWamUB3Uyj66jrYk190KsaGxuGj83Coh1HXVJGIWqztKz9ZteRHI7l1NxjS7ROrSqgR4W1obDEzlEHX4TyaXPrCuj+3jbGxoaxeMdRtD6r5iBzGbtds3pfZqs53rPZ0j3p+HubXlir9ma2cGnE2aZVBfSY010Xq6ddUrLyCfCxEdLGu87nuTgunIMnTrHjcHad+3qCBQlHuP6d1azaJwGkJZ0qKmX1vkyuG9aFtn5eTi+rKFqPVhXQy/PjjmZdPJCZR5cQf5RyNBdZZRf2CUcpWNxK0i6/JZrL/BVJEkBa0qp9GRSV2LmgdwfO6R7KiqQMuWoSlbSqgN65nR/eVovDgJ6SlU9UHemWcmEBPgztGtxqAvqKJFMzl0v8lrV0dzp+XlaGx4QwukcYh04W1NhrS7ROrSqgWy2KLiF+HKiScrHbNanHT9XaB72qi+PCSTiUTdpx5xafdlepWfmkZOUTFuDD1rST5Mko2RahtWbp7nRG9wjFx2ZlTI8wQK6aRGWtKqCD6bpYtYZ+NKeAohJ7nQ2iFV0cFw7ATx5eSy8PGPee150Su2b9geMtXKLWaV9GHilZ+ZzbqwNg0ocR7fxYLgFdVND6AnqYCegVc4/OdlmsqFv7AHp0CGDxTg8P6Hsz6RDow/XDzcpNknZpGeXdFc/raRaGUUoxpkcYK/dmOrX4uWgdWl9AD/WnoNjO0ezC09tSnBxUVNXFceGs2ZfFyVPFTVrGs4XdrlmZlMHoHmH4e9sYGNlOerq0kKW7j9GjQwBdKlQ6RseGkVNQwjaZ0lmUaXUBPcrB+qIpmflYLYrO7fzq9VwXx4VTYtcs3X2sSct4tth9NIfMvCLO6R4KwKjuoWw/eJKcgpY9gZ3IL2Ll3gw+Xn2gVQyuyS8qYc2+rNO183Ll74vk0UU5W0sXoLnFlM26eCAzj5HdzBciJSufzu188bLW7/w2KLId7QN9WJRwlCmDqq2b7fbKA8Xosga4Ud1C+fcvSaxLzuKC3uHNVo7fEtNZl3ycHYey2Xk4m4MnTp2+L+14Pk9N7NNsZWkJq/ZmUlRq57yy/Hm5sAAf+nQKYnliBved36OFSifOJq2uht6prS9eVsX+Cj1dDmTlExXSpt7PZbEoLuoTztLdxygs8bwFpFfuzSQmrM3pK5chUcF4Wy3NmkdfsvsYN723ljd+SSQ5M4+hUcE8ObE3/7ttOL3CA0k46PmDu5buNqNDh8UEV7tvTI9QNhw43mwLmK9Pzjo975E4+7S6gG6zWugS7F9pGt3UrPxKucn6GB8XTl5Rqcc1FhaX2lmzL5PRPUJPb/P1sjK4a/Pm0WevTyOkjTdbn7uEnx49l9dvGMzd53ZnXM/2DOzSlh2Hsz16cI3WmiW7j3FO9zB8bNUXXhndI4yiUjvrD7h2sriC4lKembudq99exdNztrn0tUTDtbqADqanS/mAjJyCYrLyiurdIFpuVPdQ/L2tHjfIaEvqCfKKShndPazS9lHdQ0k4lM3JfNfn0U+eKmbxzqNMHtiZAJ/q2cG+nduSlVdU67KC7m5veh5px09xXq/2Du8fHhOCl1W5tPti4tEcps5cwcerDxAV6s+a/VkUFHveFaknaJUBPSrUnwOZ+WitnZ6Uqya+XlbO7dmen3YerXUBanezIikTpUwAr2hkt1C0hjX7XV9Ln7/tMEUldq4c4rh9om/nIAB2HDp70i6/JaY36Rwr5Q3uNQV0f28bg7sGu6RhVGvN52tTuPyN5aTnFPLBrcN47vK+FJXYWZ8s4xHORq0yoEeHtuFUcSnpOYWkNKAPelUXx4VzNLuQrR7UfWzF3gz6dg6inX/lycoGd22Hj83C6n2unw/+m41p9OgQQP+Itg7v790pCKUg4SwJ6EdOFnDXxxt4ZNZmSppoAZRf96TTo0OAw4XLy43pEUbCoWyy8oqa5DXBXB3d/9kmnvpmG/FRIfz48FjO79WB4TEh2CyuvSKoyZ/mbuO5eWfd+vNnFc8J6KdOwKqZUFz35Xf5+qL7y0bfAfUa9l/VBb07YLUoj1maLr+ohE0px0/3bqnIx2ZlaFSwy/PoBzLzWJd8nCuHRNQ4YVqAj43o0DZnTQ39pfk7yS8yFYXfmqCWnldouiueX0PtvNzoHmFo3XRz7SQezeGyf//GwoQjPDHBNEB3CPQFoI2PjSEuuiKoTXpOIZ+tSeHDlckel95sSp4T0HOPwsKnYd+SOneNLgveBzLzOZCVT7C/F0G+Xg1+6Xb+3oyICWFRgmd80Nbuz6K4VFfLn5cb1S2UnYezOd6ENcKq5mw6iFIwtY7uoHGdgkg43PJXRiv3ZvDdlkPce153gv29mL0xrdHPWVN3xaoGRrYlwMfWJLXmNfsyueqtlZwqsjPr7lHcc153LJbKJ9QxsWFsP3TSpe9/Vd9vPYRdQ2SwH3+cs61Z2nDckfsH9Nx0yNwL/mXBJ2t/nQ+JaOeHzaJIzswjJTO/UemWcuPjwkk8lsu+9NxGP5cj+UUlzTZd6sq9mXhbLQyLDnF4f3levT559PyiEraknmD2hrQ6a3daa77ZeJBzuofWOdgrrnMQqVmnWnS0bnGpnT9/m0CXED8evDCWyQM7s3jH0UYHnaV7juHvbSU+unp3xYpsVgsju4U2utb8/dZD3PTeWsICfZhz7zkM6er4dcuvCFY2Y8+uuZsOEtcpiLenDyUrr4gXvt/RbK/tTtw7oOccgQ8nwafXgG9b8GkLWfvqfJjNaqFLiFmOLiUrn66h9e+DXtXFfTsCrpkj/cjJAq55exXT3l3DV+sbX/Ory4qkDAZ3bYefd/VucgADItvh52Wt9RJ/zb5MXv5xJ7d9uI4xf/+FuGcXMmXmCh77agu3frCOXUdqTpNsOHCclKx8rhgcWWdZ48oaRnc2YLGRohI7Ow9n883GND5efaDBPTc+WplM4rFcnr2sL75eVq4aGklRiZ3vtx1q0PPBmdkVa+quWNWYHqGkZOWfbhOq72u9+9s+7v9sEwMi2/LNPefU2o13YGRbApvoisAZ+9Jz2ZJ2kqmDO9Mvoi33nNedrzem8cuu2r9r29JO8tIPO5qtj/7ZwH1Hip5Mg48uh5yjMG0WWG0QEg3H666hg+npknQsl4MnTjF5YOdGFyeinR/9IoJYvOMod53bvc79N6Uc5+SpYs7t2b7WRTW2HzzJ7z5aR25BCb3CA/nLDzs4t1d7woN863yNohI7Xlbl1KId5bLyikg4lM3vL+5Z4z7eNgvx0TXn0X/cdpj7PtuI1aLoFhbAoC7tuDa+Cz3DA+jczo/bPlzHI19u4dv7RuNtq16n+HrjQfy8rEzo17HO8lbs6VI+8rcmR04W8O3mg+w6ksPOw9kkHculpELPpFnrUnlr+pBaGyCrOpZdwL9+SuT8Xu25qI9JjfSPaEvP8ABmb0hj2ogop5+rXGZuIU/P2Uba8VM8eGGsU48ZE1s2ne7eDLqGdnX6tUrtmhd/2MEHK5KZ2K8jr103CF+v2k8gNquFkd0bf0XgrLmbD6EUTB5o0m/3X9CDhQlHePqb7Sx6NMRhuvS7LYd47KstFJbYaefv3WpG0rpnDf14MnwwEfIy4KY5ED3GbA/p5lQNHUxPlz1Hcym16yZJuQBc3KcjG1KOk55TWOt+RSV27vjfBmZ8sI5r3l7FhhqmpF2YcIRr3l6FVSlm33MOb00fQlGJnWfmbq8z9ZJ2PJ9xryxh2rtrOJHvfK6zvNZ9joMG0YpGdgtlz9FcMnIrH+uve9J58ItNDOrSjs3PjmfhI+N448YhPHhhLBP6dWJAZDtevnIAOw9n8+9fEqs9b0FxKT9sPcSEfh0d9j2vqkOgL2EBPk71dHnxhx28/OMuVu3NpFNbX+4Y143XbxjM4kfG8Z+bhpKckcfl/15+eoUmZ/x1/k6KSuz8+fK+p0+cSimuGhLJppQT7K1nCm5RwhHGv7aMJbvS+eOlfbh6SN1XKQDd2wcQHuRTr3mFCopLuf+zjXywIpnbRscw88YhdQbzcmN6hDX4iqA+tNZ8u/kgo7qF0rGtqcT42Kz885qBpOcW8tL3Oyvtb7drXl20mwc+N1cbY2PDeGvpXjJza/9ONtSs9alc8eaKs6Zh3v0CekE2fDDJ/L75W+g64sx9kcMgNKY6QJEAACAASURBVBacyDNHV+jV0pgeLhWN7xuO1vBzHVPqzt92mIzcQm4ZFcWBrHyuemsld328/vSXX2vNf37dy92fbKBnx0Dm3j+aPp2C6NY+gIcv6smiHUf5cXvNPWpyCor53YfryS0sYX3ycabOXOF0YFmxN4MAHxsDIx13FSxXnkdfXaGWvnZ/Fnd9vJ7YDoF8cOtw2tQQkC+OC+fqoZG8uXQvm1NPVLrvl13HyC4oqbHvuSN9OwfVub5rSamdZXvSuWZoJKufvpAPbh3OExN6M3lgZ2LDA7mkb0fmPTCGDoG+3Pz+WmYuSapzXMGafZnM3XyIu87tdrrnVLkrBkdgUabrpTOyC4p57Kst3PnxBjq29eW7B8Zwx7hu1Roka6KUYvLAzixMOMrMJUl17p9fVMLvPlrHj9uP8KdJfXj28jinXwvOzO/TkLRLSamdbWkn+WZjWp1TZmxOPcGBzHymDq78eRgQ2Y47x3Xjy/WpLNtjTsD5RSXc99lGXv8liWuGRvLJ7SP48+V9OVVcyr9/qft/Ul/Hsgt44bsdbEo5wRVvruDLdSktPmrZ/QK6bxCMfhBu+Q4ihlS+b9R9Jv3iRIohqsIXsKlq6L07BtIlxI9FdeTRP1yZTLf2bfjz5X359fHzePTinixPzGD8a8t4es42nvh6Ky//uItL+3XiyztHnu4yBnDH2Bj6RQTx7LcJDmveJaV2Hvh8E0npubw1fQif3zmCnIISps5c4VTNc2VSBiNiQrDVMVFZ/4i2tPE+k0fflnaS3324js7t/Pjf74bT1q/2XkPPXh5HeKAPj87aXCl3/c3GNMKDfDinhh42jsR1DiLxaE6twWFT6gmyC0o4v3fNPUZiwtow575zmDywM/9YuJs7P95QY2NrSamdP89LIKKdH/eeV/1yvkOQL2Nj2zNn48E6TwwrkzKY+K/fmLPpIA9c0IM5946mV8fAWh/jyBMTejNlkCn76z9Xv/opl11QzM3vrWXV3kz+3zUDuX1st3q/Vvf2begY5OtU2iW/qISVSRn830+J3PTeGgY+v4jL31jOo7O28NrimssJpjHU22ZxmH576MJYenQI4KlvtrHnaA5Xv7WKhQnmBPXK1QPwsVnp0SGA64Z14ZPVB0hu4uX6Xv5xF0UldmbfPYr46GCe+Hobj321lfyillvVy/0COsCIu6DTAMf3lRRB8SnH91UQU9YQ6m210NGJfLQzlFKMj+vI8qQMcmtYqm1L6gk2p57gllHRWCwKf28bD14Yy69/OJ+bRkYxa10qs9ancf/5Pfj3DYOrXQLbrBb+ftUAjucX8eIPO6s9/1++38HS3en8ZUo/xsa2Z2hUCN/eP5qIdn7M+GAdH69KrrH8acfzSc7Md9j/vCovq4VhMSGs2pdJ4tEcbn5/DUF+Xnx6+wjCAnzqfHyQrxf/uGYg+9Lz+PuCXQBk5BaydHc6UwdHYK1HbbFv5yBK7JrEozVfhSzdfQyrRdV5bP7eNv513SCeuzyOpbuPcfm/l/PM3O28ungPH67Yz7wth1iemMHrvySx60gOz1wWV2Pj8dVDIzl0sqDWPvuz1qVy47tr8LFZmH33KH4/vpfDdgVn2KwWXr12EFcOjuDVxXt4dfGeajXG43lFTH93DZtTT/DvG4Zw1VDnUjpVKaUYExvGir0ZtS6w8eO2wwx6fjE3vruGf/28h4zcIq4aGsm/bxjM1EGd+e9v+2ps0C4utfP91sNc1KeDwzy5r5eVV64ewOGTp5jwr2WkZuXz3i3DuH1st0rtRg9fFIu3zcI/Fu5u0LE6snZ/FnM2HeSOcTHER4fwv9tG8NCFsXyzKY2pM1eQdMw1vd3q4r6Noo7kHIVXe8PEV2D4HbXuGhHsh9WiiAzxq9elZl3Gx4Xz3vL9LNuTzqX9O1W7/6OVybTxtlZLKYQF+PDc5L7cNjqGgydOVRtyX1Hfzm25a1w33ly6l8kDOzOubJ7sj1Ym89GqA9w+JoYbR5xpGIsM9mf2Pefw0OebeObbBBKP5fLMZXEczy8iNesUqVn5pGbls64sl+9MQAfTH33p7nRu+O9qvKwWPrtjBJ3aOj+n/OgeYdwyKooPViRzcVw4u4/kUGLXXOlE75aK4jqdaRjtV8Oo0iW70hkaFVznlQOYYDVjdAz9Itry3HcJfL/1ECdOFVfL5I3r2Z5L+tY8jfDFceEE+tqYvSHN4f/0t8R0npqzjbGxYbxzU3yNJ4b6sFoU/7hmIFaL4vWfE7HbNb8f3xOlFOk5hUx/dw37M/P4z01DubBP46ZAHtMjjNkb0thxKJv+DlJ0eYUl/HleAj06BPD4hF4MjQquFJjHxobxW2IGT32zja/vOafaSXx5YgaZeUW1jkUY0jWYhy/qyfxth/n3DYOJDa9+ZdMh0Jc7xnbj/35O5PaU4wyuoTums0pK7Tz77XY6t/U93dhqtSgeubgn8dHBPPzFZia/sZyXr+zf7NNqe1ZAb9MerD6m0bQOXlYLUaH+dAtrfJfFioZGBRPSxptFCUeqBfSM3EK+33qYG4Z3IbCGgUxdQ/2dyuk/eGEsC7Yf4alvtrHokXGs3Z/F898lcFGfcJ66tPr84AE+Nt65OZ5XFuziP8v28dmalEo9PAA6BPpwaf+O9AwPcOpYy086JXbNrLtGnl48pD6enNiHZYkZPP7VVgJ9bfTtHFTvdEN0aBv8va015tGPZRew43A2f5jQq17PGx8dwvcPjAVMb5CTp4rJyiskK6+YE/lFDIsOqbUHka+XlcsGdGbupoP8ZWpJpUbe3UdyuPeTjcR2CODNaUOaJJiXs1oUf79qAFaL4o0lSRTb7dwyKprp767h8MkC3r9l2OleMY1xTtlMnMuTMhwG9DeXJnEsp5C3bxrqsE97O39vnrksjoe/3Mxnaw5w06joSvfP3XyQtn5edQ6sevDC2Dp7A90xrhufrknh5fm7+PKukfXq+VXVJ6sPsOtIDm9NG4K/d+UQOja2PT88OJYHPt/IQ19sJiasDQMi2zX4terLswK6xQLB0U73dJl54xDaeDftv8BmtXBB7w4sSjhCcam90qIZn69JoajUzs3nRDf6dXy9rPz96gFc8/YqHp21mRVJmfTuGMT/XT+oxnSF1aJ46tI+DOzSjk0px4kM9qdriD9dQvyIDPZ3uodDuX6d2/L4Jb04r1d7ejqoGTnDz9v0WLjm7ZUcPAHPXBZX7+ewWBR9OgWRcMjxiNGle8rX46w9MNTGalGEtPEmpI133TtXcPXQCD5fm8L8bYe5Nr4LYE4wt36wFn8fK+/PGFbjyb0xLBbFX6/oj9Wi+M+v+/h0dQoA//vd8BoHjNVXh0BfencMZHlSOvecV7mrbmpWPv/9bT9TB3WucYASwJRBnfl6YxqvLNjN+L4dT3fHzSssYVHCUa4YEtHgFFRFAT42Hr4olj/N3c5PO4+dXuS9vtJzCvl/i/cwNjasxm61Hdv68u4tw4h/cTHfbz3crAHdqf+UUmqCUmq3UipJKfWkg/sfVUrtUEptVUr9rJSqf+fbphLSzanRogB9OgU1WQ+XisbHhZNdUMLa/WcmsCoutfPJmgOMjQ2je3vnasB1GRYdwk0jo1iYcJQ2PlbemxFfY8+Sii7t34k/TorjlnOiOb93B3p0CKx3MAcTNO47vwd9O9feI6YuQ6OCufe8Hvh7Wxs8JqBv5yB2Hs5x2AC5dPcxwoN86NOpYSedxhjSNZiYsDZ8vcH0dskrLOG2j9Zx4lQx790yrN7LHtaHxaJ4cWo/bhsdg7+3lU9vH9Fkwbzc6B5hrEs+Xm1Q1ss/7sSqFE9M7F3r45UyZSwqtVeaeGvRjiOcKi6tc+qH+rhuWBe6tW/D337c2eDJ0/6+YBcFxaWVuqk60tbPi9E9wpi/7XCz9nypM6ArpazATGAiEAfcoJSqWo3aBMRrrQcAs4FXmrqgTguJMYOL7E0z211DjI1tj6+XhUUJZ7oWLkw4wtHsQmY0Qe28oicm9uamkVF8MGN4vfLXZ5vfj+/J6qcvpH1g3Q2qjsR1CiK3sITU45X7RZeU2vktMYPzenZo1GV2Q5k+6RGs2Z9FckYeD32xiR2Hspl545Aa8/1N/frPXh7HmqcvZGCXpq8pjukRVm063dX7Mpm/7Qj3nNfdqc9kVGgbHrwwlh+3H+Gnsh5iczcdIqKdH/FRjct3V+RltfDEhN7sTc9jVgNGXG84cJzZG9K4bUwMPTrUXSmb2K8jacdPNetsoM7U0IcDSVrrfVrrIuALYErFHbTWS7TW5d+k1UDDms6bQkg38A6AU66f3vW04gL46XnIM70Z/LytjIttz6IdR0+fnT9amUzXEP8684H1FeBj4y9T+50eAu+ulFKNmiCt/Cqh6pdnY8oJcgpKapxPvDlcMSQSpWDau2v4aecxnp/ct9buk67gqpNZ+QIbvyWZtFapXfP8dzuIaOfHneOc7w55x9hu9AwP4M/zEjiQmcdvielMGdS5STssgLl6jo8K5tXFe+q12HmpXfPst9vpGOTLgxc4N3r34riOWC2KH7cfbmhx682ZgB4BpFa4nVa2rSa/A350dIdS6k6l1Hql1Pr0dOdH49VL/G3wh73QpvGNPk7b/QMsfxUWP3t60/i+HTl8soDtB7NJOHSSdcnHuXlUVL264wnnxYYHYLWoaiP2luw+hs2iGN0EjYANFdHOj1HdQjl44hR3jI2p1vjnztr4VF5gY9b6VHYezubJib3rlcbztll4+cr+HDxxiunvrcGuqTaYqCkopXh6Uh+y8goZ/9oy5m46WGdKpLjUzhu/JJFwKJs/TurjVFoTIKSNNyO7hfDjtiPNlnZxJqA7ikAOS6eUmg7EA/9wdL/W+h2tdbzWOr59exfVmFrgspqjZbm/o2fWWrygdwcsyuQCP1qZjJ+XlWvKGsVE0/P1shLbIaBaw+jS3enVusu1hD9NiuOJCb15amL1HkjurnyBjZTMfP65cDfDooO5bED1Lrt1GRoVwrQRXUnNOkVcp6AGN7TXZUjXYL68axRhAT48/OVmrnxrZbURywAn84t5a+lexr2yhNd+2sMFvTvU+7gm9OvEvow89tQyRqIpORPQ04CKkSgSqDaNnFLqIuCPwGSttWsmTnCG1vCfc+FXh+cU10hda35Pfev0ppA23gyLDuHbzYeYu/kQVwyJcKoPtGi4uCpTABw5WcDOw9lNnuZqiLjOQQ7nFvcEY2LNdLp3/G89WflFPHtZ7Q2GtfnDhN707hjIjNHRTVvIKoZFh/DtfaN55eoBpB0/xdSZK3j0y80cOVnAvvRcnpm7nZEv/8zfF+yiW/s2vD8jnndvjq/3cV3SNxylzHQfzcGZa4d1QKxSKgY4CFwP3FhxB6XUYOA/wASttfOzA7mCUlCYDceacakqv2AY9ziE9620eXzfjvylbN7mWzzoMvtsFdcpiG82HiQjt5CwAB9+3WM+iuf3brn8eWswIMJMp7v7aA7XDI102CfdWW39vFjw8LgmLF3NLBbFtfFduLR/J2YuSeK93/bzw7bDFJXa8bJYmDKoM7eNiaFPp4a3T3UI9GVYVAgLth/hkVpmMG0qdQZ0rXWJUup+YCFgBd7XWicopV4A1mut52FSLAHAV2VnsBSt9WQXlrt29Zh1sUlc97H5ve49M0f7BX8ETAPMX77fwahuoQ2am0PUT3nD6I5D2Yzr2Z6lu9PpGORLLxddugvDZrUwukcYvyWm83g9B2+dDQJ8bDwxoTc3DOvKf5btJSzAh+kjoxrc46qqif078vx3O9ibnttkXZZr4lR2X2s9H5hfZduzFf6+qInL1TjBMSYNorXrc+p5mWbCMKsXHNkK2742tXWbN11C/Hnu8jhG1DFPt2ga5VMAJBzKZlT3UJYnZjBpQKcW6a7Y2rwwtS8n84srTSTnbrqG+vPSFf2b/Hkn9DMBfcH2Iy6fl909J+eqS0g3k3bJb4auiz/+AWYON3/3nAhFOXBg+em7Z4xu3CWbcF5bfy8ig/3YcTibDQeOk1PYst0VW5MOgb4O51ER0KmtH4O7tmuW7oseGtBjzO+sva5/rdS10LFs5sdu54LND3Y77LUpmkFc2RQAS3enm+6KTk40JoQrTezXke0Hs12+IIhnBvSYcfDoLrPghStlH4aTKdClrIbu5QfdzoPdC5xaZEM0vb6d27I/I48F2w8THx3sknlShKivif1Md8cFCa6tpXtmQPduA0GdXJ8/TyvrrtilwqpJvSaYIH+s+lzlwvXiOgehNSRn5p8V3RVFCyrKh8SfzorKVZcQf/pFBNW60lhT8MyADrDoGdf3RU9da6br7VhhsY0+k+GuZdDB8waQuIO+FaZAOF8Ceuu24En49CrY+mVLlwQwtfRNKSc4fLLuBXgaynMD+qFNkLjI9a/T7VywVZhS1T8EOg1smRGrza0wBzKboZ2iHjq19aWdvxed2vo6Pa+78EApa2DjR2D1NlNyFLT8Is4Ty6bbXeDCWrrnBvTm6It+yUsw7avq21PXwvsTIbdlx1i5VGEufHI1fHiZubQ9SyiluGNsN+47v4d0V2ytSovh+0cgKBKmf2O6EXs37UI2DdGtfQC9wgNdmnbx4IAeA/kZrjszF+WbD44jNl9IWQl7FrrmtVtaUR58di2krYMJfwWbDyz6E6Q33ZqNjXHf+T2YPrKeU/In/QTr3nVNgUQzUzDkJpj0T4gZa5ajtFhbdErtchP6dWRdchbHcgpc8vweHNDLpu487txiF/W2/j34W1c4VX1SHzr2N7WDPQtc89otqSgfPrsOUlbBle9A3yvM6NgtX8L/pjq1/N9ZoygPfnzCvIcbP4b5j8PeJS1dKvdX3ghpt8O7F8E/YiEjqfle22qDkfdAr4lntv/yInx+XYs3kF7avxNaw6KEoy55fs8N6MHlfdFdFNBT10BAB/BzsGiAUqa3y95fzFzpnsJuhy9uhOTlcMV/oP/VZnvbCLh5LhTnw0eTIbva3G1nn+JT8PkNsPYd815OeQPCesHsW133mXGl8rRX+h5I+rl5X9teChmJsOEj+HI6vD7IbLNYTA8wezF8dYv5n7va7FthyV+rb/cPNW1qu35wfRlq0TM8gJeu6Oey+fA9N6CHxcKNsyB6TNM/t9YmT16xu2JVPSeaALd/WdO/fkuxWKD3JJj6Jgy4tvJ94X1NvjI/09TUyxb7OCuVFJrAs38ZTHkTel4CPoFw/aeg7fDFNFN7dxcHVsH/DTC/Fzxhyp+6zjWvVZQPR85ME81Hl8NfI+CNePjuQTi40YwDKSqbLvaSl+DK/8LR7WZUdUPZ7bDsn7D0bzWnUXcvgIQ5JuVZ1bDboX0fWPiUa04spcVnUrB7l8C398OsW6qlIZVSTBsRRYSLlh703IDu5We+qK5Y6OJECuQerX3gUvQY8GoD+3+t33NrfVbk+iopLjjTHjD8Dhh0o+P9IofCDV/AiQMmp+6skiJY8w58fTucSK17/8YoKTJftKSfYPLrMOiGM/eFdoer34f0nfDdQ64tR1NJWw+fXgO+bU2a8Yp3ILAjfHZN07dpHNtpAvcHk86kLtr3gfhbzYnx3tXwSAJM/rcpT7nYi2HMo7Dxf7Dli4a99pGtpua99GVzBbD6bfNelivKhx8fh/a9YdT91R9v9YJLXzHf3RX/17AyOLLuPXh9CLwYbq7IAdJ3mXTr3iUm5bSnGXrblVHNuYBpRfHx8Xr9+vWufZGEOSa/O/Ke+j1u3bvg5V9z4Nr6FXxzO9z1G3Qa4HgfMF36gmNMzbYmWkNmEiT/Bvt/M+mM0kK49mPTJbIuB1bBls/MFyisp/npEGcmDGsKeRllNb415gvbofZFfwFIXmFq7H7tzDGFxZogU5W9FLZ9Zb6oJw6AsprjuG8tBLhoDpY175gv/qT/Z2ptjqx71wSq6NEOymw/837+8iIc2W7er5Kist+FplYaMw6OHwB7Sd2fgYrPfXSb+R8ER5ta9srXYczDEDG0+v6HNsFHU0xX2VvnQ1DZAttZ++C98WaMxO2Lz2xvjNS15sRh8zX/u14TTUOjs0pLYNZN5jvV53LnH1dwEnyCTBrz6A4oKYCf/myuroKj4cp3ocswswTk8ldhxnzH71u5WbeYYHvfWghuxFr2pSXmamjdu9BlpKnA9b/GfD/KPyMnUk2K8sg2uOjPMPrhJunOrJTaoLWOd3Sfc2spuavdC0ygrE9AP7YTfnkJLn6h5n1OZUFgJxM4axPa3bzx2Ufh1PGynyzzu+cEk4P//hHY8IHZP7CTmTqgtBDC+5lth7dC+16mJ0lVv7wIy/4B3oFQWhZQAK56z+S3ExebfHD8baahqL4yEuHTq80UB1e/71wwhzNfKHspfHMH5KVD3FQYcTdExp/5UK+aCYufMQOzpn9tAt/u+WeCecXg2VjFBeDlC8N+B2E9oPsFNe9bHujtdnOyDepsavS7fjC1sAc2mJNV9mHITjOB0+Zj1rL1D4V2ZYFi9Zuw5m3z/nQaYE5s3gHQ90pzNZORBAdWmPfuwArY96v5fIx+GC5+3jQw7/sVds6D6LEmsHe/0Pz/jmwzqS2/tnDLd5WDdkg3mDYbPpwEn1wFdy51/PlxVuJi+PIm8xo3zWlYILTa4IbPz9wuLan7M1n++Rt4I5z3BISXfd9unmfaCZa+bEaEZySZ2v/AG2sP5gDjXwSfAHMFf7osxSY9WnzK/LSNNDX6mhTmmpTdviVwzoNw0XOVT27ln9l2XeC2hfDtfebk2ww8u4a+9O+w9K/wxyOV38Ca2O3w/iXmS3z/Oji0GfyDHdeOnJmat7QY/jfFfFmrunmeqYHv+9XUqGLGmS9ixecsyoN/9TdXC+c9aQLB9tnQtgt0P98E+5TVMHiaqTmdTDVfgo4DIDAcVrxeFjD7w6RXz8w544z9v5kPrcVm0ihdGjgvTuZeU4vZ9ImZAbNjfxPYB083J7a9S0ywrxq4N39mHnPVe+ZL2xg75sEPvzfHEengvazJomdM2e2l5mTpFwK9LoXznzYNwXXJSDTvz+Et5idrnwkYl70KA683PWvmlaUHAjubk3m3c83v8iuagmzY8KE5OeQcNv+/K/9rgv2Cp0xjdHC049fft7TshH5r5e1FeebqIfdI7Sc2MO/RvwaYbsDTvm78lZPWJtdeUgRXvF3zdyh5handOvP5Ky6ADyaYk1h9Uqz/m2oqfPaSytuv/8y0FdVUobCXwqybTaVsyE11v47W5qRt8zEDntpGOvf5qUFtNXTPDujlqZF71zhXu1z7X5j/mOnB0fcKky+02Exqxads1GFp2ZvvbI1313zzRfQLNpfGfsHmJ6Bj5RGmjmhtagE/v2DO8BYv02Ng0HSYOrPu19YadnwLC5+G7IMmiF70fN0f+pIieGOomTly2qyaA0Z9FObCls9NgLT5mlpjbSfEbbNh3gPmZHbVu+YEVl8F2aZb4pbPoPNgEwjDnFuxHTD51m/vM1divS+DrqMadqVTk+JTphFZa/Mlr+3/UVJo0lPr3zeNz37tzPtU12eo3IrXYdf3JsDnlQ14s9jgj0fNMX33kPlMxk02x6vUmUrLgVUmhdZUabzyitblr8PQW8zraG2C5/Fkk3Ne9EdzpTPtqzOzp9aktNicpBz1OKvN2v+aHlle/qbC5+1v/icDbzT/k9m3mfco/nfmxJey0ow87TK8YWstlBabfLvFaiqMtV0F1KL1BvS09fDuhXD959D70tr3PZkGM0eYN2v6N+bNSl5hLluH3GQaesDk7j67ztSwG1prrS+tzZcxcbE50XQ7r34fpsJcWPaKSXEERcADG88EJq1NDcVeYmoRymJ6fBzbZWqJ9f2SNKVju0x3t/RdJthExpueKGBOcIGdoU17x7WoAythzl3mfR37ezj3iQZ/gdze0R2mRhnY0aRLgmPMSTo4BjoPMp+Bj6ea9hu0uVLsEGdSgpNebfppLOx2M8fK/t9M5SIvw6RyYsaeCfZRo+G6T0wlqKUs+as5gealQ7uuJvh3GQkzvm/4/+TYTlNR6HlJg4vVenPo9RlctPM702XtstfOvFnRo2HMI6axJXa8acxJXWvybaHdXVfuqpQyr12fxqSKfAJMm8DAG80c8Vab+TJ9PLX65WbMueaE5my+3JU69IY7fjEphyPbzckGTAD63xTTYIYyJyDftqbx7LYfTS3ry+lm+60LoGst3Utbg/A4eKCOytOM7yHnKOz+wXwXkn4yDZjabhqrm5LFYq6Wfn4BdCn4h51JMQ260fSK6Tigaa+GGuL8p2HsY6YNY8OHpkxTZjbuBNehj0sn7vPsGrrWsOJfJkhFDKl7/5Np5tK3opIieO8i02J9z0pzaXo8Ge5f65IiN5vjyWYgiNXLBECLzfwdHG3SC2fzPCh2u+kOmpFoUhYFJ01+vuAkXPOhOY609aYx2UdW0WmQpmyQFk2q9aZcnHHquGmYjJtScxBL3wNf3GCGun9ylQl4U95o3nIKIQS1B3TPPwUf2wXbv675/kXPmMaP2mZmbN/T9Fv1DjQngPr0FhFCiGbi+QF92yz45k7HMyPuXwabPoZz7q87J26xmtkbwTSMCCHEWcazG0XBNIzaS0wf7fJG0v3LTP541/cmZ3zuk849V4c4uO5TU2MXQoizjOfX0MtnXdyz0KywA5Aw17TiD55uukt5+zv3XH7toM9lrimnEEI0UuuooYNZX9C7DQy5GS74E0x4uXHDoYUQ4izj+QE9sKNJqfiXDduGlh2sIIQQLuL5AV0pOP+pli6FEEK4nOfn0IUQopWQgC6EEB5CAroQQngICehCCOEhJKALIYSHkIAuhBAeQgK6EEJ4CAnoQgjhIVpsPnSlVDpwoIEPDwMymrA47qK1Hje03mOX425dnDnuKK21w9W6WyygN4ZSan1NE7x7stZ63NB6j12Ou3Vp7HFLykUIITyEBHQhhPAQ7hrQ32npArSQtPkpjAAAA3pJREFU1nrc0HqPXY67dWnUcbtlDl0IIUR17lpDF0IIUYUEdCGE8BBuF9CVUhOUUruVUklKKSdXd3Y/Sqn3lVLHlFLbK2wLUUotVkollv0ObskyuoJSqotSaolSaqdSKkEp9VDZdo8+dqWUr1JqrVJqS9lxP1+2PUYptabsuL9USnm3dFldQSllVUptUkp9X3bb449bKZWslNqmlNqslFpftq1Rn3O3CuhKKSswE5gIxAE3KKXiWrZULvMhMKHKtieBn7XWscDPZbc9TQnwe611H2AkcF/Ze+zpx14IXKC1HggMAiYopUYCfwdeKzvu48DvWrCMrvQQsLPC7dZy3OdrrQdV6HveqM+5WwV0YDiQpLXep7UuAr4AprRwmVxCa70MyKqyeQrwUdnfHwFTm7VQzUBrfVhrvbHs7xzMlzwCDz92beSW3fQq+9HABcDssu0ed9wASqlIYBLwbtltRSs47ho06nPubgE9AkitcDutbFtrEa61Pgwm8AEdWrg8LqWUigYGA2toBcdelnbYDBwDFgN7gRNa65KyXTz18/4v4A+Avex2KK3juDWwSCm1QSl1Z9m2Rn3O3W2RaOVgm/S79EBKqQDga+BhrXW2qbR5Nq11KTBIKdUOmAP0cbRb85bKtZRSlwHHtNYblFLnlW92sKtHHXeZ0VrrQ0qpDsBipdSuxj6hu9XQ04AuFW5HAodaqCwt4ahSqhNA2e9jLVwel1BKeWGC+ada62/KNreKYwfQWp8AlmLaENoppcorXp74eR8NTFZKJWNSqBdgauyeftxorQ+V/T6GOYEPp5Gfc3cL6OuA2LIWcG/gemBeC5epOc0Dbin7+xbg2xYsi0uU5U/fA3ZqrV+tcJdHH7tSqn1ZzRyllB9wEab9YAlwddluHnfcWuuntNaRWutozPf5F631NDz8uJVSbZRSgeV/A+OB7TTyc+52I0WVUpdizuBW4H2t9UstXCSXUEp9DpyHmU7zKPBnYC4wC+gKpADXaK2rNpy6NaXUGOA3YBtncqpPY/LoHnvsSqkBmEYwK6aiNUtr/YJSqhum5hoCbAKma60LW66krlOWcnlMa32Zpx932fHNKbtpAz7TWr+klAqlEZ9ztwvoQgghHHO3lIsQQogaSEAXQggPIQFdCCE8hAR0IYTwEBLQhRDCQ0hAF0IIDyEBXQghPMT/B5Bxc4ssI5aaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "pretrained_model=models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet50_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.4926 Acc: 0.7623\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.7623\n",
      "val Loss: 0.2428 Acc: 0.8889\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.8889\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2482 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.8889 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1437 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.8889 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1321 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2523 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9016\n",
      "val Loss: 0.4081 Acc: 0.8431\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8431\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1908 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1302 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1668 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1674 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1772 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1758 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1295 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1719 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1214 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1610 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1404 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2476 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1441 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1314 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1404 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2494 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1250 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1948 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1517 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1393 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2235 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1448 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2622 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1667 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1816 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1806 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2439 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1433 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2306 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1425 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1936 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1679 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1385 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2352 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1430 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2130 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1714 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1459 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1786 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1438 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2218 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1619 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1918 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1445 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2432 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1460 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1480 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2312 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1369 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2388 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1519 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1674 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1432 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2447 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1467 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1928 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1591 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2129 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1555 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1492 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1316 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1827 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1475 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1697 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1426 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1489 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1772 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1452 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1616 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2184 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1351 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1729 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1445 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2240 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1516 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1416 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2265 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1375 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1535 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1610 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1796 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1507 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1603 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2247 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1432 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1961 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1487 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1502 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1494 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1456 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2216 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1433 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2325 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1740 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1871 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1471 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1370 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1783 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1733 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1452 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1642 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1853 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1762 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1517 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1471 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1702 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1440 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2144 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1482 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1867 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1337 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1446 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2080 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1401 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1801 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1915 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1804 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1459 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1462 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1581 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1383 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2005 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1629 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2099 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1495 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2089 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1440 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1719 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1333 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2682 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1425 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1506 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1605 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1870 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1563 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1929 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1316 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1578 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2045 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1370 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1557 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1715 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1475 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1598 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1649 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1764 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1869 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1439 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1378 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2307 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1377 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1858 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1550 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1398 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1309 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2271 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1327 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2877 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1505 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1886 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1508 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2385 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1587 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1614 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1600 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1682 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1392 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1422 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1561 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2070 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1590 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1349 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1558 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1712 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1488 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1700 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1526 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1403 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1834 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1671 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2050 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1401 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1397 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1990 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1415 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1990 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1838 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1435 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1460 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2421 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1526 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1429 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1690 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1994 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1462 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1354 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2680 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1529 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2514 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1388 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1913 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1606 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2171 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1536 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1513 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1438 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1471 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2008 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1431 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1640 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1483 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2611 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1432 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1770 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1430 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1718 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2017 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1637 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1443 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1752 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1451 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1549 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1961 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1482 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1405 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1621 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1659 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1566 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1479 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1338 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1844 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1622 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1405 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2074 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2161 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.2100 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2048 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2124 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1961 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1645 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1389 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1607 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2200 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1881 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1734 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1419 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2252 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1990 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2226 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2127 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1380 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1417 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1344 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1804 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1857 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1418 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1692 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1685 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1816 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1532 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1958 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1623 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2060 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1860 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1543 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1841 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1385 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1600 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1540 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1814 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1481 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2156 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1451 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2373 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1537 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1793 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1450 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1932 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1578 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1766 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1507 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1341 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1821 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1574 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1628 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2120 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1486 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2193 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1599 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2795 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1456 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2312 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1514 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2127 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1436 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1435 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2087 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1505 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1927 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1645 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1971 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1329 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2470 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1481 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2259 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2857 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1525 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1484 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1859 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1462 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1891 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1519 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1573 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1499 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1788 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1664 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1876 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1437 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2275 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1409 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2058 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1658 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1497 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1508 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1748 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1319 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2383 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1567 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1953 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1546 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2443 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1497 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1594 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2544 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1401 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1525 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1394 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1406 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1408 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1796 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1398 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1836 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1470 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1771 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1465 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1506 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2445 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1432 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2530 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1486 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1835 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1344 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1397 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1983 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1431 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2475 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1359 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2040 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1266 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1823 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1494 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1984 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1500 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2015 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1450 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2471 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1582 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1596 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2706 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1496 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2126 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1592 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1903 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1535 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1434 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1977 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1408 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1404 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1790 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1477 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2205 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1394 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1621 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1662 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1746 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1416 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1378 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2230 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1520 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1412 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1593 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1475 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2597 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1415 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1559 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1338 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2241 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1379 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2663 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1557 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1587 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1496 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1336 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1418 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2087 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1454 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1689 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1443 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1453 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1462 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1528 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2674 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1577 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1321 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1984 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1531 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1571 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1615 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2038 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1519 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2147 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1553 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1912 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1465 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1600 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1505 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2569 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1401 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1578 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1357 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2209 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1385 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2009 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1364 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2643 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1440 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2249 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1607 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1475 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1832 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1497 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1714 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1404 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1368 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1534 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2135 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1733 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2451 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1509 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1654 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1898 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1888 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1586 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2306 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1524 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1357 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2237 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1401 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1856 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2032 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1529 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1792 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1425 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1988 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1379 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1309 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2075 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1610 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1439 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1378 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1991 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1566 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2029 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1498 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2017 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1570 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1798 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1271 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2344 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1596 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1452 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1497 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1895 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1402 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2841 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1486 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2109 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1512 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1403 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1591 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1389 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1633 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1968 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1350 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2252 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1854 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1483 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1405 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2190 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1612 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1810 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1332 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2100 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1537 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2468 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1454 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2527 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1577 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1958 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.2021 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1316 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1540 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2418 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1462 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2987 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1730 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1934 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1681 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1805 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1805 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1482 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1512 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2559 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1916 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1646 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1467 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1803 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2141 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1487 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1645 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1458 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1860 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1650 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2005 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1483 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2035 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1493 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1574 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1817 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1376 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2110 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1365 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2534 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1635 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1752 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1601 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2085 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1421 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1358 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1963 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1406 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1538 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1490 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1612 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1458 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1750 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1462 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2128 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1460 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1819 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1452 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1848 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1636 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1817 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1543 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1393 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1852 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1519 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1580 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1327 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2499 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1466 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2013 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1541 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1778 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1498 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1511 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1520 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1702 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2036 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1329 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2445 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1705 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2310 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1739 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2104 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1522 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2062 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1391 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1873 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1579 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2406 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1694 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1887 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2151 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1515 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1320 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2209 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1468 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2778 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1444 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1591 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2316 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1361 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2713 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1389 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1781 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1429 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1840 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1437 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1338 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2167 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1648 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1850 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1533 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2412 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1583 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2077 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1441 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2131 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1477 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1444 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1627 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1569 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2017 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1436 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1931 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1318 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2185 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1397 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1734 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1318 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1990 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1539 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1369 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1600 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2481 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1285 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1466 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2074 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1498 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1417 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1584 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2035 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1472 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1482 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2058 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1297 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1437 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2192 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1438 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1362 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2725 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1831 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1466 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1442 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1751 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1478 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1892 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1476 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1491 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2229 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1740 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1461 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1720 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2063 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1414 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1463 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2665 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1386 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1446 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1987 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1573 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2316 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1444 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1698 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1388 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2002 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1439 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1507 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2149 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1483 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2293 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1528 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1704 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1636 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1485 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2015 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1651 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1561 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1991 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1486 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1357 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1471 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1706 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1471 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1595 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1823 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1541 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2183 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1590 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1952 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1546 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2148 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1691 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1936 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1386 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1783 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1453 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1545 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1551 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1977 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1441 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1465 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1337 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1603 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2025 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1503 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2611 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1699 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1507 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1865 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1583 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2584 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1423 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1955 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1335 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2296 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1572 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1463 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2149 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1430 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2296 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1710 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1484 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2301 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1498 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2531 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1555 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1518 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3073 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1479 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2171 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1807 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1780 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1432 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2190 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1451 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2483 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1434 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1465 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1745 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1418 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1296 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1678 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2687 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1354 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Training complete in 30m 58s\n",
      "Best val Acc: 0.960784\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet101(pretrained=True)\n",
    "pretrained_model=models.resnet101(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet101_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5050 Acc: 0.7582\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.7582\n",
      "val Loss: 0.2230 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2926 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9085 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9085 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1655 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3053 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1062 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1115 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1703 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0929 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3375 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1822 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2567 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1147 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1718 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1085 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1136 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1957 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1177 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2187 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1206 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1688 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2434 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1144 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1233 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2045 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1176 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1700 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1171 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1737 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1247 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1712 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1170 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1211 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1767 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1222 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2324 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1758 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1207 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1725 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1282 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1195 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2644 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1197 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1856 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1264 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2002 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1583 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1233 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1326 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2469 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1254 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1746 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1228 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1688 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1215 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1886 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1211 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1176 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1220 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1162 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2474 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1222 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1855 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1191 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1227 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1632 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1151 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1819 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1264 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2366 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1175 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1219 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1224 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2689 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1197 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1250 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1303 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2011 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1213 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2010 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1248 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2370 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1236 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2237 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1178 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2102 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1208 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1255 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1253 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1238 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1633 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1270 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2212 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1209 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1994 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1253 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1878 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1249 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1227 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2084 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1267 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1168 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2167 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1181 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2541 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1246 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1256 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1802 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1202 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1685 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1256 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2088 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1412 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1215 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1864 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1311 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1220 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1332 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3019 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1182 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2447 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1192 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2264 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1128 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1199 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1921 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1225 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2157 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1172 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1976 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1210 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2003 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1177 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1815 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1215 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1316 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1714 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1679 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1715 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1161 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2338 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1238 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1209 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2013 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1283 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1217 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1166 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2039 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1199 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2313 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1181 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1757 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1206 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1910 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1265 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1262 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1716 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1155 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1994 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1300 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2169 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1230 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2056 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1228 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1248 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1153 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2423 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1202 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1995 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1944 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1244 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1785 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1308 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2205 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1202 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1270 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2426 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1907 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1240 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1269 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1222 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2568 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1168 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2224 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2049 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1183 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1159 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2141 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1163 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2497 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1242 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2421 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1171 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2049 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1234 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1787 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1924 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1175 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1766 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1286 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1983 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1235 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1246 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1225 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2774 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1279 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1292 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1673 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1140 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1308 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2138 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1212 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2943 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1897 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1212 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2314 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1247 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1226 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2561 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1235 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2627 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1289 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2043 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1183 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1791 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1182 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1786 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1211 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1727 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1245 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2307 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1136 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1796 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1230 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2222 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1243 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1575 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1237 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1835 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1237 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1908 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2008 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1265 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2046 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1212 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1191 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1585 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1222 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2173 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1251 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2150 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1183 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1655 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1256 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1439 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1220 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1189 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1823 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1194 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1934 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1133 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1725 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1153 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1991 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1186 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1992 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1226 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1842 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1198 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2479 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1213 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2006 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1181 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2109 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1237 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1924 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1247 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2062 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1252 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1760 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1213 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1193 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2955 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1862 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1202 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2143 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1219 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1301 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2046 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2399 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1173 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1468 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1227 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1251 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2100 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1236 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1556 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1233 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1775 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1245 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2032 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1213 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1906 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1930 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1166 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1853 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1278 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1183 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2369 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1242 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2114 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1235 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2038 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1188 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2014 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1224 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1186 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1870 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1204 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1861 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1189 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1161 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1826 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1272 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1193 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1667 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1224 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1617 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1201 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2454 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1127 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2506 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1214 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1672 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1131 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1227 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1217 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1918 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1199 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1188 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1893 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1193 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2627 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1269 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1893 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1301 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2192 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1225 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2552 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1243 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1835 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1815 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1231 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1873 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1255 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1921 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1229 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2076 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1197 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1795 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1189 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2370 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1194 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1236 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2724 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1212 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1957 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1218 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1265 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1211 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1250 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2009 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1203 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1273 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1782 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1997 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1894 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1200 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1680 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1245 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1613 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1208 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1242 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1577 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1207 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1924 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1717 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1272 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1782 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1898 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1300 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2226 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1200 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1913 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1221 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1244 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1763 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1324 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1602 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1217 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1885 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1221 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1883 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1239 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2123 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1229 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1203 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2023 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1299 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2051 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2076 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1215 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1213 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1187 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1753 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1171 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1209 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2249 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1216 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2018 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1149 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1931 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1257 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2088 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1179 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1778 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1223 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1727 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1212 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2217 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1769 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1980 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2599 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1228 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1169 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1937 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1221 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1250 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1769 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1205 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1925 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2022 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1159 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2469 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1221 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1230 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2520 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1218 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2140 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2345 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1151 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1525 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1236 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1202 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1757 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1239 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2333 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2240 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1248 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1844 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1148 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1269 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2081 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1180 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1908 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1170 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1787 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1198 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2211 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1117 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2129 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1269 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1852 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1153 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1922 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1199 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1223 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1218 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1216 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2173 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1962 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1217 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1601 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1157 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2505 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1236 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2140 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1217 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2631 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1266 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2040 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1301 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1854 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1233 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1722 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1228 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1970 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1243 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1702 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2122 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1166 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1182 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2047 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1205 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1247 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2195 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1162 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1181 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1210 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1864 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1256 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2222 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1425 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1210 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2479 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1228 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1964 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1184 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2328 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1241 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1859 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1239 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1683 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1225 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1873 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1209 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2229 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1186 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2407 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1321 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2055 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1221 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1202 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2397 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1171 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1316 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1205 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1147 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1937 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1207 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1250 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2063 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1151 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1596 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1169 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1718 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1233 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1747 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2490 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1206 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1663 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1807 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1251 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1934 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1096 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2142 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1268 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2606 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1253 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1218 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1202 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1585 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1187 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2711 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1194 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2169 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1407 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1220 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1639 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1259 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2182 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1271 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2002 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1169 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1598 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1277 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1964 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1208 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1771 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1152 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1174 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2109 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1227 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1974 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1205 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1502 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1197 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2066 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1230 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2017 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1196 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2152 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1180 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1616 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1190 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1775 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1207 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1176 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1297 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2092 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1226 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1954 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1204 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2010 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1156 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1709 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1201 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1224 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1234 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1591 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1265 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1866 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1234 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1168 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1903 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1216 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2194 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1273 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1785 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1213 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2110 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1200 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2536 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1196 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1269 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1519 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1208 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1638 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1190 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1659 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1179 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2402 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1145 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1793 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1185 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1685 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1218 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1269 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1254 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1784 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1156 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2130 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1211 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1248 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1276 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1259 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1264 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1228 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1637 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1208 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1236 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1996 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1254 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2143 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1152 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1552 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1278 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1756 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1155 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2129 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1165 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1270 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1688 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1162 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1794 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1232 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1172 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1282 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1218 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2003 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1253 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1974 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1229 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1984 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1205 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1235 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1877 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1207 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2228 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1226 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1176 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1698 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1221 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1231 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1716 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2130 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1268 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2077 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1195 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2084 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1206 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1247 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1942 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1155 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1659 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1183 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1983 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1258 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2120 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1200 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1781 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1287 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1124 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1906 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1220 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1645 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1149 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1179 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1227 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2892 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1261 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1757 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1216 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1221 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1913 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1882 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1190 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1804 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2132 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1198 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1884 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2364 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1225 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1236 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1162 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1257 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2127 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1192 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1265 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1155 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1179 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1955 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1152 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1227 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1646 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1223 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1787 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1345 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1809 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1235 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1199 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1803 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1283 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2785 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1204 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1966 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1179 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2156 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1211 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2023 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1243 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1206 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2281 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1211 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1797 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1246 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1810 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2031 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1247 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1627 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1184 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2101 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1979 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1213 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2600 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1102 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1178 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1252 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1838 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1299 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1173 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1923 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1184 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1770 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1159 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2011 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1195 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1695 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1195 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1161 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Training complete in 41m 3s\n",
      "Best val Acc: 0.980392\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet152(pretrained=True)\n",
    "pretrained_model=models.resnet152(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet152_lrscheduler_wholenetwork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
