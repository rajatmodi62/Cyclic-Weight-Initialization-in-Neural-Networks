{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "The problem we're going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
    "There are 75 validation images for each class. Usually, this is a very\n",
    "small dataset to generalize upon, if trained from scratch. Since we\n",
    "are using transfer learning, we should be able to generalize reasonably\n",
    "well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n",
    "\n",
    "\n",
    "Its a cat bees dataset, constructing a transformation pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Training Function , the scheduler is lr=0.001, decays by 0.1 every 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_weight_initialization(model,pretrained_model,alpha=1):\n",
    "    \n",
    "    model_state_dict=model.state_dict()\n",
    "    pretrained_model_state_dict=pretrained_model.state_dict()\n",
    "    for layer in model_state_dict.keys():\n",
    "        \n",
    "        if layer=='fc.weight' or layer=='fc.bias':\n",
    "            print(\"skipping\")\n",
    "        else:\n",
    "            model_state_dict[layer]=(model_state_dict[layer]+alpha*pretrained_model_state_dict[layer])/(1+alpha)\n",
    "        \n",
    "    #reload the state_dict of model\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, pretrained_model, criterion, optimizer, scheduler, num_epochs=50,alpha=1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                print('model is training, goign to refresh its resnet memory')\n",
    "                print('alpha is',alpha)\n",
    "                model=cyclic_weight_initialization(model,pretrained_model,alpha)\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #print(inputs.size())\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            print('{} Rajat Best_Acc: {:.4f} Epoch_Acc: {:.4f}'.format(\n",
    "                phase, best_acc, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                \n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            #collect losses\n",
    "            if phase=='train':\n",
    "                train_losses.append(epoch_loss)\n",
    "            if phase=='val':\n",
    "                val_losses.append(epoch_loss)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,train_losses,val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the model predictions\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Generic function to display predictions for a few images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            print(\"modi\",inputs.size())\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def plot_losses(train_loss,val_loss):\n",
    "    df = pd.DataFrame(list(zip([i for i in range(0,len(train_losses))],train_loss,val_loss)), \n",
    "               columns =['epoch', 'train_loss','val_loss']) \n",
    "    list_data=[df.train_loss,df.val_loss]\n",
    "    plots=sns.lineplot(data=list_data)\n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_output(model,train_loss,val_loss,experiment_name):\n",
    "    model_dump_path=experiment_name+'.pt'\n",
    "    torch.save(model.state_dict(),model_dump_path)\n",
    "    csv_dump_path=experiment_name+'.csv'\n",
    "    df = pd.DataFrame(list(zip(train_loss,val_loss)), \n",
    "           columns =[ 'train_loss','val_loss'])\n",
    "    df.to_csv(csv_dump_path)\n",
    "    list_data=[df.train_loss,df.val_loss]\n",
    "    plot_dump_path=experiment_name+'.png'\n",
    "    plots=sns.lineplot(data=list_data)\n",
    "    fig=plots.get_figure()\n",
    "    fig.savefig(plot_dump_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E1. Train whole model, LR scheduler, 100 epochs, resnet18 \n",
    "----------------------------------------------------------------------------\n",
    "Resnet18, train the whole model\n",
    "\n",
    "Best val Acc: 0.960784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5493 Acc: 0.6762\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6762\n",
      "val Loss: 0.2206 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3740 Acc: 0.8443\n",
      "train Rajat Best_Acc: 0.9150 Epoch_Acc: 0.8443\n",
      "val Loss: 0.1780 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9150 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3247 Acc: 0.8484\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8484\n",
      "val Loss: 0.1660 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3190 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1666 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2437 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1701 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3625 Acc: 0.8279\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8279\n",
      "val Loss: 0.1896 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2896 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1785 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1648 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1706 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2195 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1696 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2503 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1793 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2443 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1754 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2187 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1709 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2403 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1609 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1780 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1800 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2516 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1710 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1755 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2971 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1730 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2884 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1888 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2433 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1771 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3095 Acc: 0.8402\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8402\n",
      "val Loss: 0.1731 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2604 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1700 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2859 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1704 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2044 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1777 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1759 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2476 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1722 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2699 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1747 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2396 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1708 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2263 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1759 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1770 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2381 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1797 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1810 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2640 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1785 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1764 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2249 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1749 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2751 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1687 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2820 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1732 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2608 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1714 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2550 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1779 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2773 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1778 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2553 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1740 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2460 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1700 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2468 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1808 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2461 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1865 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "pretrained_model=models.resnet18(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet18_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5597 Acc: 0.6844\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6844\n",
      "val Loss: 0.1940 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2785 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1749 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2946 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1685 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3431 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1433 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1930 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1501 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1761 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2135 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1637 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2595 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1677 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2632 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1632 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2752 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1689 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2736 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1705 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2652 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1724 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2799 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1761 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2114 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2847 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1748 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2740 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1725 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1685 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3010 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2340 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2921 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1670 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2612 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1880 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1678 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1603 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2688 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1669 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2342 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1754 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2775 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1736 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2314 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1716 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1729 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2454 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2771 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1671 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1711 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3166 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1660 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2772 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1802 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2171 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.2009 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2831 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1602 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2498 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1756 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1999 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1706 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2630 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2783 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1629 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2403 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1663 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1722 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2667 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1763 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2462 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1715 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2567 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1644 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2402 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1784 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1732 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2924 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1681 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2707 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1651 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2701 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1754 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1679 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2282 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1793 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2712 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1639 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1615 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1670 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2484 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2764 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1727 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1752 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2617 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2131 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1654 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1677 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3351 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1715 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1849 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2428 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1723 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2562 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1730 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2735 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1934 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2281 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2267 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1694 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2563 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1663 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2460 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1775 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2085 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1712 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2670 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1670 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2192 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1685 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2445 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1643 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1981 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1675 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2252 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1655 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2515 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1629 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2668 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1701 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2778 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1823 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2229 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1739 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2243 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1668 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2464 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1668 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2756 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2548 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1600 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2126 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1746 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2827 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1664 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1834 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2046 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1703 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2870 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2954 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2445 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1709 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2320 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2905 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1763 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2163 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1751 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2218 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1686 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1812 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2760 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1803 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2476 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1737 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1697 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2326 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1652 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3040 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1756 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2937 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1616 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1694 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2543 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1625 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1656 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2144 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1714 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2509 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1690 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1999 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1741 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1681 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2855 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1730 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2398 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1812 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3315 Acc: 0.8361\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8361\n",
      "val Loss: 0.1642 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2491 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1822 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2717 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1742 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2817 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1607 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2545 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1791 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2667 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1681 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2208 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1596 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2762 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1620 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1672 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2868 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1783 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1706 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2776 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1729 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2583 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1668 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2212 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1743 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2067 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1965 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2847 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1730 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2115 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1833 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3252 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1664 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2945 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1677 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3001 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1909 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1871 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2053 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1711 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2683 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2675 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1682 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2392 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1803 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2609 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1605 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1723 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2455 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1815 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2789 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2325 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1724 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2205 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1743 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2215 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1679 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2769 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1675 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1597 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1765 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2589 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1783 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1793 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2701 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1785 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2396 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1751 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2888 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2273 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1825 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3283 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1771 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2178 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1618 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2786 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1654 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1613 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2872 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2425 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1803 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1799 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1622 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2957 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2643 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1591 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1640 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1993 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2426 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1677 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1780 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2194 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1627 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2079 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2511 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1648 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2436 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1743 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1946 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1648 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2701 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2698 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1733 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1877 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1921 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1681 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2647 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2233 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1686 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2053 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1723 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2544 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1688 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1628 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2249 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1934 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2549 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1736 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1669 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2495 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1639 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2746 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1658 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2557 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1775 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2815 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1646 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2397 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1807 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2499 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1622 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2783 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1641 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2903 Acc: 0.8443\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8443\n",
      "val Loss: 0.1704 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1847 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1762 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2718 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1752 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1644 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1859 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1793 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1810 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1637 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2871 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1988 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1798 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2695 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1716 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2175 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1688 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2546 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1707 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2613 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1828 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1665 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2907 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2265 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1702 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2646 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1636 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2707 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1715 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2698 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1612 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2761 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2928 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1802 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2921 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1773 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2508 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1696 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2554 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1732 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1683 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2648 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1744 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2934 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1698 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1698 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2348 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1715 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2667 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1661 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1665 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2732 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1797 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2534 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1651 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2413 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1630 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1731 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2996 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1720 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2428 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2566 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1853 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2721 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1661 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2734 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1594 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3040 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1689 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2588 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1651 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2523 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1909 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2503 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1657 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1891 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1574 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2450 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1682 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1626 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2524 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1776 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2230 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1728 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2454 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1656 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2650 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1685 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2447 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1677 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2871 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1645 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1699 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2351 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1691 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2489 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2264 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1690 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2358 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1632 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3462 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1740 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2487 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1599 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3174 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1538 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1743 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2418 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1623 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3047 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1696 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1640 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2849 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2582 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1808 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3211 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1896 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2474 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1684 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1757 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1717 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1758 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1756 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2693 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1696 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2597 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1647 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2691 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1714 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1647 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2012 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1751 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2013 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1683 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2292 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1746 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2150 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1684 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1688 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2569 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1699 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1645 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2222 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1610 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2710 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1739 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2515 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1604 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1709 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1707 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1842 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2224 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1626 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1951 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1615 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1628 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2477 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1790 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2708 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1617 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1637 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1757 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1645 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1844 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1680 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2528 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1630 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1667 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2406 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1814 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2746 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1652 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2615 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2501 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1696 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1822 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1747 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2293 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1709 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2166 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1785 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1833 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2956 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2549 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1665 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2816 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1659 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2653 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1683 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2963 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1623 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1768 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2369 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1794 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1877 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1615 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3002 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1716 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2735 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2641 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2629 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1707 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2658 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1651 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2867 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1679 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2615 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1602 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2038 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1670 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2961 Acc: 0.8484\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8484\n",
      "val Loss: 0.1705 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2936 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1795 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2585 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1755 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2695 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1692 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1684 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2015 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1663 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1731 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1690 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2123 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1673 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2451 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1753 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2716 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2275 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1683 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2459 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1676 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2329 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1713 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2249 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1714 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1721 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1693 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2556 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1717 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1695 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2747 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1709 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1796 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1759 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2617 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1677 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2368 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1843 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3011 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1793 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1780 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1699 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1753 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1636 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2945 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1831 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2578 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1684 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2128 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1641 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2326 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1684 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2443 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1604 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2688 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1687 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1579 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1690 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2243 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1698 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2359 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1708 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2364 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1772 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1662 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2490 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1732 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2509 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1744 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2541 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1738 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2565 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1657 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2819 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1734 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2090 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1838 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1650 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1707 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1772 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2421 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2400 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1677 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2361 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1646 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3580 Acc: 0.8238\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8238\n",
      "val Loss: 0.1667 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1710 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1692 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2416 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1711 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2599 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1744 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2398 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3030 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1751 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2548 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1897 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1732 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2565 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1673 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1614 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2855 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1672 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2466 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1789 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1755 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2548 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1929 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1789 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2385 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1782 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3304 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2091 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1874 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2786 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1856 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1732 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2465 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1613 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2230 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1659 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1818 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.2069 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2169 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1782 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1615 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2575 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1571 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2640 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1685 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2489 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1657 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1753 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2886 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1703 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1700 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1682 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2830 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1687 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2329 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1606 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2775 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1703 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1720 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1815 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1743 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2468 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1735 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2455 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1653 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2673 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1930 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2994 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2872 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1676 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2532 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1654 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1890 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1656 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1696 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2630 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1670 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2854 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1766 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2885 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1744 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2144 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2217 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1796 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2992 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2679 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1585 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2785 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1606 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1764 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1765 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2332 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1809 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2729 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1638 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1708 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1671 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2316 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1714 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2416 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1650 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1620 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1657 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2835 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1857 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1914 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2348 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1784 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2036 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1707 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1672 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2258 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1620 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2620 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1688 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2359 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1657 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1655 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1779 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2545 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1682 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2910 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1624 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1710 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1808 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1709 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1838 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1767 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2377 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1794 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1675 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2298 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2498 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1767 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2199 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1679 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2619 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1748 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2592 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1744 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1685 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2854 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1783 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1971 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1768 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2601 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1618 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1650 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1640 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2266 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1702 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2041 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1697 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2857 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1727 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2571 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1651 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2753 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1668 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2071 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1705 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1651 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3011 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1660 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1681 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2647 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1637 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2294 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1705 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2267 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1717 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 13m 19s\n",
      "Best val Acc: 0.973856\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xUVfr48c+ZmfTegDRI6L03AQWsqCiuFbvurl1X3dWvun0tv3Wb7rqLuuru2rBiQ0WxUaRKgNAJhFBSSO+9zPn9cWdCykwySSYJkzzv14sXmTt3Zs5NZp459znPOVdprRFCCOH5TL3dACGEEO4hAV0IIfoICehCCNFHSEAXQog+QgK6EEL0EZbeeuHIyEidkJDQWy8vhBAeafv27fla6yhH9/VaQE9ISCApKam3Xl4IITySUuq4s/sk5SKEEH2EBHQhhOgjJKALIUQf0Ws5dCFE31NXV0dGRgbV1dW93RSP5+vrS1xcHF5eXi4/RgK6EMJtMjIyCAoKIiEhAaVUbzfHY2mtKSgoICMjg8TERJcfJykXIYTbVFdXExERIcG8i5RSREREdPhMRwK6EMKtJJi7R2d+jx4X0LcdK+Svq1NosMqyv0II0ZTHBfTkE8X8a00qlbX1vd0UIYQ4rXhcQPf3MQNQWdvQyy0RQpxuiouLef755zv8uIsuuoji4uIOP+6WW25hxYoVHX5cd/G4gB7gbRTmVNRID10I0ZyzgN7Q0HYHcNWqVYSGhnZXs3qMx5Ut+ntLD10IT/CHT/exP6vUrc85NiaY310yzun9jz76KEeOHGHy5Ml4eXkRGBhIdHQ0ycnJ7N+/n8suu4z09HSqq6u5//77uf3224FTa0uVl5dz4YUXMm/ePDZt2kRsbCyffPIJfn5+7bbt22+/5aGHHqK+vp4ZM2bwwgsv4OPjw6OPPsrKlSuxWCycf/75/PWvf+X999/nD3/4A2azmZCQENavX++W34/HBfQAH+mhCyEce/rpp9m7dy/JycmsXbuWiy++mL179zbWcv/3v/8lPDycqqoqZsyYwRVXXEFERESz5zh8+DBvv/02L7/8MldffTUffPABN9xwQ5uvW11dzS233MK3337LyJEjuemmm3jhhRe46aab+Oijjzh48CBKqca0zuOPP87q1auJjY3tVKrHGY8L6I099DrpoQtxOmurJ91TZs6c2WxiznPPPcdHH30EQHp6OocPH24V0BMTE5k8eTIA06ZN49ixY+2+TkpKComJiYwcORKAm2++mWXLlnHvvffi6+vLT3/6Uy6++GIWL14MwNy5c7nlllu4+uqrufzyy91xqIAH5tD9bTn0yhoJ6EKItgUEBDT+vHbtWr755hs2b97Mrl27mDJlisOJOz4+Po0/m81m6uvbzwZo7biM2mKx8MMPP3DFFVfw8ccfs2jRIgBefPFFnnzySdLT05k8eTIFBQUdPTTHr+eWZ+lB9h56hZQtCiFaCAoKoqyszOF9JSUlhIWF4e/vz8GDB9myZYvbXnf06NEcO3aM1NRUhg8fzhtvvMH8+fMpLy+nsrKSiy66iNmzZzN8+HAAjhw5wqxZs5g1axaffvop6enprc4UOsPjAro9h14pOXQhRAsRERHMnTuX8ePH4+fnx8CBAxvvW7RoES+++CITJ05k1KhRzJ49222v6+vry//+9z+uuuqqxkHRO++8k8LCQpYsWUJ1dTVaa5599lkAHn74YQ4fPozWmnPOOYdJkya5pR3K2alCd5s+fbruzBWLqusaGP2bL3n4glHcs3B4N7RMCNFZBw4cYMyYMb3djD7D0e9TKbVdaz3d0f4el0P3sZgwm5TMFBVCiBY8LuWilMLf20yFDIoKIXrIPffcw8aNG5ttu//++7n11lt7qUWOeVxAB2O2qPTQhRA9ZdmyZb3dBJd4XMoFjPVcKmSmqBBCNOORAT3A2yJVLkII0YJHBnR/b+mhCyFESx4Z0AN8JIcuhBAteWRA9/M2y2qLQoguCwwMdHrfsWPHGD9+fA+2pus8MqAHeJtlLRchhGjBI8sW/b0tspaLEJ7gfxc73n7r58b/XzwK2Xta37/ojxA9EXYuh+S3Wj/OiUceeYQhQ4Zw9913A/D73/8epRTr16+nqKiIuro6nnzySZYsWdKhw6iuruauu+4iKSkJi8XCM888w8KFC9m3bx+33nortbW1WK1WPvjgA2JiYrj66qvJyMigoaGB3/zmN1xzzTUder3O8siAHuBjpFy01nKFcSFEo6VLl/LAAw80BvT33nuPL7/8kgcffJDg4GDy8/OZPXs2l156aYdih70Ofc+ePRw8eJDzzz+fQ4cO8eKLL3L//fdz/fXXU1tbS0NDA6tWrSImJobPPze+fEpKStx/oE54ZED397bQYNXU1Fvx9TL3dnOEEM6006Pmwqfbvn/K9cY/F02ZMoXc3FyysrLIy8sjLCyM6OhoHnzwQdavX4/JZCIzM5OcnBwGDRrk8vNu2LCB++67DzBWVhwyZAiHDh3ijDPO4KmnniIjI4PLL7+cESNGMGHCBB566CEeeeQRFi9ezJlnnuny63SVx+bQQS5DJ4Ro7corr2TFihW8++67LF26lOXLl5OXl8f27dtJTk5m4MCBDtdBb4uzRQyvu+46Vq5ciZ+fHxdccAHfffcdI0eOZPv27UyYMIHHHnuMxx9/3B2H5RLP7KE3uQxdeIB3L7dGCHE6Wbp0Kbfddhv5+fmsW7eO9957jwEDBuDl5cWaNWs4fvx4h5/zrLPOYvny5Zx99tkcOnSIEydOMGrUKNLS0hg6dCg/+9nPSEtLY/fu3YwePZrw8HBuuOEGAgMDefXVV91/kE54ZEAPsF+1SHroQogWxo0bR1lZGbGxsURHR3P99ddzySWXMH36dCZPnszo0aM7/Jx33303d955JxMmTMBisfDqq6/i4+PDu+++y5tvvomXlxeDBg3it7/9Ldu2bePhhx/GZDLh5eXFCy+80A1H6ZhL66ErpRYB/wDMwCta66db3H8L8Bcg07bpX1rrV9p6zs6uhw6wJiWXW/+3jQ/vnsPUwWGdeg4hhPvJeuju1dH10NvtoSulzMAy4DwgA9imlFqptd7fYtd3tdb3dq7ZHRMg1xUVQohWXEm5zARStdZpAEqpd4AlQMuA3mPkuqJCCHfZs2cPN954Y7NtPj4+bN26tZda1HmuBPRYIL3J7QxgloP9rlBKnQUcAh7UWqc72MctGq8rKgFdiNOOp80PmTBhAsnJyb3djFY6c3lQV8oWHf1lWr7Sp0CC1noi8A3wmsMnUup2pVSSUiopLy+vYy1twl/KFoU4Lfn6+lJQUNCpYCRO0VpTUFCAr69vhx7nSg89A4hvcjsOyGrx4gVNbr4M/MlJI18CXgJjULRDLW2iMaBLDl2I00pcXBwZGRl0pcMmDL6+vsTFxXXoMa4E9G3ACKVUIkYVy1LguqY7KKWitdYnbTcvBQ50qBUd5G8bFJUcuhCnFy8vLxITE3u7Gf1WuwFda12vlLoXWI1RtvhfrfU+pdTjQJLWeiXwM6XUpUA9UAjc0o1txmxS+HqZJOUihBBNuDSxSGu9CljVYttvm/z8GPCYe5vWtgBvCxVyGTohhGjkkWu5gHGhaOmhCyHEKR4b0KWHLoQQzXlsQPeXy9AJIUQzHhvQA3zkqkVCCNGUxwZ0f7muqBBCNOOxAT1ArisqhBDNeGxA95McuhBCNOOxAT3AxyKLcwkhRBMeG9D9vc1U11lpsMoiQEIIAR4c0E9dhk566UIIAR4c0P19ZAldIYRoymMDur2HLrNFhRDC4LEBXS5yIYQQzXlsQLdfhk566EIIYfDYgC49dCGEaM5jA3pjD12qXIQQAvDggC7XFRVCiOY8OKBLD10IIZry4IAuOXQhhGjKYwO6j8WE2aRkpqgQQth4bEBXSuHvbaZCcuhCCAF4cEAHY7ao9NCFEMLg0QHd38dMheTQhRAC8PCAHuBtoVJmigohBODhAd3fW3roQghh59EBXa5aJIQQp3h0QPf3NstMUSGEsPHogB7gbZGZokIIYePRAd3fR3roQghh59kB3dtMRW09WsuFooUQwsMDugWrhpp6a283RQghep1HB/QAWaBLCCEaeXRA95fL0AkhRCOPDugBtjXRpYcuhBAeHtD9fYyUi5QuCiGEhwf0xh66lC4KIYRnB3T7VYukhy6EEB4e0AN87Dl0CehCCOHZAd3eQ5eUixBCuBbQlVKLlFIpSqlUpdSjbex3pVJKK6Wmu6+JzvlLD10IIRq1G9CVUmZgGXAhMBa4Vik11sF+QcDPgK3ubqQzfl7SQxdCCDtXeugzgVStdZrWuhZ4B1jiYL8ngD8D1W5sX5vMJoWvl0l66EIIgWsBPRZIb3I7w7atkVJqChCvtf6srSdSSt2ulEpSSiXl5eV1uLGOGBeKlh66EEK4EtCVg22NyxsqpUzAs8Av2nsirfVLWuvpWuvpUVFRrreyDf4+ZgnoQgiBawE9A4hvcjsOyGpyOwgYD6xVSh0DZgMre2pgNMDbImu5CCEErgX0bcAIpVSiUsobWAqstN+ptS7RWkdqrRO01gnAFuBSrXVSt7S4BX9v6aELIQS4ENC11vXAvcBq4ADwntZ6n1LqcaXUpd3dwPYE+Mhl6IQQAsDiyk5a61XAqhbbfutk3wVdb5br/L3N5JbW9ORLCiHEacmjZ4qCXChaCCHsPD6gS5WLEEIYPD6gS5WLEEIYPD6g+3mbqam3Ut8gF4oWQvRvHh/QGy9yUSdpFyFE/+bxAd1+GTq5apEQor/z+IB+6kLRkkcXQvRvHh/Q7Zehk0oXIUR/5/EB3X4ZOql0EUL0dx4f0KWHLoQQBo8P6I09dMmhCyH6OY8P6I09dKlyEUL0cx4f0O1VLtJDF0L0dx4f0Bvr0CWHLoTo5zw+oHubTVhMSqpchBD9nscHdKUUfnLVIiGE8PyADrLiohBCQB8J6P4+ZlmcSwjR7/WJgB7gbaFSeuhCiH6uTwR0f28zFZJDF0L0c30ioAf4WDq12uLyrcf5en9ON7RICCF6Xp8I6P7e5g7PFK2tt/LU5wd4ddPRbmqVEEL0rD4R0AO8LR2eKbrzRBGVtQ1kFlV1U6uEEKJn9YmA7u/T8R7694fzAcgqrsZq1d3RLCGE6FF9IqDbe+haux6Yv081Anptg5X8ipruapoQQvSYPhHQ/X3MWDXU1Ftd2r+kso49GcVMiA0BkLSLEKJP6BsB3ctYoMvV2aKbjuRj1XD1jHjASLsIIYSn6xsB3cd+oWjX8ujfp+YT6GNh8YRoADKLK7utbUII0VP6REDv6JroGw7nM3toOGEB3gT5WiTlIoToE/pEQO/ImugnCio5UVjJvOGRAMSG+pEpKRchRB/QJwK6vYfuSuni96l5AMwbEQXYA7r00IUQnq9PBHT7dUVdSblsOJxPdIgvw6ICAIgJ9SNLAroQog/oEwE9oHFQtO2A3mDVbDpSwLzhkSilAIgN86Okqo5yWa1R9EO1Lpb6Cs/QNwK6vYfeTsplT2YJJVV1zBsR2bgtNtQPkFp00f/szSxh/O9WszezpLebItykTwR0fxd76BsOG/nzucNPBfQYW0CXtIvobzam5lPbYOXDHZm93RThJn0ioPt5udZD//5wPmOjg4kM9GncFhdmBPQMCeiin9lt65l/sfekrGfUR/SJgG42Kfy8zG320Ctq6tlxoogzm6RbAKICffAyK+mhi35nd0YxgT4WTpZUszO9uLebI9ygTwR0aP+qRT8cLaSuQTfLnwOYTIroED/JoYt+paiilvTCKm6eMwRvs4lVe072dpOEG7gU0JVSi5RSKUqpVKXUow7uv1MptUcplayU2qCUGuv+prbNWELXeQ/9+8P5eFtMzEgIb3Wf1KKL/maPLd0yd1gkZ46I5Is9knbpC9oN6EopM7AMuBAYC1zrIGC/pbWeoLWeDPwZeMbtLW2HsYSu8x76htQ8ZiaE42vLtzclteiiv9mdYaRYxseFcPHEaLJKqknOkLSLp3Olhz4TSNVap2mta4F3gCVNd9Balza5GQD0+Fe9v7fzHHpOaTWHcspbpVvsYsP8yCmtpq5BanJ7S2puOX/84oD0EnvI7owShkYGEOzrxbljBxppl92SdvF0rgT0WCC9ye0M27ZmlFL3KKWOYPTQf+ae5rnOuFC04x76BtvVieYNdxLQQ32xasgukTVdesuHOzL497o00vLLe7sp/cKezBImxBnXAwj29TLSLnuzO3SRGHH6cSWgKwfbWv3VtdbLtNbDgEeAXzt8IqVuV0olKaWS8vLyOtbSdrR1oegNqflEBHgzNjrY4f2xof4AkkfvRYdzjUC+N7O0nT1FV+WWVXOypJqJcaGN2y6aEE1mcRXJUu3i0VwJ6BlAfJPbcUBWG/u/A1zm6A6t9Uta6+la6+lRUVGut9IFzi4UXVtvZUNqPnOGR2IyOfpugphQX0Bmi/amI40BXWYtdrc9GcbveKKthw5w7tiBeJmVVLt4OFcC+jZghFIqUSnlDSwFVjbdQSk1osnNi4HD7muia/x9zA5TLn/4dB95ZTVcPqVVlqiRzBbtXTX1DRwvNC4ysjfL9YD+5d6T5JZKmqyjdmeUYFIwLubUGWuInxdnjohi1R5Ju3iydgO61roeuBdYDRwA3tNa71NKPa6UutS2271KqX1KqWTg58DN3dZiJwK8La0uQbd863GWbz3BXQuGsXD0AKeP9fUyExnoIymXXnIsv5IGqyY8wJt9maUuDYzmldVw55s7eGrVgR5oYd+yJ7OEEQOC8LctO20naRfP51IdutZ6ldZ6pNZ6mNb6Kdu232qtV9p+vl9rPU5rPVlrvVBrva87G+2Iv7eFmnor9bZKlR+OFvK7T/axcFQUD50/qt3Hx4b6SkDvJam2dMviidGU1dSTXtT+JQF3nCgCYNWek+SWSS/dVVprdmcUNw6INnWepF08Xp+ZKRpgv2pRXQOZxVXc9eZ2Bof7849rp2B2kjtvKjZMJhf1lsO5ZSgFl06KAVwbGN1xvAiLSVHXoHl7a3q7+wvDyZJq8strm+XP7U6XtMtbW09wJE+qnTqjzwR0++ljQXktd7yRRG29lZdumk6wr5dLj48JMSYXSf7QddV1DSxZtpFnvz7Upfrx1Nxy4sL8mBgXipdZuZRH33GiiIlxIcwfGcXyrcdlXW8X7bYNiE6IbR3Q4VTaZVdGxwanK2vrKayo7XL7Sqvr+OVHe3jw3WSZk9AJfSigGz30h97fxb6sUv5x7WSGDwh0+fGxYX5U11nd8qbsLw6cLGVXejH/+PYwdy3f3moMw1WpueUMjwrE22Ji1KCgditdauut7MooYdqQMG6eM4TcshpW78vu1Gv3N7szirGYFGOclPB2Nu3y+Kf7ueSfGxpTnp2Vlldha2cJH+2UZX07qs8F9O3Hi3j4glGcPXpghx7feKGLfpx22ZiazxOf7Xf5LOVgdhkAt581lK/353DFC5tIL2w//91Ug1WTll/BiIFBAIyPCWFfVmmbbdiXVUJtvZWpg8NYMHIAg8P9eX3zsQ69bn+1J7OEUYOCHC6BAUbaZd7wSD7ffbJDZ6vbjhWSWVzFmpSuzS9Js6VaYkJ8+fPqg+1e40A012cCepAttbJ4YjR3zR/W4cf399LF5PRifvpaEv/ZcJRsF0sBU7LLCPA28+ii0bz245mcLKnm0n9tYPORApdfN72wktp6K8OjjLOpcbEhFFbUcrKNWbvbjxsDolOHhGEyKW46YwjbjhWxrwMlj93l+8N5rD/k3klzrkovrORQTpnT+40B0RKH+fOm7GmX3S6mXcpr6knLN3rW7/xwwvUGO5CWV4HZpHjmmsnklNbw4rq0dh/zt69SuPm/P0i6lD4U0KcnhPHnKyfylysnNV4vtCMaL3Rxmk4uKqmsY/nW43y++yS70ospKK9x2xv4WH4FP351W+Pg8f4s12ZrHjhZyshBQZhMijNHRPHxPXOJCPThxv9s5Y0tx116DvsM0eEDjYA+3lYb3VbaZeeJYuLC/BgYbEwIu2paPH5eZl7f5NprdhetNY+s2M1jH+7p8eCitebON7dzzb83U1pd53Cf9MIqSqrqms0QdeT8sYMwKfjuYK5Lr70/qxStYWx0MGtScru0hMbR/Ariw/yYPTSCSybF8NL6I212st7YfIx/fpfKukN5Hc7790V9JqB7mU1cPT0eP2/Hp5LtCfHzwt/bfFqmXE6WVHHli5v41Ud7ueetHSxZtpFpT37D2N+u5rxn1nH760mdbnd+eQ03/8/o3bx922yUgn0uBHStNQezyxg96FQuNjEygI/unsNZI6P4zcd7eXl9+70re8mifbxjTHQwZpNir5M2aK1JOl7I1MFhjdtC/L24bEosHydnUtSLYyAHTpaRVVJNZnFVj1dp7EwvZl9WKUWVdbzi5Pe+y7aaorMBUbsQfy9GDgxyuR7dvhTv40vGYdXwflLnq46O5JUz1Ha29siiUWgNf/7yoMN916bk8vtP93PmiEi8zSY+3dXWBPb+oc8E9K5SShF7Gi6jm5pbzhXPb+JkSTX/u3UGX9x/Ji/fNJ3fXTKW62YNZmhUAOsO5fHcNx2fnFtZW89PXt1Gdkk1r9w8gwlxISREBLiUusguraakqo4x0UHNtgf5evHyTdOZNiTMpUGt1NxyBgT5NFYj+XqZGR4VyD4nPfSskmpySmuYNiSs2fab5wyhpt7Ke10IJl317YGcxp/XdjGX3FFvbjlOgLeZc0YP4JUNR8krq2m1z57MksaB5/ZMGRxKcnqxS5Um+zJLGBDkw/SEcOYMi+DdpPROVahYrZpjBRUkRgYAEBfmz21nDuXj5Cx22uYd2KVkl3HvWzsZNTCIF2+YxvxRUXy2O6vfV8ZIQG/idKtFT04v5qoXN1HbYOWd22ezcNQAxkQHc97Ygdw6N5HfLB7Lv2+czuVT4/hkVyYllY5PtR2pb7By71s72ZNZwj+vndIYIMfGBLvUQ7cPiDbtoduZTYqzRkRxILu03Tal5pYxYmDzaqRxscFOSxd32PPng5sH9NGDgpmVGM4bW47T4KYPtdaaz3efpLqu7WvV2n1zMJfJ8aEMHxDIuh7MoxdV1PLZ7pNcPjWOXy8eS029lWVrUlvttzujmLHRwXiZ2//YT4kPo6SqjqMFFe3uuyezpLHXv3TmYDKKqth4JL/Dx5FVUkV1nZWhUQGN2+5aMIyoIB8ebzJYn1dWw49f3Ya/t5n/3DKdAB8Ll0yKIae0hm3HCl16rU1H8tlxoqhXz+i6gwT0JowLXZwesw7XH8rjupe3EOTrxYo75zC+jdPkG2YPprrOyvvbXeudaq359cd7+e5gLo8vGc/54wY13jcuJpiMoqp2A/HBk0ZAHzXQcW9vZmI4WkPScecfMK01R/IqGgdE7cbHhJBTWuNwBuj240X4eZkZHd36dW+ek0BGUZXLud/2bE4r4J63drhUQZNbVs2u9GLOHTOA+SOj2JpW2GMVGu9vT6e23soNs4eQGBnANTPiWb71OCcKTlUcWa2avZml7Q6I2k0ebOTZk0+0nXaprK3nSF554/vz/LEDCfX34p0fOn6mZC9ZHBp56v0Q4GPh4QtGsfNEMSt3ZVFd18BtrydRWFHLf26eQXSIMfZ17pgB+HmZ+XR3+2mXDYfzue7lrVz+/CamPPE1k/7wFUuWbeSBd3by928OcbLk9OnUdZQE9CZiQ/0orKjt9VKpT5Iz+clr2xgSEcCKO88gITKgzf3HxYQwbUgYy7eecOmU88V1abyzLZ17Fg7jhtlDWj0XwL6TbaddDmaXEhPiS4i/44lbUwaH4m028cNR5wE9u7Sa8pp6hrf4UrAHB0dnCjtOFDEpPsRhL/P8sQOJDvF1WwnjOlva5P2kjHYHOb87YHyJnDNmIAtGRVHbYGVLmuvVPp1ltWqWbz3BzITwxlTK/eeMwKQUz35zqHG/tPwKymvq282f2w2PCiTIx8LO9KI299ufVYpVn8rL+3qZuXxKHF/tz6agvHXapy32ksVhUc3f71dOjWNcTDB/+uIgD76bzK6MYv6+dHKz5Qv8vS2cM2YAq/Zkt1sL/+K6IwwI8uGlG6fxq4vGsHhiNIE+ZrYdK+If3x7mp68ldbmevrdIQG8ithdLF0sq6/h0VxYPvpvMA+8mM2VwGO/eMZsBtkqO9tw4ewhH8yvaPdXNKKrk2W8OsWjcIIdr3NhX4Guv0iUlu4zRTiangPHBnhQfwtY2AvrhHNuAaIse+lhbG1rm0atqG9ifVdoq3WJnMZu4ftZgvj+c3zjY2hVrU/LwNps4nFvebgnfNwdyiQ31Y/SgIGYkhOPnZe6RPPr3qfkcL6jk+tmDG7cNDPbl1rmJfJycyYGTxt9xT6bR026vwsXOZFJMig9lZzs9dHs1UtMzyGtnxlPXoPlwR8cmBqXlVxDoYyEqyKdVW367eCxZJdV8sTebxy4czQVNzirtLpkUQ2FFLZvaKJvdm1nChtR8fjwvkfPHDeK2s4by1I8msPyns9n46Nk8f91U9mWV8p8NRzvU9tOFBPQmYsPsk4u6P+2itWZvZgnL1qRy5QubmPLEV9z39k6+O5jLdTMH8/qPZ7q8bAHAhRMGERHgzRub2y7d+/OXKSjgt5eMdVjeGRnow8BgnzYDem29ldTccka3M7g2MzGcvZklTmeQtqxwsQv0sTA0MqDVmi67M4qpt+pWA6JNLZ05GG+ziTddLJt05mRJFSk5Zdwxfyi+XqY201nVdQ1sSM3jnDEDUErh62XmjGERrE3J6/byxTe3HCcy0JtF45sHuLvmDyPIx8JfVqcAxsxLPy9zh2ZPTxkcysHsMqrauFbvnszSxveM3YiBQUwbEsbb20506PjT8ioYGhXg8H05a2gEd8wfyn1nD+e2M4c6fPz8kVEE+VjarHZ5cd0RAn0sXDdrsMP7F40fxHljB/LsN4eapaw8hQT0JuyTi3riQhcPvb+bxf/cwF9Wp1BTb+WehcP54K457PjNeTz1owlOZ/I542Mxc82MeL45kON0YHfHiSJW7sri9rOGNh6rI+NsszWdOZJXTr1Vt1stMTMxgnqrdtrLO5xbTv1TA+QAACAASURBVKi/F5GB3q3bEBvSamB0u63SYYqTHjoYX0hnjYxkbUrX8uj2dMviiTEsGjeIlclZTgdHNx3Jp7rOyrljTs1OXjAqihOFlRzrxqCQWVzFtwdyuHp6PD6W5u+XEH8v7lownO8O5vLD0UJ2Z5QwPjbYpYXq7CbHh9Jg1Y1liY7szSxhQmxwqyB8zYx40vIqSDredsqmqbS8coa2kV587MIx/OL8UU7nmfh6mTl/3CC+3JdNTX3rv9WJgkpW7TnJ9bMGO+0sKaV4Ysl4LCYTv/yo5+cTdJUE9CYGBvlgNqluT7lU1tbz6a4sLpkUww+/OodP75vHL84fxbQhYR36wLV03azBaODtra1n62mteeKz/UQF+XBnOzNpx0YHk5pX7jSApdgqXJytB2I3bUgYJgU/HHV8CnzEtoaLow/oeNvgbHHlqSqEHceLGRoZQHhA6y+ApmYlRnCsoJKcLlz8Ym1KHtEhvowcGMhV0+Mpra7nq/05Dvf9en8uAd5mZg0Nb9y2YOQA2/O4Z4DWkXd+OIEGp73NW+YkMCDIh6e/OMC+rBImxLqWbrGbHG/s37Jk0K6qtoHDuWUOB+wXT4wmyMfC2y7OHK2srSerpLqxBr2zLpkUTVl1PesPtU49vrIhDbNJcevcxDafY1CIL48sGsWG1Hw+aCdt9N3BHP6y+qDbKqu6SgJ6ExaziUHB3b8u+uYjBdQ2WLlmejwDglzLkbsiLsyfc0YP4J1tJ1qtPvjp7pPsPFHMw+ePIsDH4uQZDONigmmw6sbA3dKB7FK8zabGemFnAn0sjI8NYYuTPHpqXnmrkkW7lgOjWmt2nChiahvpFjt7YO3soGRdg5WNqfnMHxmFUoozhkYQG+rHiu0ZrfbVWvPdwRzOGhnVrJc8OMKfxMiAbsuj19ZbefuHdM4eNYC4MH+H+/h5m7n/3BHsOFFMdZ2VSfGuDYjaRQT6MCTC3+kZ1oFsY0DUUUD397Zw6eQYVu05SUlV++W0R21LBwyNavs91Z65wyMJ8/dqlXYpKK/hvaR0fjQllkEh7X/mrp81hGlDwnjy8/3kOxjctVo1z359iB+/msSyNUf461cpXWq3u0hAbyE21K/bUy5rU/Lw9zYzI7H94NRRN8weQn55LV82WX2wuq6BP31xkLHRwVwxLa7d52isdHGSdjl4soxhAwJdqmeemRBOcnpxq95+QXkNhRW1DHPSIxvXYgmAYwWVFFbUtpk/txsbHUygj6XNAdm27DheRFlNPQtGGde9NZkUV0yN5fvDea1K2vZmlpJTWsM5Y1ovBjd/ZBRb0gpcrmPviK/2Z5NfXsMNZwxpc7+rp8eTEGEEfFcrXJqaEh/qdMao/W/j7HmXzjDKaVcmtz842hjQI7vWQ/cym7hwQjRf789pVq322ubjVNdZuf0sx/n3lkwmxdOXT6Cipp4nPtvf7L6y6jpuf2M7//j2MFdOi+Oa6fG8sPYIX5wGFwaRgN5Cd08u0lqz9lAuc4ZFtMp7usNZI6IYEuHPG5uPNW77z4ajZBZX8evFY1xK6cSH+xHka3E6Y/RgdiljXJhtCMZgVm29tVWViH1AdISTOvZQf2/iwvwalwBwNqHIEYvZxPSEsDZLJtuy7lAeFpNizvDIxm1XTItDa1pVbnxzIAeTgoWjWl/0fMGoKGrqu6d88Y3Nx4kP92P+iLYvtu5lNvHUjybwoymxJER0vPc7OT6U7NJqh7XZezJKCA/wJtpJj3dCXAjjYoJ5+4f0dnPR9hr09s76XHHJxBiq6hoa5yNU1tbz+uZjnDtmIMMHuPa+BeO9efeC4XySnMUaW+rsSF45ly3byJqUXP5w6Tj+cuVEHr9sHJPjQ3no/V0cbmNxtJ4gAb2FmFBfskuru60O9Wh+BemFVcwf2fYHsbNMJsUNs4zVBw+cLCW3rJrn16Ry3tiBzBkW2f4TYAwMjY12PGO0qKKWnNIahxN7HJmRYATglnn0w04qXJoaHxPSWLq4/UQRQT4WRrhYpTEzMZzU3HKHp8vtWZuSx9QhYc0GzoZEBDAzMZwV25vXpH97MIepg8OICPRp9Tyzh0bgYzG5fdbo4Zwyth4t5PpZQzC58AU9d3gkz14z2aV9W7IPQDtKu+zJLGF8bEibi+FdPT2e/SdLG3vgzqTllRMb6tfptZiampkYzoAgn8a0y3vb0imurOPO+a71zpu6e+Ewhg8I5Ncf7eXTXVlc9q+NFFfWsfyns7h5TgJKKXwsZl64YSp+3mbueGO708XReoIE9BZiQ/1psGpyHayF4Q72nOqCUc4vWt1VV06Lw8dilO4989Uhauqt/PKiMR16jnExIRzMLm012NPWlH9HQv29GT0oqFX6IzW3HH9vMzFt5DPHxwaTll9BWXUdO44XMcW2XK4rZiVGAHS4l55bWs3+k6WN6ZamrpoWx9H8isble0+WVLE3s9RhugWMqovZQyMaK2bc5c0tx/E2m7jKhfRZV42JDsbbYmqVdqmua+BwbjkTYtt+H9g7LhvbWVI5Lb/CLb1zMJaeuHhiNGtS8iiqqOXl748yfUgY0xPC239wCz4WM3+8fAKZxVXc9/ZOEiIDWHnfPGYPjWi2X3SIH8uum8qJwkp+8d6uXltTRgJ6C6dq0bsn7bL2UB5DowKID3c8kOUOYQHeXDIphg92ZPBuUjo3nZHQ4Q/LuJhgquusHM1vPkHnYLbRa2+vBr2pmYnhbD9e1Oys50heOcMHOK5waWyDLTe77VghKTllTB3sepXGxLgQ/LzMHQ7o9t60ozOoiyZE4+9t5v0kY3D0W9vs0HPHOP9yXjAqirT8CrfVNJdU1fHBjkwunhjt8KzA3bwtJsbHBLeqdDmYXUaDVbeblx8S4U9sqB+bUp1PeNNaN9agu8slk2Korbfy4HvJZBZXcUcnrpFgNyMhnP9bNIpb5iTw/p1nNE5AbGnW0Ah+dfEYvt6f43AtneLKWlbaJg+6uuZMR0lAbyE21OgxdsfAaFVtA1vSChpL2rrTjbOHUF1nJcTPi/vPGdHhx4+z9bxapl1SsssID/BuNZuvLTMTw6msbWi2JO7hnPJWM0RbGm8bnH1zywm0xqUBUTsvs4lpQ8I6nL9eeyiPAUE+jHVQkhngY+GiCdF8tjuLytp6vj2Qw5AI/zbTRvYvhnWH3FO++MbmY5TX1DudXNMdpgwOY3dGCXVNvpDtten2AXRnlFLMGRbB5rQCp73WvLIaymvq26xB73Cb40OJDfVjbUoew6ICOGd01z5zdy8Yzu8vHdfu/JBb5iRw2eQYnvnmEGsO5nIwu5Tn16Zy1YubmPrE1/zs7Z2sO5TXbaXREtBbiOnGS9FtSSugtt7q8HTe3SbFh3LzGUN48rLxTtdbacsw2zU+Wwb0A9lljB4U1KGLiMy0nera8+hl1XVkl1Y3XtTCmaggYwbimpRclDpVF+2qWYnhpOSUNatlb0t9g5UNh0+VKzpy1bQ4Kmob+HBHJhuPFHDO6IFt/i4SIwMYHO7vlvLFqtoG/rvxGAtHRTUuj9ATpgwOpabe2rggG8DejBJC/b0aLwzTlrnDIymurGP/ScdVU0fsi3J1sQa9KaUUl0yKAeCOs4Z1avygs6/7x8snMnpQMLe+uo1Ff/+eP3+ZQmVtA/csHM6Hd89h26/OZcnk2G55/bYLkvshf28LYf5eHQroDVZNeXV9u4Fz3aE8fL1MzEzseC6vM/6wZHynH+tlNjFqYFCzSpcGq+ZQdhnXznQ8kcWZAcG+JEYG8MPRQm4/a9ipKf8ufIDHx4Tw7cFcRg8KarzMoKvsKz7+cLSw2YqSzuzKKKakqo75bXzhzkwMZ3C4P3/64iC19dY20y1gfMAXjIri/aQMqusaOjwDuKl3t52gsKKWuxYM7/RzdIZ9YDQ5vahxQay9WcaSua58sc8ZZuSbN6TmO6xZT7Ol9dyZcgH48bwEfCwmLpvSPcHTGT9vMy/dOI1la1KZFB/KwlEDXKp9dwcJ6A7Ehp260IXVqsmvqCG7pJrskmpOllSTVVJFVnE1J4uryCquIqeshgarZtl1U7l4YrTT512bkssZQyO69KHuSeNigvlyXzZaa5RSnCispKquoUP5c7tZieGs2nMSq1U7XcPFYRtijYDuyoSilibFh+JtMbkc0Nel5GFScOZw5wFdKcWV0+J45utDBPlamOHCl/P8kVG8vvk4SceKmDfCtUqjluoarI2Dez3VIbCLCfElKsiHnSeKufEMqKlv4FBOGT+Z51raZ0CwLyMGBLIxNd/hLOW0vAp8vUzEhLTf2++IAUG+PHjeSLc+p6viw/15+oqJPf66EtAdiAnxY/3hPOY+/R05pdXUt8j9eZtNDArxJSbUl9lDI4gJ9eOr/dk89fl+zhkzwGHAPpZfwbGCynanHZ9OxsUE8862dLJKqokN9SPFPiDqYsliUzMTw3lnWzopOWWk5pXjbTYx2IWBYfs1Rqe5UH/ekq+XmSnxoS5PMFp7KI8pg8PaPdO6Ylocz35ziPkjo1yaXHXGsAi8zSbWpuR2OqCvTM4is7iKJy4b16nHd4VSiinxoey0VbqkZJdR19D+gGhTc4dH8s62E9TUN7Saf5GWV05CRECPpUX6MgnoDlw+NZbK2gYGBPswKNiX6BBfBgb7Eh3ix8AQHyIDfFq9+eaNiGTpS1t45fs07j279SCkfU2Pnsifu8tY24DX/qxSYkP9OHCyDJOCER2YnGFn71X+cLSQ1JxyEiMDsLgQDM8aGcUvzhvZajVBV80aGsG/vjtMaXVdm6tX5pfXsDujhF+40KOLDfXjheunMjbatYDm721h1tBwvtyXzdUz4hnpZDKVM1ar5oV1Rxg9KIiF3Vju2pYpg8P4an8ORRW1jQOiHQnoc4ZF8OqmY+w8Udyq5O9ofkW7g6vCNRLQHVg0PppF452nThyZPTSCC8YN5Pm1R7h6enyrdczXHsojMTKAIZ2YrddbxkQH2S4aXcJ5YwdyMLuUhMiATk3+iAszytd+OFpIapMr3LTH18vMfZ2o0rGblRjOc9q40lFbwfD7wx2bH9DR98ctcxK4962dnP/ses4dM5C7FgxzuWrn6wM5pOaW84+lkzs0GO1O9gHp5Ixi9maWEuxrIT7c9RTJrKERmBRsSs1vFtBr662kF1U1DmCKrpEqFzd67MIx1DVYG9egtquuM8oVu2t2aHfx9zbWJbdXuqTYKlw6a2ZiOJuO5HOisNKlAVF3mDo4DC+zYmta22mXtSl5RAZ6N64h427njBnIpkfP5oFzR5B0vJArXtjENf/ezNqU3DanxWuteX7tEQaH+3PxhI59ibjTxLgQTMqYMbrXhRmiLYX4eTEhLrTVBKMThRU0WLXbB0T7KwnobpQQGcCtcxNZsSOjceEigK1HC6mus7ZZPXG6GhcTwv6sUipq6jleWOnyDFFHZiaGU1RZh9Y4XWXR3fy8zUyMC2WrkyV8wajeWX8oj7NGRHVrHjcswJsHzh3JpkfP5jeLx3KisJJb/reNi5/bwEYnE282HylgV3oxd8wf6lKKqrsE+FgYNSiYbUcLScku69RCX3OHRbArvZjyJhc8OeLgOqKi8ySgu9m9Zw8nzN+bJ5pcpXxtSi4+FhNntMgdeoKxMcFkFlfxw7FCtO7YDNGWmlZndOTKOV01KzGcPRklTq8VuyujmKLKtssV3cnf28JP5iWy7uGF/OXKiZTV1HH9K1u5440k0gubzyh9fu0RooJ8uGJq90/zb8+UwaFsTjOWfnY1ZdbU3OGR1Ft1s3V9Ghflkh66W0hAd7NgXy8ePG8kW48Wstq2hO26lDxme1C5YlP2FIR9lcGu9NCHRgYQGeiDSblnVT1XzUwMp96q2XG89QJTJVV1PPrBboJ8LD2eEvO2mLhqejxfPzifhy8YxfpD+ZzzzDr+9lUKlbX17M4oZkNqPj+Zl3havHeaTuzqTECfNiQMH4uJjalNA3o5kYE+HbrconBOAno3uHZGPCMHBvL/Vh0kNbeMtPwKj6puacpeffDVvmwCvM0uzQx0RinF/JFRjB4U3C1LBzszPSEcs0m1SrvU1Ddw5xvbOZpfwYs3TiPUv+0rIXUXXy8z9ywczpqHFnDR+EH887tUzvnbOn798V6CfS1c7+SKRD3NvpZOkI+FIZ1Yi8jXy8z0hLBm6aW0fPeu4dLfSUDvBhaziV9fbORI731rJ+B4sSdPYF/vuqbeyqhBQV3OMT952Xjevm22m1rnmkAfC+NjgpsNjGqteWTFbjanFfCnKyYyd3jn6sPdaVCIL39fOoUVd55BRKA3uzNKuOmMhA7PkO0uQyMDCfK1MC42uNPvgznDIjmYXda4rHFaXjnDJKC7jQT0bnLWyCgWjoriYHYZg8P9ezTF4G72tMvodq4h6go/b3On1pbpqllDI5pdOemvX6XwcXIWD50/kstPg/x0U9MTwvnknnm8ddssftaFkk13M5kUT142ngfO7fzsS/sX56YjBRRV1FJUWScDom4kAb0b/erisVhMirNHD+i1+mF3sE8w6sqAaG+bmRBObYOV5PRi3tp6gmVrjnDtzHjuWdiz66K4ymxSzBkWibfl9PqILpkc22piUEdMiA0hyNfCptT8blvDpT+TiUXdaPiAQFbeO4+4DkzAOB1NsQ2GdaZU7XQxIzEcpeCf3x1m85ECFo6K4okl4z36i9YTmU2K2UMj2Hgkv3F9HneustjfnV5f/33Q2Jhgjx/BXzAqik/umdu46p4nCvHzYsygYDamFjAuJoR/XTe1V+u6+7O5wyJIL6xi/aE8vMyK+C4MtIvmpIcu2qWUYlIH1yI/HV04fhDVdQ3855bpBPjIW7+32PPoq/dlMzjcX75Y3cil36RSapFSKkUplaqUetTB/T9XSu1XSu1WSn2rlBri/qYK0TX3nTOCb38xnwFBPbM2tXBs+IBABgT5UNegJd3iZu0GdKWUGVgGXAiMBa5VSo1tsdtOYLrWeiKwAvizuxsqhDtIzryLKguhtqJLT2G/LB3IgKi7udJDnwmkaq3TtNa1wDvAkqY7aK3XaK3tc5a3AKdXHZgQwj0+vR/ev6XLTzPHlnYZJiWLbuVKQI8F0pvczrBtc+YnwBeO7lBK3a6USlJKJeXldf0ai0KIHhY0CA5/1eVe+vljB7Jo3CDO8tAJd6crVwK6o3NUh+t9KqVuAKYDf3F0v9b6Ja31dK319Kgo+UMK4THSt8GeFTDmEuN26jdderpQf29evHFaj11rs79wJaBnAPFNbscBWS13UkqdC/wKuFRrXeOe5jlx4FOocL4cqhDCjeprYeV98PXvIGYK+EcYn0Fx2nEloG8DRiilEpVS3sBSYGXTHZRSU4B/YwTzXPc3s4nidFjxY/j8QWjjwgBdsusdSP+he55bCE+z6TnIOwAX/xV8gmDURXBoNdR3b79NdFy7AV1rXQ/cC6wGDgDvaa33KaUeV0pdatvtL0Ag8L5SKlkptdLJ03VdaDwseAz2f2KcArpbQz2sehh2vgnWBvc/vxCepOAIrPszjF0Coy40to25FOqrIWdv77ZNtKLauvxVd5o+fbpOSkrq3IOtDfDfRZCfAndvgWA3Xo8wIwleOcfWyJ/A4mfc99yi51QWgl8YSJli52kNr18KWbvg3h+MAVGAhjqoqwLf7rlcn2ibUmq71nq6o/s8c4qWyQw/etF4Y31yr3tTL2lrjf8Hz4GUVd2X1hHdo6IA8lLgucmw+93ebo1nq8iHshw493engjmA2csI5g11chZ7mvHMgA4QMQzOexyKjkK5G9P2aWth4ASYeiOUnYSTye57btG9ik/APybB8Y0QNRq+fBTKpTy20wKj4M4NMO3W1vdl7YS/jjB+1+K04bkBHYyUyJ0bIWige56vthLSt8LQ+TDifFAmSHFYUi9ON1obYx+6AYafC5f+06iV/uL/ertlnmnTPyE/FSzeYHIQJiJHQl21VLucZjw7oJtM4O1v9My+/GXXT/+0FS74fzDhSgiIhPhZRtpFnP4OfAqHvoSFv4TQwRA1Cs76P9j3IRyUv2GHbP03fPVr2P2O8328A2D4OXDgM7Bae65tnqKhHra8CHmHevRlPTug253YAluWGb2KrvAJhJm3GbW2YIzqV5dATVnbj7Na4fDXXZ4916sa6qEks7db0TnVpUZPfOAEmHXXqe1z74eB4437Gup6r32eZPd7xu9r9GKY32odvubGXAplWZC53fk+WkNZtnvb2F3yD8PmZbDv466XZJotUF8Fy2YYBRzJbxsZgG7WN9YQnXAVHFgJa54ybs/4qRGcO2rrvyF+5qmAPvtumPOz9isl6qtg87+M17/xY/DzkKVmi09A6rfGrL+j643T6Nu+NT6E9dXg1c461VnJ8N0TMOtOGHGe8cGtq4TQBMen6d3l+78ar33NcuODZGfxNgbPrfXGQJ472AfJlYKvfwsHP4ewRAhLgPBE4+fYae5LA/akQ6vh47sg4Uy44j/Nf5eOjLwATF7GZy9+Ruv7tYbPfw6734eHDxvvp4Y69/0tukprqC42qqEyd8DLC0/d5xsK4y+HKTdC7FTXn7OuGg5+ZpzlT74eULDjdfj4TvjiEZh4FSz4JQR0/qpPbekbPXSlYPE/IGEefPM7+Pt4o468IyoLjV/4odWntpm9jOeuLmn7sd4BxsBR9l54bbFRHXA6y9kH/5wOf58Anz1gBOZxlxk9WjC+2F5aaPRYHGmog7VPG+Wd6duM9BTAjjfguSnwxzh45Vz46jdwfJPR+3dFeR7kHoDCNCjNsq3sV9n+Kf2c++HylyFuWuv7Bk0wvqCtDcaktK4oPAqvL4Hk5cbtqDEwcByU5xgVNat/Ce9ce6pS6uDnsPwqIx2Y9F84udv11zq4Cp4/A9b/xfXfnzNat/87LD4B791snNEsfQu8XJiS7xdqjFdUFzu+f/My47hHLTKCeW0FPDMWPrwDjm049eVo/7+uCvZ+YKQqcg+6fnwdVXAEVv8K/j7x1EJj0ZNh8bPwwB644UOjg5L8Nux627i/phxKT7b9vA11sOJW+OAncHIXBA6AeQ/Afdvhls+N38OBT400cTfxzDr0tmQkGR+CiVfD+CuMwGDxBf/wth+3/xN47ya49UsYcsap7VteMKY8P5zquO52/ydGoJh1J6StgXdvMHK4N34MIW2tYdYJ9bVQmmEcT3CMUZ634e9QkWf0JiZeY5R0OlNdahyD1sYbOiTOyINGjmx+FpK2Flb8xOilL1lmBHu7nP1Gb+PkLphwNVz4p1O/2/xUo+ohZx9k74GMbWCtg/Ofgjn3GgHaZDFmGxamGbNx07fC9FshepJxLN/8rnW7p9xgtKOmHCpyIXyosb2hHmrLjB5Wez74qZEauHNjxz9QDfWw9QX47injS/7CP8Pka5vvozVUFRlBPyzB6IHtWQEbnoWCVON3CTDucqM6KzS+1cs0Ksk0yi59Q43jjZtpnGlEDOtYm9O3GIP6Katg9MVw/pNG0DFZHJ917njdmAVq/4J2hdXq+Gzs4OfwzvXG2i9XvWbsU55nnMXu/QBqSiEo2viijZsB175lpDb/aFuo1WQxPlMLHjXeL12ltfHe3LzM+J2YLMZ7f9yPYNJSx4+pLjVSL4FRkPQ/o2pq5u0w78HW8cRqhY/ugD3vwUV/NVK3jtTXGmeOXdBWHXrfC+gtffBT4w941Wsw4lzn+332c6OX9cix5qeExzfB/y6Eq141/vhNNdTDv6Yb6Z07vjc+JMc2wlvXgH8Y3LbG8Yejrtq1HhAYb8T0rbDleWMASjcYPenzHjeC6ltLjTdI0TEjh3z+4zDs7NbPsftdIzd6zXJIPLP91y3JhPdvNoLyGffCub83UhfPjjfuv+TvpxZqcqa6FI58C7HTjQC29mlYb5s+XlVo7OMTDJf8w/hCyj9sfBHU1xgB0P7/sIVGwN+zwuj9RI02xjca6oxlGu5Y3/6X59H18Nolxgdy0Z9cTwll7zHWMcnaaQS7i//W8YlsVqvxRbxzOWz8B1z9mpGuaOn4JiO4mb2MHmzcTCOd8fnPjffazSshzuHn+JSTu2Dz83B4tfEFY/aGxPnGYH/USKODsu0VmHoTTLoWasuNM7Txl3fsmJodX4NR4htiC8ZZycZnJmq00TNt+QVaW2kbxP7C+PvHToVptxj35R4AL3/4/m/GF0zgQOO9Zp+l2lFaG5/L+hrjvWutN1KyM37asbRY0TFY+yejx+4bDPN+DrPuMM48tIbPfwFJ/4GzfwNnPdS5trqorYCO1rpX/k2bNk33iJz9Wj83TevnpmpdX+d8v+emav3mla23N9Rr/XSC1h/c1vq+HW9q/btgrQ981nx7xnatV/9aa6v11LaiE1pv+bfWry3R+v/FaV1TYWxffo3WH92tdeq3rduXvVfrf883XuOP8VqvekTrHW9onb2vRRsbtN79vtbPjjf23f76qfsqCrR+9yZj+38u0LrwqPPfQUt1NVp//rDx2E8fMLYdWat1eZ7rz9FU5k6tV/9K64/v0Trpf8ZxNDS4/viSTK03P6/1q4u1/n2Y0a7lVzf/Pbfls58bj3nxTK2PbnDtMa+cp/Wfhmq95wPXX6ctZTmnnufTB7Te9a7WVSVar7zfaNuWf7d+THGG1p/9Quu6auN2fa3xf1WJ1ilfGr/TfR8b246sNd6vH96h9b5PtK4ubf5cB7/Q+j+LjNf6Q7jWTw8xjq+quPPH9PZ1Wi+bfer29te1fnaC1qXZnX9OrbVOTzLe/wc+N267+vsvz9d674fG7/fvE0+9X7OSta6t7Fqbsvca77nfBWv919FaF6drvf5vxu2vfuOe90g7gCTtJK72/R46GD3bd683Ttun3ND6/pIMeHbcqdRASx/dZZy2Pnzk1EBRQ53RO/cNgdvXOR843fexcZqZbytfihhh9DbmPWg8duXPjLRNbRkEDDDSGyMuMM4mIhnFXAAAB4FJREFUKgrgjcuM3sukpUauvi31NUbOcvL1Ri8i6b9Gr7iyABb+yujZt5WScWbPCmOgLzyx44/tLlVFRo928Bntp9PstDaO5ZvfGz3mH6+GwbOb71N03BhknXaLccw5+41Zkq6+hqtqyuDVxcbENYufcSYy515Y+Ou2z97yUuCNy4387Mlko9TW7A1zH4Czf2X0lrVuf0Az7xDsfMM4c1n8jHGsnbXlRfjyEbhnm3EWAEY+vL1BdVdYrcZnSyljUb7qUuPvETjA6L0HDoBh5xjv943PGSmP7D3GY70DIfEsOO8JiBze9bY0dWyjkTq6+G/G+EPyW0Z6qAeWmujfKRcw3uAvLzQC5H1JYPFpfn9lIex53xgIsednm9q/Et670Th9TJhnbNvxBqy8F659x/npoLXBGESz1hv7jLoIIke03q+uyrhowJ4VxqCsbzD8/EDXqgHqqo0vKf9wY8AwZnLnn6uvqa2EvSuMCgaljFK9gePgh5eMwXRlgov+cioN0F2sVtj1Fuz7CM56uPWXiyP5h43T+4ZaoxolYZ5RmeWO4NlZ9g6RXzjM/ZnRWXG3hnpY/ZhRolyea4wbadu8k5/tND63XzxijN8kzjcmB8ZMOX0qatxIAjoYpXlvXgE3fGCMzHdETTn8+ywjjzzWtsDkB7cZve7b17r3W9le927PR3ZFRb6Rr275BSZOKTwK/5x6qqc79SYjP+ruAe2+7uWzjUHni/9m5Ke7m9VqjMOU5xqdpD4YuJ2RgA5GL73gSOtTL62NU+xRF8PAlte+buf5qorcfyouel5WslHZM+FK93yR9kcZSUY6aMr1vd2SPq+tgN43Jha5QikjmFutxoJe9hKwvBT47kkjf91eQK/IN3pyxSeMagMJ5n1DzGRJSXVV3PT2K3BEt+sbE4s64ov/Mya92KfzH11n/D90QduPqyiAv46EN35km1AjVzQSQpxe+l9An3StkXvb8oJxO22dMREkbEjbjwuIMGYd5uw1KgLiHEx1FkKIXtT/AnrcNCNfvumfRgrl2PfGqLgrRl1k/L/gMbkSjhDitNP/AjoYS6zWlBnrLtSUtp9usZt9F1zzZserZIQQogf0z4A+aLwx1fnoejjzIdcDum+wMd1deudCiNNQ/6lyaWnBL41Uy+Tr+lUNqxCi7+q/AT1yuPunAwshRC/qnykXIYTogySgCyFEHyEBXQgh+ggJ6EII0UdIQBdCiD5CAroQQvQREtCFEKKPkIAuhBB9hAR0IYToI3rtikVKqTzgeCcfHgnku7E5nqK/Hjf032OX4+5fXDnuIVrrKEd39FpA7wqlVJKzSzD1Zf31uKH/Hrscd//S1eOWlIsQQvQREtCFEKKP8NSA/lJvN6CX9Nfjhv577HLc/UuXjtsjc+hCCCFa89QeuhBCiBYkoAshRB/hcQFdKbVIKZWilEpVSj3a2+3pLkqp/yqlcpVSe5tsC1dKfa2UOmz7P6w329gdlFLxSqk1SqkDSql9Sqn7bdv79LErpXyVUj8opXbZjvsPtu2JSqmttuN+Vynl3dtt7Q5KKbNSaqdS6jPb7T5/3EqpY0qpPUqpZKVUkm1bl97nHhXQlVJmYBlwITAWuFYpNbZ3W9VtXgUWtdj2KPCt1noE8K3tdl9TD/xCaz0GmA3cY/sb9/VjrwHO1lpPAiYDi5RSs4E/Ac/ajrsI+EkvtrE73Q8caHK7vxz3Qq315Ca15116n3tUQAdmAqla6zStdS3wDrCkl9vULbTW64HCFpuXAK/Zfn4NuKxHG9UDtNYntdY7bD+XYXzIY+njx64N5babXrZ/GjgbWGHb3ueOG0ApFQdcDLxiu63oB8ftRJfe554W0GOB9Ca3M2zb+ouBWuuTYAQ+YEAvt6dbKaUSgCnAVvrBsdvSDslALvA1cAQo1lrX23bpq+/3vwP/B1httyPoH8etga+UUtuVUrfbtnXpfW5xcwO7m3KwTeou+yClVCDwAfCA1rrU6LT1bVrrBmCyUioU+AgY42i3nm1V91JKLQZytdbblVIL7Jsd7NqnjttmrtY6Syk1APhaKXWwq0/oaT30DCC+ye04IKuX2tIbcpRS0QC2/3N7uT3dQinlhRHMl2utP7Rt7hfHDqC1LgbWYowhhCql7B2vvvh+nwtcqpQ6hpFCPRujx97XjxutdZbt/1yML/CZdPF97mkBfRswwjYC7g0sBVb2cpt60krgZtvPNwOf9GJbuoUtf/of4IDW+pkmd/XpY1dKRdl65iil/IBzMcYP1gBX2nbrc8ettX5Max2ntU7A+Dx/p7W+nj5+3EqpAKVUkP1n4HxgL118n3vcTFGl1EUY3+Bm4L9a66d6uUndQin1NrAAYznNHOB3wMfAe8Bg4ARwlda65cCpR1NKzQO+B/ZwKqf6S4w8ep89dqXURIxBMDNGR+s9rfXjSqmhGD3XcGAncIPWuqb3Wtp9bCmXh7TWi/v6cduO7yPbTQvwltb6KaVUBF14n3tcQBdCCOGYp6VchBBCOCEBXQgh+ggJ6EII0UdIQBdCiD5CAroQQvQREtCFEKKPkIAuhBB9xP8HIMZYbkf6xY4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "pretrained_model=models.resnet18(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet18_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
    "minute.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.4662 Acc: 0.7459\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.7459\n",
      "val Loss: 0.2515 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2523 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9085 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1936 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9085 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1428 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9216 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2999 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1219 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2810 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1130 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1624 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1178 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2403 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1244 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1141 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2589 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1204 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1235 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1286 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3112 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1217 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1361 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1988 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1381 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1318 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1323 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2617 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1369 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2801 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2371 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2496 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2366 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2465 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1379 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1350 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1331 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2452 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1319 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1268 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3039 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1280 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2464 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1350 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1364 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1349 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1307 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2510 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1343 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3021 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1296 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2373 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1378 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1416 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1382 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1428 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1474 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2099 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1290 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1317 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1352 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2513 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1381 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2515 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1387 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1354 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2411 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1326 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2310 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1312 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1323 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2139 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1375 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2044 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1278 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2434 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1362 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1300 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1361 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2019 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1331 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2728 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1271 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2433 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1319 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1817 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1339 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2346 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1356 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1454 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2320 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1384 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1673 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1329 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1902 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1407 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2442 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1300 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2368 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2738 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2035 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1340 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2324 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1304 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1307 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1615 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1433 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1347 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1350 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1381 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2031 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1368 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2342 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1356 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2640 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1281 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1327 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1847 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2619 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1339 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1351 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1356 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2050 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1330 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2808 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1406 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2242 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1315 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2691 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1298 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2484 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1313 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2111 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1472 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2397 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1970 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2295 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1315 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2129 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2273 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1271 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2310 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1297 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1404 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2116 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1330 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1304 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1449 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1675 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1388 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2217 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1361 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2715 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2393 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1372 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2414 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1466 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2705 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1406 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2536 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1295 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2860 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1347 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1329 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1344 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2031 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2247 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2008 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1726 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1517 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2352 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1287 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1966 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1415 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1391 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2307 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1335 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2167 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1337 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2621 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1360 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1336 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2894 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1297 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1871 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1254 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2200 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2632 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2523 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2049 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1278 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3011 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1290 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2366 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1379 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2740 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1320 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2594 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1355 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1337 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2019 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1371 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2073 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1242 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1432 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1879 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1275 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1340 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2710 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1469 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3179 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1370 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2971 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1360 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2873 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1392 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2299 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1397 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1380 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2575 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1346 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1353 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2238 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2561 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1377 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2629 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1395 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2312 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1293 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2148 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1357 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2620 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1300 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3248 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1447 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2179 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1325 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2257 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2670 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1316 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2239 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1353 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1541 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2496 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1384 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1383 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2088 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1387 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1319 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2427 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1329 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2658 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1336 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2325 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1394 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1957 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1281 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1325 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2419 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1262 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1322 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1293 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2658 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1375 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2254 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1302 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2809 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1257 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1940 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1366 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2072 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1334 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1395 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1312 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1440 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2584 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1478 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2386 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2670 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1318 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1375 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2528 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1382 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2212 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2184 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2468 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1341 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2794 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1263 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1885 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1366 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2598 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2124 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1297 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2464 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1305 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2619 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1348 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1417 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2832 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2385 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1330 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1405 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2375 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1300 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1277 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1364 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2029 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1411 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1351 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2386 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1350 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2141 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2431 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1314 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1987 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1315 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2411 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1312 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2277 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1405 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2274 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2536 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1343 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2196 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2538 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1311 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2220 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1349 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2411 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1296 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2462 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1309 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2300 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1325 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2450 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1357 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2438 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1282 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1350 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2374 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2335 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2090 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1340 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2162 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1247 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2344 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1383 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1324 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2346 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1352 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2602 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2659 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1287 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2081 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1333 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1303 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2822 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1375 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1952 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1392 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1351 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2056 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1308 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2924 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1276 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2781 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1337 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2449 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1358 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2509 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1306 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2313 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1284 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1339 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1914 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1363 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1372 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2471 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2432 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1404 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2593 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1445 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2808 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1307 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1928 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1336 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1362 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2640 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1355 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2162 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1306 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2555 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2827 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1370 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1314 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2228 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1425 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2603 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2429 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1373 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2295 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1625 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1321 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2076 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1300 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1339 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1269 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2760 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2593 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2271 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2768 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2119 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1371 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2801 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1405 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1870 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1345 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2357 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1307 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2156 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1269 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2723 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1307 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1362 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2386 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1308 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2687 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1395 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2490 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2744 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1422 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2193 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1325 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1321 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2034 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1306 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2442 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1332 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1390 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1392 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2555 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1535 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1315 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1824 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1351 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2904 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1373 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2173 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2072 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1327 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1285 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1277 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1302 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1495 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2383 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1400 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1353 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1262 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1266 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1393 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1462 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2283 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1321 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1262 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2517 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1313 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1373 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2610 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1419 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2308 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2461 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1354 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1318 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2493 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2817 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1383 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1950 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1358 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1369 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2826 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2304 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2825 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2585 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1872 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2862 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1340 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2203 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2632 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1341 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1381 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2593 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1460 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2097 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1311 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2854 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2196 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1424 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1487 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2654 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1361 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1432 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2081 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1314 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2181 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1345 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2675 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1442 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2300 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1363 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1316 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1372 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1345 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2742 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1318 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1387 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1388 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2079 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1334 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1297 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1317 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2763 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1405 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2467 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1387 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1345 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1347 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2642 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1354 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2823 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1489 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1277 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2208 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1276 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1305 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2003 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1249 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1327 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2184 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1302 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2113 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1317 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2711 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1388 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2436 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1339 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2703 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1469 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3015 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1327 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2910 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8525\n",
      "val Loss: 0.1344 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2380 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1417 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1346 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1382 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2479 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2424 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2695 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1403 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1419 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2263 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1309 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1392 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2183 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2673 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1361 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2621 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1396 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2103 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1253 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2480 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1320 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1303 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2424 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1988 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1366 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2133 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2333 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1277 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2277 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1355 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1910 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1315 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2371 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1389 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2370 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1406 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2325 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1294 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1269 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1391 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1310 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2576 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1465 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2183 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1370 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2540 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1376 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2441 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1459 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2211 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1324 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1460 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2447 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1364 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1385 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1926 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1434 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2812 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1347 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1394 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1299 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2159 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1371 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2702 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1408 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2601 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1431 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2551 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1367 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2644 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1395 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1300 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1311 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2867 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1348 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2077 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1381 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2060 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1350 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2272 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1369 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2198 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1398 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2711 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1296 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1809 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1281 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1343 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2648 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1363 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1261 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1398 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1963 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1360 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1334 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2272 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2716 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1389 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1392 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2434 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1301 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1404 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2078 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1415 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2271 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1310 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2382 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1357 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2773 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1279 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2504 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1431 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1407 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1267 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2766 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1263 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2649 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1333 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1423 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1368 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2682 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1291 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2113 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1403 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2328 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1324 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2005 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1338 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2522 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1391 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2433 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1343 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1827 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1343 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1291 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2753 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2770 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1290 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1279 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1303 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1395 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1284 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2628 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1457 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2517 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1311 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2233 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1375 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2408 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1360 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2437 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1289 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1337 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2478 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1363 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2644 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1288 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2149 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1334 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1301 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2546 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1314 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1357 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1253 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2393 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1370 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1402 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2613 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1306 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2047 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1399 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2425 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1367 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2689 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1327 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1326 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3147 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1295 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 16m 37s\n",
      "Best val Acc: 0.973856\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "pretrained_model=models.resnet34(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet34_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5950 Acc: 0.6516\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6516\n",
      "val Loss: 0.2180 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3332 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8525\n",
      "val Loss: 0.2323 Acc: 0.8824\n",
      "val Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8824\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3136 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9216 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1263 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9216 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2099 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1317 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3190 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2829 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1340 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1994 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1881 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1505 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1516 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2147 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1553 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2272 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2044 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1544 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2218 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1521 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1432 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2114 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1435 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2674 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1561 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2093 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1710 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2249 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1555 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2274 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1492 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2058 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1569 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2460 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1458 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2487 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1434 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1710 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1425 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2224 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1528 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1679 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1497 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1543 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2371 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1547 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1518 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1552 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2761 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1483 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1634 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2061 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1471 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1443 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2439 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1578 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1605 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2143 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1647 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2178 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1452 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1943 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1464 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2356 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1592 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2133 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1751 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1902 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1508 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1447 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1571 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2102 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1593 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1650 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1473 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1585 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2305 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1668 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1786 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2153 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1593 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2726 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1437 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2416 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1578 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2193 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1471 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2259 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1482 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1559 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1883 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1538 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2346 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1696 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2223 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1422 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2474 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1588 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1518 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1476 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2236 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2708 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1576 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2654 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1579 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2567 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1572 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2308 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1505 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1843 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1578 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1564 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2287 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1509 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1589 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1532 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1425 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2833 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1443 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1570 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2320 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1894 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1925 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1646 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2194 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1446 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1776 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1688 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1441 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1606 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1993 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1654 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2393 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1539 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1611 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2075 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1506 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2729 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1492 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1862 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1452 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1749 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1545 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1550 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1481 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1935 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1472 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2075 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1488 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1895 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1475 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1436 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1848 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1576 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1498 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1492 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2542 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1510 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1654 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1891 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1509 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1960 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1526 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1483 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2335 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1630 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1680 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1528 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2441 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1594 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2039 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1542 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1977 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1421 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2559 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1547 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1836 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2084 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1416 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1595 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2314 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1427 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1919 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1435 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1467 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2913 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1558 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1524 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2071 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1567 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2256 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1555 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2237 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1582 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1795 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1541 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1732 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1489 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1439 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1578 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1831 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1523 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1582 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1481 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2404 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2344 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1833 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1489 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1606 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1427 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1812 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1526 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1985 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1612 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1531 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2413 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1546 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2576 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1488 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2275 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1563 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1920 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2712 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1474 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2133 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1565 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1562 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1705 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1536 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1609 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1479 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2724 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1520 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2006 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1594 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1708 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1563 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2359 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1444 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2598 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1538 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2048 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2422 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1667 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1582 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1489 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2282 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1490 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1489 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2175 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1448 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1784 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1474 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1391 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2409 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1671 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1465 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1733 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1559 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2326 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1531 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2450 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1951 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1676 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2115 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2236 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1494 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2399 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1588 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2290 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1509 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1977 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2331 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1525 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2460 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1561 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1534 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1698 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2826 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1586 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2858 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1572 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2020 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1585 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2283 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1565 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1576 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2274 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1528 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2529 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1551 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2281 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1459 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2976 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2473 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1530 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2417 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1526 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2080 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1510 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2131 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1520 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1523 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2111 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1483 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2113 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1398 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2242 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1514 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2528 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1686 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2710 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1595 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1518 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2222 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1640 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2343 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1532 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2198 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1406 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1917 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2687 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1510 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2417 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1505 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1511 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1492 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1613 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2208 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1581 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1958 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1563 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2300 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1584 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1825 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2112 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1828 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2432 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1443 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1842 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1436 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1586 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2427 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1598 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2178 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2047 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1468 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1467 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2329 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1458 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1561 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2034 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1532 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1424 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1607 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2691 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1640 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2084 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1660 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2045 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2305 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1446 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2153 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1534 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1469 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1726 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1471 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2395 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1520 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1530 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1916 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1500 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1477 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2483 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1622 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1918 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1529 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2404 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1663 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1563 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1571 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2126 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1584 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1554 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2119 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1538 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1797 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1559 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1710 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1478 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1552 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1456 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1639 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1763 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2238 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1472 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1551 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1858 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2112 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1480 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2331 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1544 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2176 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1644 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2102 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1442 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2485 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1493 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1810 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1662 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2423 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1558 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2613 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1519 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2110 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1524 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2055 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1552 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1567 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2894 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1531 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2297 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1503 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1643 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1938 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1425 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1864 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1576 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1792 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1599 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2686 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1569 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1517 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1806 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1539 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2634 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1601 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1790 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1557 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2364 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1655 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2181 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1554 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1477 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2875 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1556 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1521 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2439 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1618 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2161 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1540 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1928 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1468 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1465 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1469 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2548 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1494 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2340 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1528 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1862 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1960 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1410 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2604 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1490 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2243 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1607 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2321 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1935 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1495 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2673 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1611 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1422 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1507 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1728 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1483 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1450 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1883 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2440 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1652 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2147 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1503 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1562 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2446 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1454 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2137 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1474 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2138 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2010 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1577 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1580 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1424 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2123 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1589 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2560 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1647 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1512 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2211 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1631 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2215 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1518 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2627 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1402 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1916 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2473 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1531 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3027 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1464 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1453 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2293 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1620 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1536 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1502 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2407 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1598 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1992 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1668 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1429 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1511 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1605 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1946 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1587 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2063 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1584 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2381 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1645 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2257 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1514 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1512 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1623 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1766 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1527 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2254 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2085 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1452 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1983 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1560 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1525 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1778 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1626 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2030 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1516 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1719 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1501 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2537 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1647 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1445 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1950 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1613 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1467 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2576 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1596 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1539 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2070 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1544 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1553 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1544 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1480 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2090 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1535 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1980 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1562 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1412 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2333 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1610 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1730 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1577 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2009 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2351 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1637 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2065 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1510 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2236 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1451 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1897 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1595 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2585 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1460 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2577 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1561 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2157 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1622 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1539 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1641 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1587 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2463 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1665 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2242 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1447 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2545 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1441 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2944 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1457 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1497 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2654 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1548 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1963 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1592 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2090 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1554 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1458 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1770 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1556 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1730 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1517 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1462 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1905 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1541 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2538 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1563 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1812 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1413 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1509 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1898 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1693 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1524 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1624 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1491 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1919 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2353 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1463 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1914 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1416 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2599 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1492 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2104 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1932 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1482 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1550 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2296 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1383 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1460 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2410 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1702 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1905 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1456 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1831 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1479 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2277 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1488 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2517 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1652 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1763 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1439 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2763 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1590 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1865 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1501 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2053 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1760 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1477 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1971 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1485 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1824 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1525 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2349 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1420 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1637 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1599 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1960 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1591 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1767 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1546 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1892 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2335 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1509 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1532 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2162 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1507 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2115 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1601 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2199 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1550 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2419 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1482 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2331 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1495 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1740 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1414 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2034 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1459 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1623 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1537 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2376 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1510 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1575 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2690 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2250 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1481 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2120 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1580 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1532 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1475 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1664 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1568 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2015 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2111 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1615 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2488 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2062 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1525 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1527 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1587 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2319 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1411 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1534 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1536 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2558 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1657 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2112 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1538 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1518 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2030 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2379 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1553 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1503 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1727 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1509 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1455 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1529 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2279 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1532 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2056 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1574 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1509 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 21m 19s\n",
      "Best val Acc: 0.960784\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "pretrained_model=models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet50_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.4926 Acc: 0.7623\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.7623\n",
      "val Loss: 0.2428 Acc: 0.8889\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.8889\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2482 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.8889 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1437 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.8889 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1321 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2523 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9016\n",
      "val Loss: 0.4081 Acc: 0.8431\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8431\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1908 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1302 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1668 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1674 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2201 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1772 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1758 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1295 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1719 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1214 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1610 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1404 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2476 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1441 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1314 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1404 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2494 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1250 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1948 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1517 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1393 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2235 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1448 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2622 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1667 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1816 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1806 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2439 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1433 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2306 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1967 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1425 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1936 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1679 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1385 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2352 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1430 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2130 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1714 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1459 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1786 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1438 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2218 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1619 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1918 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1445 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2432 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1460 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1945 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1480 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2312 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1369 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2388 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1519 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1674 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1432 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2447 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1467 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1928 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1591 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2129 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1555 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1492 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1316 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1827 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1475 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1697 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1426 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1489 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1772 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1452 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1616 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2184 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1351 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1729 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1445 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2240 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1516 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2095 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1416 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2265 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1375 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2521 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1535 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1610 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1796 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1507 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2186 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1603 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2247 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1432 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1961 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1487 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1502 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1494 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1456 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2216 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1433 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2325 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1740 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1871 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1471 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1370 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1783 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1733 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1452 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1642 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1853 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1762 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1517 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1471 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1702 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1440 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2144 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1482 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1867 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1337 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1446 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2080 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1401 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1801 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1915 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1804 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2345 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1459 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2197 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1462 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1581 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1383 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2005 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1629 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2099 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1495 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2089 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1440 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1719 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1333 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2682 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1425 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1506 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2244 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1605 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1870 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1563 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1929 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1316 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1578 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2045 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1370 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1557 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1715 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1475 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2016 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1598 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1649 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1764 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1869 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2253 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1439 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1378 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2307 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1377 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1858 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1550 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1398 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1309 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2271 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1327 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2877 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1505 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1886 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1508 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2385 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1587 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1614 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1600 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1682 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1392 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1422 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1561 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2070 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1590 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1349 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1558 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2007 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1712 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1488 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1700 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1526 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1403 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1834 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1671 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2050 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1401 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1397 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1990 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1415 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1990 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1838 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1435 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2453 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1460 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2421 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1526 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1429 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1690 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1994 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1462 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1354 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2680 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1529 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2514 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1388 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1913 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1606 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2171 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1536 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1513 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1438 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1471 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2008 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1431 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1640 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1483 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2611 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1432 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1770 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1430 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1718 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2017 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1637 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1443 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1752 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1451 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1549 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1961 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1482 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1405 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1621 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1659 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2278 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1566 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1479 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1338 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1844 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1622 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1405 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2074 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2161 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.2100 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2048 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2124 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1961 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1947 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1645 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1389 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1607 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2200 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1881 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1734 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1419 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2252 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1990 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2226 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2127 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1380 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1417 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1344 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1804 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1857 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1418 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1692 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1685 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1816 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1532 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1958 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1623 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2060 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1860 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1543 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1841 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1385 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1600 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1540 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1814 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1481 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2156 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1451 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2373 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1537 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1793 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1450 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1932 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1578 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1766 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1507 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2206 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1341 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1821 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1574 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1628 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2120 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1486 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2193 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1599 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2795 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1456 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2312 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1514 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2127 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1436 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1435 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2087 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1505 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1927 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1645 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1971 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1329 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2470 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1481 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2259 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2857 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1525 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1484 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1859 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1462 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1891 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1519 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2179 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1573 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1499 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1788 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1664 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1876 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1437 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2275 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1409 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2058 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1658 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1497 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1508 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1748 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1319 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2383 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2625 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1567 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1953 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1546 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2443 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1497 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1594 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2302 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2544 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1401 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1525 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1394 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1406 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1408 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1796 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1398 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1836 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1470 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1771 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1465 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1506 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2445 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1432 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2530 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1486 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1835 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1344 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1397 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1983 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1431 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2475 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1359 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2040 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1266 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1823 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1494 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1984 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1500 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2015 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1450 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2471 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1582 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1596 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2706 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1496 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2126 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1592 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1903 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1535 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2251 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2458 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1434 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1977 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1408 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1404 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1790 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1477 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2205 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1394 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2372 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1621 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1662 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1746 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1416 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2225 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1378 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2230 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1520 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1412 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1593 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1475 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2597 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1415 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1559 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1338 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2241 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1379 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2663 Acc: 0.8648\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8648\n",
      "val Loss: 0.1557 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2174 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1587 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1496 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1336 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2360 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2270 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1418 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2087 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1454 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1689 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1443 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1453 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1462 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1528 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2674 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1577 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1321 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1984 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1531 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2168 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1571 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1615 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2038 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2188 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1519 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2147 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1553 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1912 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1465 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1600 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1505 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2569 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1401 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1578 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2248 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1357 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2209 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1385 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2009 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1364 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2643 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1440 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2249 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1607 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1475 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1832 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1497 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1714 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1404 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1368 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1534 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2135 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1733 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2451 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1509 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1654 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1898 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1888 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1586 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2306 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1524 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1357 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2237 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1401 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1856 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2032 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1529 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1792 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1425 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1988 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1379 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1309 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2075 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1610 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2444 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1439 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1378 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1991 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1566 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2029 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1498 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2017 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1408 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1570 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1798 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1271 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2344 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1596 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2164 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1452 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1497 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1895 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1402 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2841 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1486 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2109 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1512 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1403 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2221 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1591 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1389 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1633 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1968 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1350 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2252 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1854 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1483 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1405 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2190 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1612 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1810 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1332 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2100 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1537 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2468 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1454 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2527 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1577 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1958 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.2021 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2134 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1316 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1540 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2418 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1462 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2987 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1730 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1934 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1681 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1805 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1805 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1482 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2492 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1512 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2559 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2234 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1916 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1646 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1467 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1803 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2141 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1487 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2605 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1645 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1458 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1860 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1650 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2005 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1483 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2035 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1493 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1574 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1817 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1376 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2110 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1365 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2534 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1635 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1752 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1601 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2085 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1421 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2154 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1358 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1963 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1406 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1538 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1490 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1612 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1458 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1750 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1462 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2128 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1460 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1819 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1452 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1848 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1636 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1817 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1543 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2202 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1393 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1852 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1519 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2204 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1580 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1327 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2499 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1466 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2013 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1541 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1778 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1498 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1511 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2210 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1520 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1702 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2036 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1329 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2445 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1705 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2310 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1739 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2104 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1522 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2062 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1391 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1873 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1579 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2406 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1694 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1887 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2151 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2146 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1515 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1320 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2209 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1468 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2778 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1444 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1591 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2316 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1361 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2713 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1389 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1781 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1429 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1840 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1437 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2054 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1338 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2167 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1648 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1850 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1533 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2412 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1583 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2077 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1441 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2131 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1477 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1444 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1627 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1569 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2017 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1436 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1931 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1318 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2185 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1397 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1734 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1318 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1990 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1539 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2339 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1369 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1600 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2481 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1285 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2189 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1466 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2074 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1498 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1417 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1584 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2035 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1472 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2457 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1482 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2098 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2058 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1297 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1437 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2192 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1438 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1849 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1362 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2725 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1831 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1466 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2231 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1442 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1751 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1478 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1892 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1476 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1491 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2229 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1740 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1880 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1461 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1720 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2063 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1414 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1463 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2665 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1386 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1446 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1987 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1573 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2316 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1444 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1698 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2420 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1388 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2002 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1439 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2336 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1507 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2149 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1483 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2293 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1528 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1986 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1704 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1636 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1485 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2015 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1651 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1561 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1991 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1486 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2285 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1357 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2136 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1471 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1706 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1471 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1595 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1823 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1541 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2183 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1590 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1952 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1546 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2148 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1691 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1936 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1386 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1783 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1453 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2288 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1545 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1551 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1977 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1441 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1465 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1337 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2323 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1603 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2025 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1503 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2611 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1699 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1953 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1507 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1865 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1583 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2584 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1423 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1955 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1335 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2296 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1572 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1463 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2149 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1430 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2296 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1710 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1484 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2301 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1498 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2531 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1555 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1518 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3073 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1479 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2171 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1807 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1780 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1432 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2190 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1451 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2483 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1434 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1465 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1745 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1418 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1296 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1678 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2687 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1354 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Training complete in 30m 58s\n",
      "Best val Acc: 0.960784\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet101(pretrained=True)\n",
    "pretrained_model=models.resnet101(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet101_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.5050 Acc: 0.7582\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.7582\n",
      "val Loss: 0.2230 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2926 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9085 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9085 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2219 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1655 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3053 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1062 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1115 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1703 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0929 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3375 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1822 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2567 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1147 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1718 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1085 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2220 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1136 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1957 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1177 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2187 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1206 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1688 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2434 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1144 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1233 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2045 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1176 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1700 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1171 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1737 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1247 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1712 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1170 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2309 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1211 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1767 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1222 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2324 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1758 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1207 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1725 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1282 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2355 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1195 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2644 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1197 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1856 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1264 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2002 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1583 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1233 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2158 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1326 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2469 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1254 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1746 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1228 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1688 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1215 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1886 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1211 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2145 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1176 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1220 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1162 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2474 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1222 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1855 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1191 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2291 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1227 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1632 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1151 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1819 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1264 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2366 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1175 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1219 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2280 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1224 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2689 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1197 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2170 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1250 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2026 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1303 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2011 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1213 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2010 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1248 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2370 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1236 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2237 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1178 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2102 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1208 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1255 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2213 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1253 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1238 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1633 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1270 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2212 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1209 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1994 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1253 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1878 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1249 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1227 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2084 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1267 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2246 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2117 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1168 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2167 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1181 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2541 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1246 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1256 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1802 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1202 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1685 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1256 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2088 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1412 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1215 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1864 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1311 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2125 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1220 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2268 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1332 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.3019 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1182 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2447 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1192 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2264 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1128 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2525 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1199 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1921 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1225 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2157 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1172 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1976 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1210 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2003 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1177 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1815 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1215 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1912 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1316 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1714 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1679 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1715 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1161 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2338 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1238 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2289 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1209 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2013 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1283 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2367 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1217 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1166 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2039 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1199 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2313 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1181 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1757 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1206 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1910 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1265 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1262 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1716 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2042 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1155 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1994 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1300 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2169 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1230 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2056 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1228 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1248 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1887 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1153 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2423 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1202 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1995 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1944 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1244 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1785 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1308 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2205 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1202 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1270 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2426 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1907 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1240 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2214 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1269 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1222 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2568 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1168 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2224 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2049 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1183 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2401 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1159 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2141 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1163 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2497 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1242 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2421 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1171 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2049 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1234 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1787 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1924 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1175 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1766 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1286 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1983 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1235 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2108 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1246 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2330 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1225 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2774 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1279 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1292 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1673 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1140 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2160 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1308 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2138 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1212 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2943 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8566\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1897 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1212 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2314 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1247 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1975 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1226 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2561 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1235 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2627 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1289 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2043 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1183 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1791 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1182 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1786 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1965 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1211 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1727 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1245 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2307 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1136 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1796 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1230 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2222 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1243 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1575 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1237 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1835 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1237 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1908 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2008 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1265 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2046 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1212 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2362 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1191 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1585 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1222 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2173 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1251 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2150 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1183 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1655 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1256 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1439 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1220 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1949 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1189 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1823 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1194 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1934 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1133 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1725 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1153 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1991 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1186 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1992 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1226 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1842 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1198 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2479 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1213 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2006 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1181 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2109 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1237 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1924 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1247 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2062 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1252 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1760 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1213 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1837 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1193 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2955 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1862 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1202 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2143 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1219 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1301 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1777 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2046 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2399 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1173 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1468 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1227 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1978 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1251 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2100 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1236 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1556 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1233 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1775 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1245 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2032 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1213 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1906 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1930 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1166 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1853 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1278 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1874 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1183 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2369 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1242 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2114 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1235 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2038 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1188 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2014 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1224 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1972 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1186 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1870 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1204 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1861 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1189 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2021 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1161 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2337 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1826 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1272 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2350 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1193 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1667 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1224 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1617 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1201 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2454 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1127 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2506 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1214 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1672 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1131 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1227 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2037 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1217 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1918 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1199 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1188 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1893 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1193 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2627 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1269 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1893 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1301 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2192 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1225 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2552 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1243 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1835 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1205 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1815 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1231 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1873 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1255 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1921 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1229 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2076 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1197 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1795 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1189 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2370 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1194 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2191 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1236 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2724 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1212 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1957 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1218 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1820 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1265 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2028 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1211 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2269 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1250 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2009 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1203 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1273 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1782 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1186 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1997 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1894 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1200 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1680 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1245 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1613 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1208 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1242 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1577 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1207 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1924 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1210 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1717 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1272 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1782 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1898 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1300 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2226 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1200 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1913 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1221 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2001 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1244 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1763 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1324 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1602 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1217 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1885 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1221 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1883 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1239 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2123 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1229 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1863 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1203 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2023 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2365 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1299 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2051 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2076 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1215 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2000 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1213 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2059 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1187 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1753 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1171 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1209 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2249 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1216 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2018 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1149 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1931 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1257 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2088 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1179 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1778 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1223 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1727 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1212 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2217 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1769 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1271 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1980 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2599 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1228 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1865 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1169 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1937 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1221 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1250 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1769 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2227 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1205 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1925 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2022 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1159 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2469 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1221 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1230 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2520 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1218 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2140 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2345 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1151 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1525 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1236 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2106 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1202 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1757 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1239 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2333 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2240 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1248 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1844 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1148 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2122 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1269 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2081 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1180 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1908 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1170 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1787 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1198 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2004 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1380 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2211 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1117 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2129 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1269 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1852 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1153 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1922 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1199 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1223 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1218 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2341 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1216 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2173 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1237 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1962 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1217 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1601 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1157 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2505 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1236 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2140 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1217 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2631 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1266 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2094 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2040 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1301 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1854 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1233 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1722 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1228 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1970 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1243 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1702 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2122 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1166 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2286 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1182 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2047 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1205 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2262 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2105 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1247 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2195 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1162 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1773 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1181 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1210 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1864 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1256 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2222 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1425 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2378 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1210 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2479 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1228 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1964 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1184 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2328 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1241 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1859 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1239 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1683 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1225 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1873 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1209 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2229 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1186 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2407 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1233 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2024 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1321 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2055 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1221 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2311 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1202 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2397 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1171 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1316 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1915 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1205 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1147 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1937 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1207 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2255 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1250 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2063 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1151 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1596 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1169 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1718 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1233 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1747 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2490 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1206 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1663 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1807 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1251 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1934 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1096 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2142 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1268 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2606 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1253 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2261 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1218 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1982 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1202 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1585 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1187 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2711 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1194 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2169 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1407 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2096 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2052 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1220 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1639 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1259 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2182 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1271 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2002 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1169 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1598 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1277 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1964 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1208 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1771 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1152 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2086 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1174 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2109 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1227 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1974 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1205 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1502 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1197 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2066 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1230 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2017 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1196 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1304 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2152 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1180 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1616 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1190 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1775 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1207 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2347 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1176 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1297 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2092 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1226 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1954 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1204 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2010 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1156 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1709 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1201 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2068 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1224 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2384 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1234 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1591 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1265 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1866 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1234 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1168 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1903 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1216 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2194 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1273 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1785 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1213 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2110 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1200 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2536 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1196 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1269 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1519 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1208 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1638 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1190 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1659 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1179 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2402 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1145 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1793 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1200 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1996 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1185 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1685 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1218 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1269 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1254 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1784 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1156 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2130 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1211 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1248 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1959 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1276 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1259 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1909 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1264 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2284 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1228 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1637 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1208 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2172 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1236 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1996 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1254 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2143 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1152 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1552 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1278 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2276 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2207 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1756 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1155 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2129 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1165 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2232 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1270 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1688 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1162 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1794 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1232 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2177 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1172 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2315 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1203 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1868 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1282 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2327 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1218 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2003 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1253 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1974 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1229 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1984 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1205 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2083 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1235 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1877 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1207 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2228 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1226 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2069 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1176 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1698 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1221 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2165 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1231 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1716 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1194 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2130 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1268 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2077 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1195 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2084 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1206 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2245 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1247 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1942 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1155 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1659 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1183 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1983 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1258 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2120 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1200 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1781 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1287 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2435 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1124 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1906 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1220 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1645 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1149 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1875 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1179 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1939 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1227 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2892 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1261 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1757 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1216 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2121 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1221 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1913 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1224 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1882 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1190 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1804 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1234 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2132 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1198 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1884 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2364 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1225 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1236 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2223 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1162 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1989 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1257 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2127 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1192 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2526 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1265 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1759 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1155 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2626 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1179 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1955 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1152 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1743 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1227 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1646 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1223 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1787 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1345 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1809 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1235 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2064 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1199 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1803 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1283 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2785 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1204 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1966 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1258 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1900 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1179 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2156 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1211 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2023 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1243 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2322 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1206 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2281 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1211 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1797 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1246 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1810 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1274 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2031 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1247 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1627 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1184 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2101 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1979 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1213 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2600 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1102 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2078 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1201 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2547 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1178 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1998 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1252 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1838 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1299 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2332 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1173 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1923 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1184 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1770 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1159 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2011 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1195 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.1695 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1195 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "model is training, goign to refresh its resnet memory\n",
      "alpha is 1\n",
      "skipping\n",
      "skipping\n",
      "train Loss: 0.2107 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1161 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Training complete in 41m 3s\n",
      "Best val Acc: 0.980392\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet152(pretrained=True)\n",
    "pretrained_model=models.resnet152(pretrained=True).to(device)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, pretrained_model,criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'alpha-1-cyclicweight_resnet152_lrscheduler_wholenetwork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
