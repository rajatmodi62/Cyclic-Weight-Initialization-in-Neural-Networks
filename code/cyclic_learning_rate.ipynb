{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "The problem we're going to solve today is to train a model to classify\n",
    "**ants** and **bees**. We have about 120 training images each for ants and bees.\n",
    "There are 75 validation images for each class. Usually, this is a very\n",
    "small dataset to generalize upon, if trained from scratch. Since we\n",
    "are using transfer learning, we should be able to generalize reasonably\n",
    "well.\n",
    "\n",
    "This dataset is a very small subset of imagenet.\n",
    "\n",
    "\n",
    "Its a cat bees dataset, constructing a transformation pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images\n",
    "^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's visualize a few training images so as to understand the data\n",
    "augmentations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Training Function , the scheduler is lr=0.001, decays by 0.1 every 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #print(inputs.size())\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            print('{} Rajat Best_Acc: {:.4f} Epoch_Acc: {:.4f}'.format(\n",
    "                phase, best_acc, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                \n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            #collect losses\n",
    "            if phase=='train':\n",
    "                train_losses.append(epoch_loss)\n",
    "            if phase=='val':\n",
    "                val_losses.append(epoch_loss)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,train_losses,val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the model predictions\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Generic function to display predictions for a few images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            print(\"modi\",inputs.size())\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def plot_losses(train_loss,val_loss):\n",
    "    df = pd.DataFrame(list(zip([i for i in range(0,len(train_losses))],train_loss,val_loss)), \n",
    "               columns =['epoch', 'train_loss','val_loss']) \n",
    "    list_data=[df.train_loss,df.val_loss]\n",
    "    plots=sns.lineplot(data=list_data)\n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_output(model,train_loss,val_loss,experiment_name):\n",
    "    model_dump_path=experiment_name+'.pt'\n",
    "    torch.save(model.state_dict(),model_dump_path)\n",
    "    csv_dump_path=experiment_name+'.csv'\n",
    "    df = pd.DataFrame(list(zip(train_loss,val_loss)), \n",
    "           columns =[ 'train_loss','val_loss'])\n",
    "    df.to_csv(csv_dump_path)\n",
    "    list_data=[df.train_loss,df.val_loss]\n",
    "    plot_dump_path=experiment_name+'.png'\n",
    "    plots=sns.lineplot(data=list_data)\n",
    "    fig=plots.get_figure()\n",
    "    fig.savefig(plot_dump_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E1. Train whole model, LR scheduler, 100 epochs, resnet18 \n",
    "----------------------------------------------------------------------------\n",
    "Resnet18, train the whole model\n",
    "\n",
    "Best val Acc: 0.960784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
    "minute.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5623 Acc: 0.6967\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6967\n",
      "val Loss: 0.2138 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.3042 Acc: 0.8566\n",
      "train Rajat Best_Acc: 0.9281 Epoch_Acc: 0.8566\n",
      "val Loss: 0.2095 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9281 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.2776 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9346 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1820 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9346 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1933 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9346 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1743 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9346 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.2324 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1126 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.2953 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1704 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.1908 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1717 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.1661 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1993 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.1633 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1768 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1936 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1851 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.1021 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9713\n",
      "val Loss: 0.2009 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1600 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1898 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.1803 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1647 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.1055 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1726 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.2088 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1721 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.0832 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1810 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1673 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1466 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1686 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1644 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1670 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.2001 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1948 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.1348 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1629 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.2153 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1729 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.2271 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1792 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.1369 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1589 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1840 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1586 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.1108 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1695 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.1158 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1739 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.1454 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1826 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.1324 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1800 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.1903 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1828 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.1771 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1647 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1368 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1850 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1551 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1562 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1670 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1675 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1905 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1827 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1674 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1617 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1764 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.0943 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1825 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.1427 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1796 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.2014 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1888 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1351 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1822 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.1043 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1815 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1760 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.1280 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1745 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.1243 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1759 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.1689 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1763 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.1509 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1709 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1585 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1744 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1189 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1697 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1346 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1629 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1259 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1592 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.1293 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1645 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1844 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1669 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.2138 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1805 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1657 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1669 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1398 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1676 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1283 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1787 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.2162 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1792 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1665 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1595 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1923 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1418 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1693 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1439 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.2002 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.1100 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.2089 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1383 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1728 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1173 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1683 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1349 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1725 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1718 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1863 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1944 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1652 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1644 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.1433 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1874 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.1262 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1609 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.1190 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1643 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.1150 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1693 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.1353 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1795 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.0878 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1693 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.0992 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1715 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.1824 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1998 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.2168 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1971 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1053 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1659 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.1492 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.2002 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.1714 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1733 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1697 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1703 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.1488 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1729 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.1383 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1623 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.0994 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1650 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1906 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1647 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1564 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1678 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0814 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1830 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1383 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1717 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.1910 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1961 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1616 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1718 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1728 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.1573 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1850 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.1362 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1993 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1619 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1558 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1773 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.1488 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1957 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.1268 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1689 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1066 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1757 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.1446 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1773 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1487 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1770 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.0949 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1697 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.1691 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1721 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.1740 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1618 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1804 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.1217 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1678 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.2216 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1687 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.1651 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1655 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1440 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1713 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.0994 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1659 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.1212 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1789 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1695 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1662 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.1523 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1785 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.1306 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1992 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.1445 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1834 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.1096 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1823 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.1852 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1731 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.1584 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1703 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.1267 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1671 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.2520 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1665 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.1309 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1689 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.1825 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1714 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.1961 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1745 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.1564 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1705 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.2212 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.1055 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1735 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.1491 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1709 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.2127 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1802 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.2060 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.1504 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1680 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.1037 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1862 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1905 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.1984 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1875 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.1438 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1727 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.1392 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1907 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.1764 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1963 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.1678 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1885 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.1375 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1654 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.1067 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.0940 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1619 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1749 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.1648 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1614 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.1897 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1649 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.1130 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1680 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.1504 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1736 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.1259 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1819 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.1814 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1641 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.0795 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1970 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.1561 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1665 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.1534 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1682 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1655 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.1821 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1540 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1484 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1823 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.2491 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.1158 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1642 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.1682 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1737 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.1748 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1965 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1737 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.1236 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1753 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.1573 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1781 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.1667 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1850 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1687 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.1992 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1819 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1987 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.2150 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1648 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.1256 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1766 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.1091 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1655 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.1106 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1754 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.2179 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1678 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.1436 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1789 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.1781 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1641 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.2147 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1636 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.1243 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1813 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.2002 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1972 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.1524 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1780 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.1893 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1696 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.0838 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1923 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.1585 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1777 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1655 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.0886 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1764 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.1238 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1857 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1625 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1488 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1818 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1673 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.1328 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1772 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1440 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1619 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.0954 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1877 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.2035 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1667 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.1520 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1657 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1688 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.1422 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.2175 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.1816 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.2140 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.1214 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1660 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.1765 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1760 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1681 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1647 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1706 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.1152 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1630 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.1892 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1867 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.1197 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1746 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1671 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1624 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.1593 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1721 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.0912 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1721 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1628 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.1292 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1596 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.1613 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1686 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.1144 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1755 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1927 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1721 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.1569 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1676 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1784 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.1338 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1701 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1633 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1925 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1124 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1685 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.1374 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1708 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.1176 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1707 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.1794 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1776 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.1835 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1692 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.1185 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1697 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.1791 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1667 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.1713 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1994 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1772 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.2346 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1661 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.1028 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1715 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.1249 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1748 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.1244 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1686 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.1118 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1705 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.1467 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1799 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1723 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.1826 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.2003 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.1079 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1777 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1480 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1767 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.2071 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1670 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.0718 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1801 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.1951 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1749 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.2126 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1702 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1718 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.1147 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1653 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.1776 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1905 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.1360 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1866 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.2068 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.2027 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.1133 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1948 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.1487 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1741 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.0884 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1813 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.1923 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1683 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.1026 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1630 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.0862 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1850 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.1223 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1701 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.1306 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1815 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.2050 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1879 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.1379 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1654 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.1374 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1700 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1846 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1646 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1668 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.1447 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1711 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.1853 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1729 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.1258 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1716 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.1197 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1758 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.2059 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.2190 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.2104 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1683 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.1494 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1818 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.1782 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1979 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.1275 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1672 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1666 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.1341 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1785 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.1169 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1832 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.1308 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1851 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.1145 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1645 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.1957 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1707 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.1712 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1834 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.1190 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1825 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.1472 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1648 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.1629 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1774 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1881 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1659 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.1297 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1754 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.1685 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1619 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.1417 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1616 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.1521 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1630 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.1252 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1698 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.1398 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1804 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1302 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1777 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.1359 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1688 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.1268 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1816 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.1749 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1636 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1655 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.1549 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1980 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1743 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.1349 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1773 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.1007 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1813 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.1378 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1661 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.0895 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1729 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.1687 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1711 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.1765 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1752 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.1221 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1662 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.0954 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1618 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1776 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.1803 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1884 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.1598 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1645 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.1855 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1709 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.1762 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1582 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.1472 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1798 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1731 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1736 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.1353 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1747 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.1519 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.1061 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1784 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.2251 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.1612 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1667 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.1274 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1717 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.0969 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1868 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1063 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1630 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1717 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1761 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.1762 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1678 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1687 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.1776 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.1434 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1680 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.0833 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1798 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.1507 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1744 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1720 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.1485 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1703 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.2185 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1692 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.1741 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1651 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.1884 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1836 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.1463 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1655 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.1254 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1651 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.1132 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1700 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.2052 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1637 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.1086 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.2024 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1306 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1946 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.1185 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.2032 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.1844 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1662 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1597 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.1620 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1626 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.1838 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1607 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.1803 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.2192 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.1139 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1733 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.0920 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1783 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.1567 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1856 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.1337 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1671 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.0857 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1668 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.0972 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1807 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.1158 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1729 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1293 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1776 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.1072 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1611 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.1414 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1946 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.1357 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1759 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.1718 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1683 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.0960 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1725 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1621 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.1851 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1678 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1871 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.1642 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1562 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1686 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.1834 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1563 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1821 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.1222 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1844 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.1529 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1837 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.1238 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1659 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1898 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1767 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.1996 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1681 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.1929 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1664 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.1721 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1739 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.1349 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1657 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.0997 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1794 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1583 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1641 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1695 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1999 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1655 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.1871 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1738 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.2363 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1602 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.1804 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1727 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.1658 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1629 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.1086 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1798 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1703 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.1843 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1732 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.1360 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1866 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.2120 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1791 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.1313 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1790 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.1262 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1712 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.1464 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.2071 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1740 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1672 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.1891 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1701 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.1362 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1662 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.1710 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1586 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.1054 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1827 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.2225 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1758 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.2111 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1640 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.1468 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1738 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.1328 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1641 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.1148 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1630 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1698 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1862 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.1001 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1734 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.1178 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1694 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1201 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1897 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.1346 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1867 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1744 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1704 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.1991 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1646 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.1477 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1609 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.1839 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1707 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.1414 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1905 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.1396 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1637 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.2040 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1707 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1788 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.1164 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1783 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.1553 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1841 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.1697 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1642 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1720 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1745 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.1350 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1775 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1742 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1657 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1765 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.1531 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1715 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.1208 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1763 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.0997 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.1640 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1918 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1212 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1779 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.1499 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1809 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.1334 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1719 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.0866 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1703 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.2041 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1846 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.1896 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1707 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.1501 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1659 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.2182 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1751 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.1811 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.2021 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.1337 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1763 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.1378 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1768 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.1449 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1862 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.1412 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1808 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1757 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1606 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1791 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1668 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.1755 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1826 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.1492 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1833 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.2037 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.1152 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1765 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.1538 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1956 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.2120 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.1573 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1719 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1652 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1509 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1758 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.2128 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.1079 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1833 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.0939 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1808 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.1167 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1681 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.1987 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1982 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1851 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.1180 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1709 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.1659 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1689 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.2206 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1906 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.0997 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1670 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.1396 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1724 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.1637 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1767 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1704 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.1374 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1744 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.1795 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1715 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.1854 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1654 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.1327 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1611 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.1690 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1686 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1268 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1733 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.1926 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1685 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.1940 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1692 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.1486 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1743 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.1879 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1602 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.1057 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1959 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1695 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.1286 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1623 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.1732 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1736 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.1557 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1620 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.1331 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1716 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.1343 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1653 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.1665 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1840 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1629 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.1810 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1722 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.1401 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1824 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.2156 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1564 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.1281 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1690 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.1071 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1622 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1003 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1684 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1674 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.1041 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.2265 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.1234 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1810 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.1602 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.2146 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.1821 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1605 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1712 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1719 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.1279 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1868 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.1232 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1697 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.1454 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1917 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.1348 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1633 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.1626 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1806 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1661 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1225 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1675 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1832 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.2085 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Training complete in 13m 4s\n",
      "Best val Acc: 0.960784\n"
     ]
    }
   ],
   "source": [
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3zV9fX48df75t7svRckgSSEvYeCCxwoigstbqzW0VJHq9X+upTaamu/tbV1W7d1YVVUUBRBZBM2hBmSkAXZe957P78/PrkZ5N7cm0XWeT4ePCB3fO7nhuTc9+e8z/u8laZpCCGEGPgMfX0CQggheoYEdCGEGCQkoAshxCAhAV0IIQYJCehCCDFIGPvqhUNDQ7X4+Pi+enkhhBiQduzYUaRpWpi9+/osoMfHx5OamtpXLy+EEAOSUirL0X2SchFCiEFCAroQQgwSEtCFEGKQ6LMcuhBi8GlsbCQnJ4e6urq+PpUBz9PTk9jYWEwmk8vPkYAuhOgxOTk5+Pn5ER8fj1Kqr09nwNI0jeLiYnJyckhISHD5eZJyEUL0mLq6OkJCQiSYd5NSipCQkE5f6UhAF0L0KAnmPaMr38cBF9C3Z5bw9NeHsFil7a8QQrQ24AL67hNlPLc2nap6c1+fihBC9CsDLqD7eerzuJV1jX18JkKI/qasrIznn3++08+77LLLKCsr6/TzlixZwvLlyzv9vN4yAAO6XsIjI3QhxOkcBXSLxdLh81auXElgYGBvndYZM+DKFltG6BLQhejPHv/8AGl5FT16zDHR/vzhirEO73/00UdJT09n0qRJmEwmfH19iYqKYvfu3aSlpXHVVVeRnZ1NXV0d999/P3fddRfQ0luqqqqKSy+9lDlz5rBp0yZiYmL47LPP8PLycnpua9as4aGHHsJsNjN9+nReeOEFPDw8ePTRR1mxYgVGo5GLL76Yv/3tb3z00Uc8/vjjuLm5ERAQwPr163vk+zOAA7qkXIQQbT311FPs37+f3bt3s27dOhYsWMD+/fuba7lfe+01goODqa2tZfr06Vx77bWEhIS0OcbRo0d57733eOWVV7j++uv5+OOPufnmmzt83bq6OpYsWcKaNWtITk7m1ltv5YUXXuDWW2/lk08+4dChQyilmtM6y5Yt4+uvvyYmJqZLqR5HBmBA11MuMkIXon/raCR9psyYMaPNwpxnn32WTz75BIDs7GyOHj3aLqAnJCQwadIkAKZOnUpmZqbT1zl8+DAJCQkkJycDcNttt/Hcc8+xdOlSPD09ufPOO1mwYAGXX345ALNnz2bJkiVcf/31XHPNNT3xVoEBmEP3bxqhV0hAF0I44ePj0/zvdevW8e2337J582b27NnD5MmT7S7c8fDwaP63m5sbZrPzWKNp9suojUYj27Zt49prr+XTTz9l/vz5ALz44os88cQTZGdnM2nSJIqLizv71uy/Xo8c5QxqGaFLykUI0Zafnx+VlZV27ysvLycoKAhvb28OHTrEli1beux1U1JSyMzM5NixYyQmJvL2229z3nnnUVVVRU1NDZdddhmzZs0iMTERgPT0dGbOnMnMmTP5/PPPyc7Obnel0BUDLqB7mgwYDUpSLkKIdkJCQpg9ezbjxo3Dy8uLiIiI5vvmz5/Piy++yIQJExg1ahSzZs3qsdf19PTk9ddf57rrrmueFL3nnnsoKSnhyiuvpK6uDk3TeOaZZwB4+OGHOXr0KJqmMW/ePCZOnNgj56EcXSr0tmnTpmld3bFo8rLVLJgQxRNXje/hsxJCdMfBgwcZPXp0X5/GoGHv+6mU2qFp2jR7jx9wOXTQ0y4yQhdCiLYGXMoF9NJFCehCiDPlZz/7GRs3bmxz2/3338/tt9/eR2dk3wAO6DIpKoQ4M5577rm+PgWXSMpFCCEGiQEa0CXlIoQQpxuYAd3DSIWkXIQQoo2BGdA9TVTVmx2uzhJCiKFogAZ0I5oG1Q0dt8QUQoiO+Pr6OrwvMzOTcePGncGz6b4BGtBl+b8QQpxuwJYtgt5xMSqgj09GCOHY6wvs3377l/rfqx6Fk/va3z//SYiaALvehd3/bf88Bx555BHi4uL46U9/CsBjjz2GUor169dTWlpKY2MjTzzxBFdeeWWn3kZdXR333nsvqampGI1G/v73v3PBBRdw4MABbr/9dhoaGrBarXz88cdER0dz/fXXk5OTg8Vi4Xe/+x0/+tGPOvV6XTXAA7qM0IUQLRYvXswDDzzQHNA//PBDvvrqKx588EH8/f0pKipi1qxZLFy4EKWUy8e11aHv27ePQ4cOcfHFF3PkyBFefPFF7r//fm666SYaGhqwWCysXLmS6OhovvxS//ApLy/v+TfqwAAN6HrKRVroCtHPORlRc+lTHd8/+Sb9j4smT55MQUEBeXl5FBYWEhQURFRUFA8++CDr16/HYDCQm5vLqVOniIyMdPm4GzZs4Oc//zmgd1aMi4vjyJEjnHXWWfzpT38iJyeHa665hqSkJMaPH89DDz3EI488wuWXX84555zj8ut014DMofvLNnRCCAcWLVrE8uXL+eCDD1i8eDHvvvsuhYWF7Nixg927dxMREWG3D3pHHFXU3XjjjaxYsQIvLy8uueQSvvvuO5KTk9mxYwfjx4/n17/+NcuWLeuJt+USlwK6Umq+UuqwUuqYUupRO/cvUUoVKqV2N/25s+dPtYVMigohHFm8eDHvv/8+y5cvZ9GiRZSXlxMeHo7JZGLt2rVkZWV1+pjnnnsu7777LgBHjhzhxIkTjBo1iuPHjzNixAjuu+8+Fi5cyN69e8nLy8Pb25ubb76Zhx56iJ07d/b0W3TIacpFKeUGPAdcBOQA25VSKzRNSzvtoR9omra0F86xHdkoWgjhyNixY6msrCQmJoaoqChuuukmrrjiCqZNm8akSZNISUnp9DF/+tOfcs899zB+/HiMRiNvvPEGHh4efPDBB7zzzjuYTCYiIyP5/e9/z/bt23n44YcxGAyYTCZeeOGFXniX9jnth66UOgt4TNO0S5q+/jWApmlPtnrMEmBaZwJ6d/qha5pG4m9Wcc95I3j4ks7/5wgheof0Q+9ZvdEPPQbIbvV1TtNtp7tWKbVXKbVcKTXM3oGUUncppVKVUqmFhYUuvLR9Sil8PaSfixBCtOZKlYu92p7Th/WfA+9pmlavlLoHeBOY2+5JmvYy8DLoI/ROnmsb0qBLCNET9u3bxy233NLmNg8PD7Zu3dpHZ9R1rgT0HKD1iDsWyGv9AE3TWm9Z/Qrwl+6fWsf0FroyKSpEf6NpWqdqvPva+PHj2b17d1+fRjtd6VXlSsplO5CklEpQSrkDi4EVrR+glIpq9eVC4GCnz6ST/DyNUocuRD/j6elJcXGxNM7rJk3TKC4uxtPTs1PPczpC1zTNrJRaCnwNuAGvaZp2QCm1DEjVNG0FcJ9SaiFgBkqAJZ19A53l72kkr6xztaRCiN4VGxtLTk4O3ZkjEzpPT09iY2M79RyXVopqmrYSWHnabb9v9e9fA7/u1Ct3k5+nicr6yjP5kkIIJ0wmEwkJCX19GkPWgFwpCkiVixBCnGbABnRblYvk6oQQQjeAA7oJi1WjtlE2uRBCCBjQAV2W/wshRGuDIKBLLboQQsAADuj+0hNdCCHaGLABXVIuQgjR1gAO6NITXQghWhvAAV1G6EII0dogCOgyQhdCCBjAAd3H3YhSMkIXQgibARvQDQbZ5EIIIVobsAEd9NJFCehCCKEb0AFd7+ciOXQhhIBBEdBlhC6EEDDgA7qJynoZoQshBAz4gC4jdCGEsBnQAV2qXIQQosWADuh+niYq6xplkwshhGDAB3QjjRaNerO1r09FCCH63IAO6P5Ny/8rpHRRCCEGdkBv6bgoeXQhhBjgAV06LgohhM0AD+jSE10IIWwGeECXEboQQtgMioBeJQFdCCEGekC3bRQtKRchhBjQAd3XQ1IuQghhM6ADuptsciGEEM0GdEAH6YkuhBA2gySgywhdCCEGQUCXnuhCCAEuBnSl1Hyl1GGl1DGl1KMdPG6RUkpTSk3ruVPsmIzQhRBC5zSgK6XcgOeAS4ExwA1KqTF2HucH3Ads7emT7IifbBQthBCAayP0GcAxTdOOa5rWALwPXGnncX8E/grU9eD5OaVXuUjKRQghXAnoMUB2q69zmm5rppSaDAzTNO2Ljg6klLpLKZWqlEotLCzs9Mna4+9ppEJG6EII4VJAV3Zua94iSCllAJ4BfunsQJqmvaxp2jRN06aFhYW5fpYd8PM00mC2Um+29MjxhBBioHIloOcAw1p9HQvktfraDxgHrFNKZQKzgBVnamJUeqILIYTOlYC+HUhSSiUopdyBxcAK252appVrmhaqaVq8pmnxwBZgoaZpqb1yxqeRjotCCKFzGtA1TTMDS4GvgYPAh5qmHVBKLVNKLeztE3TGNkKXjotCiKHO6MqDNE1bCaw87bbfO3js+d0/Lde1jNCl0kUIMbQNgpWito2iZYQuhBjaBnxA95dt6IQQAhgEAV0mRYUQQjfgA7psciGEELoBH9CNbga83d0k5SKEGPIGfEAH6bgohBAwaAK69EQXQohBEtBlhC6EEIMkoJukDl0IMeQNkoAuPdGFEGJwBHQPSbkIIcTgCOgyQhdCiMES0E3UNVpptFj7+lSEEKLPDJKArq8WlRa6QoihbJAEdNm1SAghBklAt7XQlTy6EGLoGlQBXUboQoihbFAEdOmJLoQQgySgywhdCCEGTUCXEboQQgySgC4jdCGEGBQB3eRmwNNkoLJeAroQYugaFAEdmnqiS8pFCDGEDaKAbpQWukKIIW0QBXST5NCFEEPaoAno/tJxUQgxxA2agO7naZTmXEKIIW3QBHRf2eRCCDHEDZqALlUuQoihbhAFdCPVDRYsVq2vT0UIIfrEIAro+vJ/yaMLIYaqQRTQpSe6EGJocymgK6XmK6UOK6WOKaUetXP/PUqpfUqp3UqpDUqpMT1/qh3zl34uQoghzmlAV0q5Ac8BlwJjgBvsBOz/apo2XtO0ScBfgb/3+Jk64e+lp1xyy2rP9EsLIUS/4MoIfQZwTNO045qmNQDvA1e2foCmaRWtvvQBzvjM5JThQUQHePLPNUewysSoEGIIciWgxwDZrb7OabqtDaXUz5RS6egj9PvsHUgpdZdSKlUplVpYWNiV83XI0+TGr+ansD+3go935vTosYUQYiBwJaArO7e1GwJrmvacpmkjgUeA39o7kKZpL2uaNk3TtGlhYWGdO1MXLJwYzcRhgTz99WGqe6GVboPZyq4TpT1+XCGE6AmuBPQcYFirr2OBvA4e/z5wVXdOqqsMBsXvLx9NQWU9L32f3uPHf2dLFte8sIn8csnTCyH6H1cC+nYgSSmVoJRyBxYDK1o/QCmV1OrLBcDRnjvFzpkaF8zlE6J4+Yfj5PXwBOnm48VoGqQXVPfocYUQoic4DeiappmBpcDXwEHgQ03TDiillimlFjY9bKlS6oBSajfwC+C2XjtjFzx6aQpWDZ7++nCPHdNq1UjNLAEgo1gCuhCi/zG68iBN01YCK0+77fet/n1/D59Xt8QGeXPnnASeX5fObWfHM2lYYLePmV5YRWmNvmgps0gCuhCi/xk0K0VP99MLEgn19eCJL9LQtO6XMW7N0EfnAV4mCehCiH5p0AZ0Xw8jD12cTGpWKV/uy+/28bZnlhDm58FZI0Ik5SKE6JcGbUAHuG7aMEZH+fPUqkPUNVq6fBxN09iWUcKMhGDiQ33ILqnBbLH24JkKIUT3DeqA7mZQ/G7BaHJKa1m+o+uLjXJKa8kvr2NGfDAJod40WjTyyup68EyFEKL7BnVABzg7MZQwPw92Z5d1+Rjbm6pbpscHEx/iA0ilixCi/3GpymWgS4n049DJCucPdGB7Zgn+nkZGRfpRXFUPQFZxNdDzq12FEKKrBv0IHfSAfvRUVZfz3tsySpgWH4ybQRHm54G3uxsZUukihOhnhkhA96febCWzuKbTzy2qqie9sJrp8cEAKKWIC/GR0kUhRL8zJAL6qEg/gC6lXWyrQ2ckBDfflhDq3aUPByGE6E1DIqAnhvviZlAcPlnZ6eduyyjF02RgfExA823xIVK6KITof4ZEQPc0uTEi1IeD+V0I6JnFTBoWiLux5VsVH+qD2aqRUypdF4UQ/ceQCOgAKVH+nU65VNY1kpZXwYz44Da3J4RK6aIQov8ZOgE90o+c0loq6xpdfs7OE2VYNZiRENLmdlstukyMCiH6kyEV0AGOnHI97bI9owQ3g2Ly8LbdGkN93fH1MJIlE6NCiH5k6AT0KH+ATuXRt2WUMC7aHx+PtuuvlFLEh3pLLboQol8ZMgE9OsATP0+jy3n0erOF3TllbcoVW4sP8SFTcuhCiH5kyAR0pZTeAsDFEfrenHIazNbmBUWniw/xIae0lkYpXRRC9BNDJqCDvmL08MlKlza82JbR0pDLnvhQHyxWjewSyaMLIfqHIRXQR0X6UVlvJteFzaO3ZZSQHOFLkI+73fsTQr0BJO0ihOg3hlRAHx3V1ALASdrFYtXYmVXqcHQOLaWLGUUyQhdC9A9DKqAnR+gB/bCT0sWD+RVU1psdTogCBPu44+dplFp0IUS/MaQCup+niWHBXhzM77jSxVn+HPRJ1oRQqXQRQvQfQyqgA4yK8OeQkyZdaw8XMDzYm+hArw4fJ6WLQoj+ZMgF9NFRfmQUVTvcNDqntIYNx4q4enKM02PFh/qQW1pLg1lKF/uT2gYLtQ1d3xRciIFqyAX0lEh/LFaNYwVVdu+3bSZ93bRYp8dKCPXGqsEJKV3sN9YdLuCsp9bw6//t7etTEeKMG3IBvWWzi/ZpF6tV46PUHGaPDCU2yNvpseKkSVe/YbVq/PPbo9z+xnbKahrZeaLrm4ILMVANiU2iW4sP8cbDaOCQnYnRTenF5JbV8silKS4dK8EW0CWP3qfKahp48IPdrD1cyDWTYwj39+Sl9enUNljwcnfr69MT4owZciN0o5uB5Ag/uyP0D1OzCfAycfGYCJeOFeTjToCXSZp09aH9ueVc8e8NbDhWxB+vGsf/XT+RibEBaBoO02pCDFZDLqCDnnY5PaCX1zTy1YGTXDUpGk+T66O6eCld7DP/25nDtS9sotGs8cHdZ3HLrDiUUiRF+AKda5UsxGAwMAP6zrdg2ytQmtmlp6dE+lFUVU9hZX3zbZ/uzqXBbOX66cM6dayEEG8yZbXoGVdR18jDy/cyMTaQL+6bw5ThQc33xYX4YHJTHJURuhhiBmYO/cAnkP6d/u+QJEi6SP8TNweM9nuvtDa6qTf64ZOVhPl5AHq6ZWy0P2OjAzp6ajvxoT58tiePukZLp0b2onsO5VdisWrce/5IQn092txncjMwItSXozJCF0PMwByh3/w/WLoD5j8FgcNh+3/g7auhusClp7dUuugTo/tzyzmQV8GPOjk6B31/UU1jUHRdPJhfwb/WHO3r03BJWl45AGOi/e3enxjhy5ECCehiaBmYI3SlIDRR/zPrXmiogZztEOC8dhwg1NeDUF+P5jz6R6nZuBsNXDnR+WKi07U06aomqalXzED1wfZs3tiUya1nxxPgZerr0+nQwfxKQnzcCffzsHt/crgfK/flU9Ngxtt9YP6YC9FZLo3QlVLzlVKHlVLHlFKP2rn/F0qpNKXUXqXUGqVUXM+fagfcvWHEeVBVCO9eB0e+dvqU0VF+HDpZQV2jhU935zF/bCQB3p0PYvGDqHTRVq2T50J74b6Wll/BmGh/lFJ270+O8EXTIL1g4P+/COEqpwFdKeUGPAdcCowBblBKjTntYbuAaZqmTQCWA3/t6RN1iWcAFB+Db34PFnOHD02J9OPIqSpW7c+nvLaR66d1Pt0CEOBtIsjbdGba6DZUg6Wx1w5v+1DKLe2bgO7KxiMAjRYrh09VNs+F2GO7WpJKl8Hjq/0nWX+ksK9Po19zZYQ+AzimadpxTdMagPeBK1s/QNO0tZqm2SLaFsC13EdPM7rDhY9B4SHY898OHzoq0p8Gs5VnvjlKTKAXZ48M6fLLxof62F8tarXC6t9B1qYuH7uNFffB65dCaVbPHK+VBrO1eR7AlQ1AetqHqdlMfeJbquo7/iAGOF5YTYPZypgOAnpciDcmNyV59EFC0zR+++l+nlx1qK9PpV9zJaDHANmtvs5pus2RO4BV9u5QSt2llEpVSqUWFvbSJ+3ohRA7Hdb+WR/ROpDSNDF6oqSG66bFYjDYv3R3RYKjrosH/gebngVDN/LR5nq9qgcgZQEUHoaXzoG0FV0/ph3ZpTVYmwbIZzrlYrVqvLgunZLqBnadKHX6+LT8jidEoaXS5dgpKV0cDI4VVFFUVc/hkxVU1vXeVepA50pAtxfp7F4bK6VuBqYBT9u7X9O0lzVNm6Zp2rSwsDDXz7IzlIKL/giV+bD5eYcPSwz3xc2gUAqu62K6xSY+1If88rq2Hf7M9bBmGUSMh5gpUOs8UAGUVDewJ7upD4nFDMt/DB8tgfw9MO4auHs9BI+ED2+BL38JjXXdOneb1lcYOWc4oG9ML+J4UTWxqoA96blOH5+WV4G70cCIUJ8OH5cklS6DxubjxQBYNdidLX16HHEloOcArSNeLJB3+oOUUhcCvwEWappWf/r9Z1TcWTBhMZg8HT7E0+TG2Gh/LhgVToyTvufOxDcFljZdF7f/B8qy4KLH9VH1PyfB/v85PdYvP9zNDa9swWKxwGc/hUNf6OWZURP1BwQnwI+/hrOWwvZX9SuAHmCbEB0T5X/Gc+hvbspioncJ33v8gqCD7zp9/MH8SlIi/TC6dfzjmxzhR3ZJLTUNztM44jQNNeDinMaZsOlYMWF+HhgU7MhybXA0FLkS0LcDSUqpBKWUO7AYaHO9r5SaDLyEHsxdKwbvbde8BGf/vMOHvHn7DJ69YXK3XyopXF9q3jxhU1sG65+GEedD4jwITYbgEfqIusrxt2d3dhlrDxdS02Cm+pMHYO8HMPe3emlma0Z3uORPcOtnTt+jqzKKqgnwMjEuxv+MplyyS2rQjqziqvGhZPlO5MKyjzDXO359TdNIy69gdKTjdIuN7f+lP1e67DxRyrQnvmXFnnZjpL5TdAz+lgyvzIVja/o8sFutGlsyirkltoCLwkoloHfAaUDXNM0MLAW+Bg4CH2qadkAptUwptbDpYU8DvsBHSqndSqmeTfB2VUM1rPuL/gNqR5CPO74e3a9RTon04/xRYfxzzVFOVdTBka/0FMtFy/QHuBnhqhegoQq+/IXDX5Bn1xzFoOBnbp/hv/8tmP0AnPOQ4xcecT6YvODIanjn2m5VwGQWVxMf6kNMoDcFlfXUm8/MBhEfbTzA08YXuaH0RU6Ov5cIVcqpDW85fPypinpKqhs6zJ/bDIRKly/35lNUVc997+3ipe/TXa706TVWK6xYCsoA1YXw3uIOByFnwtHjR1nW+Hfuy7iX6eFWdp8ow1J6osfSjYOJS3Xomqat1DQtWdO0kZqm/anptt9rmrai6d8XapoWoWnapKY/Czs+4hnSUK2nJNY83qsvo5Ti8YVjabBYeeLLgzBxMfx8R0uaBCA8Bc7/NRz8HPZ/3O4Ye7LLWHfoJHedO5IV1rPYGne3XrHjoM66DWsjHPsWtr3c5feQWVRDQog30YF6miq/rPd/WeoaLfjteJ5gVYXn/McYPv1y9lvj8d3xHFjtf6C4MiFqEx/ijbubwWkeva7Rwvd9VA638VgR0+KCWDAhiidXHeIPKw5gsToJ6l/9P9j9Xu+cUOp/4MRmuPQp/Wf41s/AL0KfE/rkHsjd0Tuva4/VAtteIeG9C7jEsJ2q6fcRljKbynozdR/dDc+M1YsfKk+duXPq5wbm0n9X+YbD7Pvh4ArY+1GvXjrGhfjws/MTSd+7iQ1HCiFkZPsHnX0fxEyFrx6FxlZphfoqspb/lm88H+Fnc6Ix+8fxvveNrgVzgFGXQeJFsPZJqDzZ6XOva7SQW1arj9CD9PmEM5F2Wb11DzdrX1AUfzlETyYmyJv3TNcSUJOlf/DZkZant2uwVSl1xOhmYESYD0edVLq8vjGT217bxrGemEBd9Si8Mg8+WwpbXoSM9VBd3HJ/Yx3k7YKdb1P72S95vORhnq9+gH9d4M5Pzkngrc1Z3PPOjo630DO6w6f3QNmJ7p/v6byCYPx1MPEGMHpA3Nn67YWH9AV7r8zVU4fWbm67qGnw3g3w8Z2w6d+Q8QPUlbfcX10Mr86DlQ9x1JTMHT7/wnfBH5mcEAXA5tjb9Wq27/+qB/Z3roX/3dXy/F3vwMZn9Q++mpLunesAMrgDOsBZP4PwsfC/O+GVC1qaevWCe0bX8YXHb9i1/Cn7KQs3I1z1ItzwgZ4qsZhhxxs0/mMSC8vfxho2Bj9DA4nhvhztTHBRCi79C1jq9UVV6Ptq3vKfrby/zfkvfVaxPpmbEOpDbKC+U1NzpUvBQagu0v9dVdhjH4qapmH84S8YlZWQhU80vQ1F+YhLec3tOr0yyI60/AriQrzx83RQCmoxw6GVcHIfgEvfy6/25wOwq6u7HNVVtASNYTPA4AaHV8JXj8CbV8DTI1quytY9CS+fDyuWYtr7X4xY8HdrxFBXwm8WjOGxK8bw7cFT3PDKFoqrTqstOHVAHwhMuwNM3rDqka6db0fGL4JrX20/mIiaCA/shZn36pPxKx/q3M+CpunrMT65Rw/cSukBOWszrP4NvHk5PDVcLx4oOgrewRAUj+XqV/lR7SMMTxoPwLBgL0J9PVhZlQw3vq9fRUz7sT5KP3Wg5fW2vgTf/E7/4PtbMrx/Exz6slcX5vUHg7/JhbuPXuq35z390zxzI4ycq1/OKYPro2AXeKxbRqPJj1crZqDWH2fp3KT2DwpL1v+uLYWXzoOyLDI9xvI4D/DCHXeDp4mk8AL+uy0Lq1VzvT4+ZKR+BfDD32DqEpbt8OWHo0VoGiyeMbzDp9oqXBJCfYgM8EQpKCosgFXP6Wmc6XfC+Y/qH4iJ8+Cy/9M/nLph97Es5tStJz3uelKCE5pvnxofyuP7rmY+YUTbed7B/Er7E6JVBbDjTUh9DSrzwCsY7tlAcoQfX+x13NMlt6yWPTn6yHBfbrKHCDIAACAASURBVHnnSlitVn0B27ePQ+KFcPULemnpuGv0AFZVAKf2Q0GafmUG+ug3ehJETuAP31fx2Z6T7F46F0wm0DSWzIolMsCL+9/fxbUvbOK9u2YRFeClX3m9dSXEz4Hr3tDTd9/8Tv/wSrnM9XN2ZOfbej+kS//quDrMww/mP6mP3Df+AwxGfSDR0e9QQ7V+7NTXoOgweATA5Fsgfjac8wv9T1UhnNwDebshfzf4RenHvO4N9p4opap+U/PCP6UUU+MC2WmbGA0ZCZfZWZh+1zporIHidNj3Eez9EI6uhoeO6Fch5bngHdJhJVwzTYP6Cv2D2ydMf07lSajIA6sZPPwhbFSPxpKuGvwBHfTgM+UWmPAjPd8M+g/ksTWw4O96fru7MtbD0dWYLlrG7MxE/vXdMa6cFMOwYAd7k/7wf2AwcuLCl7joC19+cdGo5lFnUoQvdY1WcstqHT/fnnN+CXk72XismPe2leLnYWRfbjmapjnseQItS/7jQ31wN8Ad3j9wa+p7YCmHabfDeY/ovwQTrtfPu7oIrv2Pa78MDryeWspe/sGXV1/Q5vZpccEA5G94h2jzbrjqueb7qurNZBZXc/VkO+va3lus53dHzoULfq2nPra9THLUPYC+MGVCbGC7p60+oKeoYoO8mgO7U1YLZG7Qr4byd+sjzRl3tn2MUnru2S9C/xC0iRyn/wE2pq9lZkIwxqZgzv9+AgYj8696gf/+ZBaLX97Mqz9k8LvLRun31Vfp/xegVz7teQ9W/UrvY+TecU1+hyry4Ov/p4/C3Zy0n1ZKn9uxNIK5Vj9vRz9bx9fBpz+Dihz9A+3K52DsNXrvpdZ8w/QPxMQL2x1iU7qerpo1omUl99S4IL4+cIqiqvp2rZObGdz0D6DoSfqfCx+HU/v0n2Nzg744r6ZYbxfiG6n/P/lGwhX/0L+X3/xBn0uoPKl/MJubrlhv/0ovi97+ql7JZhM2Wv/9mLgY/O0NRdC/Z8oNDL2XGBkaAd3G6A40/cD6RuiXaKsehtvs52s7ZDEDGriZoCwbVv8W/GNhxt38bpzGusOFPLbiAP9ZMt3+8y9cBhf9kT++vQN/z2KWzI5vvstWbne0oLJzAd3dm6zL3uHuZzcwZbgvV02O4fefHSC7pJbhIU3HqS6Cjf/UUxJGTzB5Mj23ljCfH+PvYYSPlvBby6ccch9Lyp0r2k7szvu9/n1b9YjerviG98CrfZB0pijnKGv3ZbDorHH4BIW3uW90lB/e7m4U5WVC3jv65XSsPro9fLICTdNr5cnfC188CAufhYixeq2+VxCENl0VxUyFsNEkNvXYOXrKfkD/av9JRkX4cd6oMN7YmEmD2Yq70c4vXGOd/gGmafCvKfrmKn7RcM0r+qi7k6Oz3LJaMotruHlWUx87pfTe/uv+DGEpTJ3zAPNSIvh0Vy7/z2cFbhnr9YAYPlp/vJsJLn9GX3hWchwix3fq9Ztpmv59tDTq30tXgo1Setms7d/F6XpZru17YLXqx3H301Mn177SkovvpC3HixkV4dcmcE+N0zcz2ZlVysVjI107kJsRoptKlDUrXPIklJ/QUzVVJ/W/c7aDsWlNSkOVfiUybIb+M+8boQd/29Xk+Ov0nzE3k/6zsPcjvfgiKF6/QitvWiBXeAhObNE/HHJ3wI+/avs71cOGVkBvbfLNekBPfU2fwTc6+KRvLWeHXtJVeVJPmVz5HEy+CTJ/0FdyXvMqmDyJCoAHL0zmTysP8k3aKS6yt0epwcD+3HK+STvFgxcm498qJ5wUrk/4HT1VxdwU1/Y3Bag3W1j6313EqgLeCXibrJDHAD2VMDzEW/+lfelcfRVt1CSwFoG5npjKSuJC/fRfSDcTb0T9ltfLp/K9vR+8mXfrl6qf3AOvXwY/WaPPB7SmaVBfqX9PT/++ahr1H/6E94yleM/c0O7wRjcDk4YF8krNuVzi+Q5s+Dss1hcbpeVVYMLMzKyXYPk/9bSKbQXusBltDxQxFoD42v3MNh7iSMGIdq9VXFXP9swSls5NIinclwaLlSOnKhkX07TJSWOd/vNxeKX+AfLQET2oz7xXH1Umz+/yyHjTMX1eYnZiaMuN5/1KT0t8+xiEJrFo6jTKDn6HYf1f9IVyk25qe5Dhs+C+3S5t6uLQvo/0MttL/qwHZVfZgnfBQX1O4Oyfw5wH9Su47G1w6wr9g/ju9V1ORdSbLWzPLGHx9LYpw7HRAbi7GdhxohMBvTWTJ0z8UcePWfB/Hd8fNgrCRmGxalTUNhI0/U4oyQC/pvNZswz2vq//Wxn0D9wpt4K7b+fPtxOGbkAHiJsNW57Xqw6Gz3L++D3v6f9pk28C79DmS2eS58N9u9r8QiyZHc/yHTk8tuIAsxND7OZvn11zFD9PY5vROegdHMP9PDjSyT4kf1l1mH255bx9VSLeqx8k2csXH7fLMO14BZIfAE9/fSTb9MNos/BP33KubRn9ta+Sv+og+RsyHefwxy/Sg3r+bj2YH16lr4ytLtSvAKoL9Qna6T+BBX/Tv2df/Rr8o7GgiKnYxTch97Ek3H6lyrS4IP69tpiGuXfivvFv+krbsFGUHk/lC89l+G3N0tNn85/SR4COWK0YV/6Sf5lyWJY3Hhjd5u5vD57CqsH8sZHN6xH25JTpAb3wMCy/Q79Mjxinp1TMTaP0Wfd06v/Fns3pxQT7uDOqdQ99pfRBQkkGfPwTzluyigKPXZwyxhC54P/sB0ajuz663PkmnPuw/cfUV0HeTn3BW125fmU24Tqqa+txX/EgxpjpqJldfE+ho/RUw/qn9TREban+4WOu1T/supFX3n2ijLpGK2ed1jjP0+TGuBj/ljx6J1XVm7nvvV08emkKyd3cw+CZb47wyg/Hef+uWUwe3jIXxKx79SAeMUZPyXmcmb0ShnZAH36W/nfmBtcCesZ6fTLn9E9v7+B2gcXkZuCJq8dx3YubOfup7xgd6c+YaH9GR/kzJsqfRouV1WmneODCJLubSSRF+HaqjO6btFO8tjGDJWfHc86ssVC1FLcNz/C9x2pCs4ohLUGfRxjTdolAdb2Zgsp6Elr1RYkN9KLBYqWoqp5wfwd58pEX6H9An/iqLtQnjMLHgE+o/mfYTP3++gooz4bsrbjVlnDEGsPwC+92+F6mxgdj1WBn5PXMMj6np4gu/Su3H7sfs8Edrn/PtYlAgwGueQXfF8/jptwnwHphm5TCV/tPMizYi9FR+i9boLeJvdnl3OS3Qi+Bc/eGGz+E5Eucv1YnaJrGxvQizhoZ0v4D0+QFi/8Lr8zFtOFp0qf8hme27Ge12Z0gRxeRR1fD2j+Bf4w+2LCpKdHrtPd+oP8f2IQksifoIu5/fxfL6hNgzOOca+ji9okGA1z+T70BXf5uuPiJLqdXTrf5eDFKwayE9p1Qp8YF8ebmLMcpsg5sOlbEd4cKCPV156+Lup7+sFo1/rczh3qzlZ+8tYMVS2cTbWsjYsvdn2FDO6D7hMCMu9qMVh1qrNPr2hMvcvnw0+ODeemWqaw7XEBafiXvbMmi3txSv+vnaeT22Ql2n5sU7seHqdlOJzRBz8c+9NEexsX48+vLmiZ4z30YDn5ObY2Jn9Tey8uTb7bbZa11hYuNrRY9p6zWcUBvbfwi/Y8jURPh3o0UVtZz/b+/w+DmxurRjht2Th4eiFKw5ZRi1tTbIHsbZoM7S833M27qOTyccpbzc7KJGMMPib9i3tEnaPj+b7hf8CtA32R647Fibjs7rvn7Oz4mgD05ZXBeiv5hdfkzLZfQPeh4UTWnKuodt2z2j9LndQJiWFTUyH82ZrJiTx63nR1v//GTboJdb+tVL4nz9DmdYdP10sZDX8KoS/Wcr18kVnd/Xt9ZypMvbCLMz4Olbr9jXo4P53bnDRkMcPnf7d5ltWqcrKhrCXSdsCm9mHHRAXY3npkaF8QrP2RwIK+cya02CHdFatPI/su9+Ty2cGyXd7TalV1GXnkdPz1/JG9vzuKON1NZfs9Z+PTA6vOuGtoBHeAyu40h2zN5wpIvOn34S8ZGcklTns9i1cgoqiYtv4KD+RVMHhbocKu3xHBfahos5JXXddg8zGLVuP+9XZgtVv51wxQ8jE0jLXcfWJrKhu3ZfPO/fZwoqSEupH2+t7nCpdV9tl++vLJapnTyl8WRukYLP3krlZM1ig/vnolbB+WY/p4mRkX46T07bn0MjJ5kFlbxfeNYFg7rfGfMxgk38dmh71i4/kkYMQfizmZdWg4WSyPzxzbNUWRu4LGqJ7m84C5qA2bjdUMvrcSkVf58ZKjjB4UmAjA6youx0f4s35HjOKAbDHq11kvn6otsDEb4xUH9qvH+Pc059pPldfziw91sSi/msvGRPHn1BP74ZRqrD5yk0WLF5KTZWVe8szWLJ744yMZH5zZvyO6K2gYLu06UOhzw2H4ud2SVdjqgb8soIcjbRGlNI6v2neTaqV3bvuHLvfm4Gw3ce/5IpicEc8cb23nwg928ePPUDsuN6xotuLsZutWy25HBv7DIGXODXptentPx4yryur06zs2gSAz3ZeHEaB6Zn9LhhE5zpYuTPiS7TpSSmlXKbxaMaTPKBkApxjdN8O3LtV+SZ2ubGx/aUk1j+wDpqa6LVqvGQx/tYU9OGc/8aBLjYwOcPmdafBC7TpRhcfMEpTjQtELUlSX/p0uK9Oc3jT+mJGCc3kUQiFvzM9I9b2HqGyNgWQi8sYDIxhxCtJLm9gK9ZVN6MdEBnsSFuFbBdO2UWPblljdvam5X5Di4+I8w+go9ZePZVNHTFMy/PnCS+f9cz64TZfz12gk8d+MUArxNXDwmgoo6M9syemc15ap9J2mwWDvdUGtHVimNFq1d/twm3N+TYcFenT5ubYOF/bnlLJ4xnLgQb5bvcPJ774DVqrFyXz7nJYfh52niglHh/HbBGFanneJvqw/bfU5do4U3N2Vy3tNr+fpA51d0u0ICem0pvHFZx61tNQ1evUhvZ3uG2BpLHSvoeGJ0U7qeZ7xsvP0Ph+QIP9zdDOxzUGOdUVRDpL9nm8tOP08T/p7GHtu56B/fHuGLvfk8Mj+F+eNcS2FMiwumqt7M4aaNvNPyK3B3MzAyrPNVAnHB3jS4+fJy8kuQdCF1jRZer5jOt5F36nXdZ98H8/5A9ZLvyNHC2ZPdewHdatXYfLyYsxNDnabSbK6cFI3RoPjYSfDZGXMjT3j9il/uDOWOt3ZwzfMbmfu3dUz54zfc/fYOhgV58+V9c7h++rDm1z4nKQxPk6G5Ht+ZBrPVea+ZJhV1jWzP1D8oXNm4pLVN6UUYDYrp8Y4nvafFBZOaVdqphma7sksxWzVmJASzaEosm48XN+/U1Rk7TpRysqKOyydENd92++x4bpgxnOfXpfO/nS3/V/VmC29vzuT8p9fxhxUHiAvRF/D1Bkm5+EVASCJkbYTZ99l/TMnxlsURZ0iwjzuhvu5OOwVuPFbE2Gh/Ar3tl665Gw2kRPk5HKFnFFW1GZ3bRAd69Ug/l0935fLsd8e4flosd5/relmcrdZ4R1YJY6L9ScurIDHct9MTYNCqp0tTG931Rwr5tHEGi+bNhKSWtEc4EO7n4fB71RPS8isoq2lkdqLrWx6G+HowNyWcT3bl8cj8FLt94A/mV3Dzq1sxWzVCfdwJ9HYnyMdEVKAXgV4mRob5cvOsuHbfPy93N85JCmN12ikeWzi2ww8Zq1Xjquc2Mj4mgL8smuD0vDccLcJs1fDzMLKz0wG9mAmxAR12Q50SF8Qnu3LJKXV9AV5qZilK6Smb5Ag//v7tET7emcMDFyZ36vy+3JuPh9HAvNEtZcVKKZZdOZaMoioe/XgfUQFepBdW8fzaY+SV1zE9Poi/Xz+Rs0aGuPxh3lkS0EGflT/wmb4C0N5sf8b3+t8jzj+TZ9XUh8TxCF3PM5a1K3s83fiYAFbsybM7wZpZXMMlY9vXuscGeZHTzZRLamYJv1q+l7NGhPDEVeM79UMcG+RFhL8HqVml3HJWPAfzKzh/VLjzJzqQFOHXPEr86sBJArxMzBzRfvQ3ITZQnxjtJZvS9fz52R3lz+1YNDWW1WmnWH+0sN3ahJLqBn7yVip+nkZWLJ1DhCsT2a1cPCaCb9JOsT+3osN02A/HikjLryCjqJo/LBzjdDLxu0MFBHiZuHpyDP/ddsLlipTKukb25ZZz73l2Gty1MrUpd77zRKnLAX17Zgkpkf4EeJkI8DJx9sgQPt6Zw31zk1zOaVusGl/uy+eCUeHtPnBMbgZeuGkqVz+/kRte2QLAlOGB/GXRBOZ04qqsqyTlAhA3B+rL9Z4b9hz/Xl8VGJJ4Rk8rKdyPY6eqHF5SpmaV0GCxOt3genxMAJV15uYmXDblNY2UVDe0mRC1iQn06lbK5URxDXe9vYOYIC9euHlKp0fWSin9kjqzlILKOoqqGjrcFNqZ5HBfckprKa9tZM3BAi4cHWF3EnBibADHC6up6KV9KzelFzMyzKfTQff8UeEE+7i3y/k2Wqzc+84OCirrefmWaZ0+LsC80REYFKxO6zjt8uamTExuitpGC98d6rhHutWqse5wAecmhzE9PpgGs5W0/A7mAFrZnlmCxao5/bkeFemHj7uby3l0s8XKzqxSpse3TKJeN3UY2SW1bO3EHML2zBIKK+tZ0Crd0lqQjzv/WTKdqyfH8OaPZ/DxvWdzTlJYrwdzkICus9XNZm5sf5/Vqq8ETTj3jDffSYrwpbLezKkK+zv6bTxWjNGgmJHQweIaaB517T0tlZBR3L5k0SY60IvKOnOXAputosVi1XhtyXSH6SBnpsYFkVtWy9qm4NGVCVEb25zEu1uzKK9ttHtVAi3fq/1dTLvsyCpprmI5XYPZyraMkk6PzkFPnV05KZpv0wooq2lovv3xzw+wNaOEv147gYnDOt+GAfT03vT4YL5Jc9xXPKu4mrWHC7j73JGE+3nwuZMdlvblllNU1cDclDCmxOnn5epCoE3HinF3MzAlruPqFTeDYvLwIJcD+sH8SqobLExrlZe/pGlRWWcmR7/cm4+nycC80Y6vGEeG+fLMjyZxXvKZCeQ2EtABAofpHeCC4trfV1uqr4az0ziotyW26uliz+b0IiYPD3R66Zsc4Ye70dAuSGXaqUG36U5f9KdWHeLwqUqevWGy3WO7alrTSOqtzVkAjO7GCD0pQv9evvpDBl4mN85Ntr9Jua3fy15XG3W1UlnXyB1vpnLjq1t50c7uQ3tzyqhpsHQqf97aoqmxNFiszcH07S1ZvLPlBPecN5Kr7DUs64SLx0Zy6GQlWcX2t+t7a3MWbkpxy1lxLJgQxdrDhR1+2H93qACl4LzkcKICvIgO8HQ5j775eDFT4gLxNDlf7DQlLoiD+RVU1zvfN9Y2Qdt6hO7l7sblE6JYtT/fpWOYLVZW7c9nXkpEl+vXe5MEdJsr/60vwDidTwj8eBVMuO6Mn1Lrni6nK6/V84yujPZMbgZGR/mz97TccEZRNUphN//Y1dLF748U8samTG6fHc95DoKmq0ZH+eNlcuNAXgWxQV4Oa/ZdERes715UUt3ABSlhDoNFsI87w4K92n2vXPHmpkzKaho5e2QIT606xG8/3Y/Z0lLquvFY08rHEV0L6GOjA0iJ9GP5jhw2pxfz+IoDzE0J5+FLXFgY58TFTf2G7I3Sq+vNfJiazaXjo4jw9+SKidE0mK18c8DxiH7t4QImDwsk2Ee/OpscF+RSv/mCyjrS8is6rtFvZWpcEFZN3/HLme2ZJcQGeentiFu5blosNQ0WvtyX7/QY2zJKKKpqcJhu6WsS0G3MDXoD/tP3TyzN6v7uLF0U6utOkLfJ7sToluPFWDWc5hltxsf4cyC3AmurkrPM4mpiAr3sBreYwM6P0Iur6nnooz2MivDjkfndb0lsamrUBd0bnUNLpQvQvNDLkQmxgZ0eoZfXNvLy+uNcODqcd+6Yyb3nj+TdrSe4861UqppGfpvSO65IcsWiqbHsySnnrrdSiQ/14Z+LJ3W4SMtVw4K9GR3lz2o7QfqTXblU1plZcrZ+BTt5WCAxgV58vtd+2qWgso69OeXMTWlJSUwZrqfPTpZ3vLXhmoMFaBpcaK+hnR2Thumrip2lXTRNY3tmKTPslEFOGR5EQqiPS2mXL/bl4+3uxgXdmKDvTRLQbcqz4fVL4VCr1aCWRnjhbL01bh9QSpEU7md3cdHm9GK8TG4ur5KbEBNIZVM/cZuMomqHKZFQXw/c3QwtOxc5oWkav/7fPsprGvnH4kkuXS67wpZ26c6EqE1yhB8mN8UFKR3/Mk6ICSCntLb9jkEdeG1DBhV1Zh64MBmDQfHI/BT+fPV4fjhaxPUvbiazqJpdJ8q6lD9v7arJMRgNCoNB8eqt0xzv3NQFF4+JIDWrhKJW71vTNN7clMm4GP/m1ZlKKa6YGM2Go0WUVDe0O866w/r+rBe0CehNeXQnaZdv0k4RG+Tl0haDAAFeJpLD/djh5LiZxTUUVdW3yZ/bKKVYNDWWbRklDlNOoKdbvtp/knmjI/By75mf754mAd0meITe4L71xGjeLr0v8vCZfXZaiRF66eLp+diNx4qYnhDscvXIuNNWjGqa3obAXoULgMGgiA70dDnl8sH2bFanneJX80d1ezTdmm3C17bitTvum5fEizdPbdOq2J7mPLqLE6NlNQ28tiGD+WMjW1rvAjfOHM5/bptGVnE1lz37g0sVSc6E+nrw7xun8O6dM4nvxvyEPRePjcCqwXcHW65SN6UXc7SgitvOim8zuXfFxCjMVo2v9revjFl7qIBIf882H8JjowNwNxo6nBitrjez4VgRF4+J7NRE4rT4ILZnlFBe6zinb8ufz0iwPwC6ZkoMStHh4q3Nx4spqW5gwfj+mW4BCegtlNI7KWZtbNkr8fj3gIL4c/rstJLCfSmvbaSw1aipoLKOowVVnQoOSRG+eBhbVoyWVDdQWWfuMCi4urgoo6iaxz9PY05iKD920Hujq+YkhvLG7dPbXL53VWK4b5uFII6Mjw1AKRyurj3dKz8cp6rBzAMXtd9y8PxR4Xx0z9n4e5pwNxo6XPnoqvnj2n5w9JQxUf7EBHq1KV98Y1MmwT7uXDExut1jR4T5tKt2aTBb+eFoERektK3ucDcaGB8T0OEIff2RQhrMVvv7B3Tg5llxVDdYeGNjpsPHbG/q3+JopXFUgBdzEkP5eGdum7Rka1/uzcfH3Y3zR3Vvbqg3SUBvLe5sffOH0gz964zv9Z7GHfXc7mW2idFjrSZGNzdty+XqxBG0TIzaRui21MuIDgK6K7XojRYrD7y/Cw+Tgb9dN7HHGw4ppTh/VHivNDJyxNfDyMgwX5cmRkuqG3h9YyYLxkeRYm+vU/Ryyy/vm8OnP53dp534nFFKcfHYCNYfLaK63kx2SQ1rDp7ihhnD2qXQlFJcMSGaLRnFFFS05MVTM0uoqjfbzTFPjQtif26F/Q3UgdVppwj0NrWpQnHF6Ch/LhoTwWsbM6h0UHmTmlXKtPjgDkf+i6bGkltWy1cHTra7Im60WPnqwEkuGhPRY+nE3iABvbW4OfrfmRv13dWzt+r1533IVm7XemJ047EiArxMna7LnhAbwIE8fWL0eGHLPqKOxAR5UVBZT4PZ8aTwv9YcZU9OOX++enyv9afoCxNiAtiTU+60T8hL36dT22jhgQvtbAjeSoivR7fq6M+Ui8dENo2yC3lnSxZKqZZt8k5zxcQoNI021SHfHSrA3c3QdiemJlOGB9JgsTY3Wmut0WJlzcFTzEuJsNvawJn75iZRXtvI21uy2t1XUFlHRlG10w+KS8ZGEubnwU/f3cnUJ77l7rdTeW2D3qJ3w9EiymoaWTDBwX6h/YQE9NbCRsG4RXoP7KoCvXfLyLl9ekrhfh74exrb1KJvSi9m1ojgTlc3jIsJoKreTEZxNZnF1bgZFLFBjlvzRgd6oWk4rEzIK6vl32uPce2UWC7rx3nFrpgQG0BhZb3DRV0AhZX1vLk5kysnRpPoYPelgWZ6fBCB3iY+253H+9uzuWRsRLsyP5vEcD9SIv3apF2+O1zAzBHBdq9EbJOq9vLo2zNKqKgzdzrdYjM+NoDzR4Xx6g8Z1DS0rSffkVna9N46vtL2NLnx5c/n8NdFE7hgVDgH8ipY9kUaC57dwI/f3I6fh5Fzkro3qd3b+u/1X19QChb9p+XrH3/Vd+fSRClFUoRfcy36ieIackpruasTja5sJjStgtyXU05mUQ3Dg7077IEdG2jb6KKmZZPpVj7bnYdVg/vndTw6HYgmNJVL7skpIzLAfpnji9+n02jRuL+TjZ36M6ObgXkpEXzc1C3wtrPiO3z8FROjefrrw+SU1mBpuvK7xcGIPtzfk5hAL7t59NVpp/AwGjg3uesB8+dzk7j2hU28u+UEP2n1+7EtswRPk4Gx0c7nHcL9Pbl+2jCun6b33c8tq2VbRjHbMkoYH+PaYqe+JCP005kbIGsz5KT2Wf356ZJaNelqae7U+WqJxDBfPE0G9uWWN1W4dNzQyLZa1FGly2e7c5kaF2Q32A90Y6L8MRqUwzz6qYo63tmSxdWTY7q1GrY/uripLUJKpJ/TthJXNKUgvtyb39yioaMa7SlxQezMavs91TSNb9JOcU5SaLdWX06NC2J2YggvrT9OXWNLnj41s5RJwwK71KkzJtCLqyfH8uQ1E7hx5nDnT+hjEtBPV3gQXp8Pr86DDU52/j5DEsN9KaluoLiqno3pxYT7eXSpL7jRzcCYphWjmcXVTsvebDnxvLL2KZeD+RUcOlnJVZP6d06xqzxNbiRH+NldYGSxavzj2yNYrBr3zR18VyfnJoWREunH/fOSnJYPDg/xZuKwQD7fm8d3hwsZEerT4c/V1OGBnKyoa1M9dSCvgtyyWi4e0/3t/n4+N4miqnre33YC0DeEPpBXbndB0WAkKZfTGxj/PQAACRlJREFURYxr+ffwntnstrtsjaWOnKpic3pRtzq3jY8J4N2tJzBbNacjSw+jG+F+HuSWtd8A4NPduRgNqt9PEnXHxGEBrNqvVzxYNdiaUczKffl8tf8kRVUN3DRz+KC8OvFyd+OrB1wvBrhiQhRPfHkQo0E53iavia3h1s4Tpc1bHX6TdgqDosNmV66aNSKEGfHBvPj9cW6YOZxdJ0qxathdUDQYyQj9dK37ocdO77vzaMW2Hd3KffkUVTU43JbLFeNjAzE31dm6kiqICWpfumi1aqzYncd5yWHNvToGowmxgZTVNPLLD/cw889ruPGVrSzfkcOMhGCeu3EKjy0c29en2C9cPiEapcBs1ZyuFxgd5Y+nydAm7bI67RRT44II8XV9z9GO/HxeIicr6li+I4ftGSUYFE47Nw4WMkK356db9VYAxv4RrKICPPH1MDZPVHVntWHrFZeOVom2Fh3oRdppZWZbM0rIL6/j/102usvnMRDYdk1auT+fuSnhLBgfzQUpYf2yy15figzwZHp8MGl5FU4rSUxuBibEBDYv1c8uqeFgfgW/6cGfpTmJoUwaFsjza9OJDvRkTLR/hzsfDSZD4112VniK/qefUErfXHp3dhlxId7EBnX9Mn9kmA+eJgNWK82XvB2JDfTim7RTWK1a8+KeT3fl4uPuxoUurLocyJIj/Pj6gXMZFuwlQdyJP189nsLKepcmHifHBfLahgzqGi3N3R27Wq5oj1KK++clcfsb28ktq+V2Jzt6DSYupVyUUvOVUoeVUseUUo/auf9cpdROpZRZKbWo509T2NIu3W3uZHQzMC46gPhQb5fq2GOCvGgwWymq1uux6xotrNyfz/xxUf22QVFPGhXpJ8HcBYnhvi6nAqcOD6LRorE/t5zVaSdJjvDt8b40548Ka74a7Yl2CwOF04CulHIDngMuBcYANyilxpz2sBPAEuC/PX2CQmdbMdrVzRFa++NV4/jrookuPTY6wNZGV690WXuogMo6M1dNHryToaJ32fLZ3x0qYHtmaY9Ut5xOKcWv5o8iPsSbs7rYf34gcmXoMQM4pmnacQCl1PvAlUDzBpyapmU23dc/CrcHobkpEfxwVK9w6a7OdENsXYs+aVggn+zKJczPo9tXCmLoCvX1YHiwN29sysRi1Xo03dLaOUlhrHv4gl45dn/lSsolBshu9XVO022dppS6SymVqpRKLSws7MohhqzEcF/evmNmt3bt6YrmgF5WQ1lNA+sOF7JwYnSPbKoghq4pwwOpabAQ6e/ZI62Rhc6VgG7vN7fjjkUOaJr2sqZp0zRNmxYW1n9bUIoW/p4m/DyM5JXVsXLfSRosVq7u5v6VQtjSLheNiTijnTQHO1dSLjnAsFZfxwIdb/ktBpWYIC9ySmtJy69gZJgPYwdA10DRv81JDMXDaJC5mB7mSkDfDiQppRKAXGAxcGOvnpXoV2ICvdiTU0ZhZT0PXZzc5VWqQtiMCPPl4LL5MjrvYU5TLpqmmYGlwNfAQeBDTdMOKKWWKaUWAiilpiulcoDrgJeUUgd686TFmRUd6EVhpV62eOUkSbeIniHBvOe5VGCradpKYOVpt/2+1b+3o6dixCBkmxidFhfEsODB17tEiMFCerkIp2KaVpReKZOhQvRrEtCFU+cmh3HnnASpbhGin5M1zcKpAC8Tv7389MXBQoj+RkboQggxSEhAF0KIQUICuhBCDBIS0IUQYpCQgC6EEIOEBHQhhBgkJKALIcQgIQFdCCEGCaVpXWpt3v0XVqoQyOri00OBoh48nYFiqL5vGLrvXd730OLK+47TNM3uhhJ9FtC7QymVqmnatL4+jzNtqL5vGLrvXd730NLd9y0pFyGEGCQkoAshxCAxUAP6y319An1kqL5vGLrvXd730NKt9z0gc+hCCCHaG6gjdCGEEKeRgC6EEIPEgAvoSqn5SqnDSqljSqlH+/p8eotS6jWlVIFSan+r24KVUt8opY42/R3Ul+fYG5RSw5RSa5VSB5VSB5RS9zfdPqjfu1LKUym1TSm1p+l9P950e4JSamvT+/5AKeXe1+faG5RS/7+98wmNq4rC+O8jRpAqhIamlKRShCzqoqabEEgXaRCJWqwLBYtCFwU3XSi0iO2mUOiiG+2muypm4R9CNW1x1ZAq7UpqTaBCXFQJtaQkCw3qppL26+Le0CEkq2HyeHfOD4Z3z5nLcD7mvPMO976Z1yFpRtL32S5et6R5SbclzUr6OfuayvNaFXRJHcB54FXgReCQpFIfpfMFMLbG9zEwbbsfmM52aawAx2zvBoaAo/k7Ll37A2DU9kvAADAmaQg4C3yadf8NHKkwxlbyATDXYLeL7v22BxruPW8qz2tV0IFB4I7tP2z/D3wDHKw4ppZg+zrw1xr3QWA8j8eBNzc1qE3A9n3bv+Txv6STvJfCtTvxXzY788vAKHAx+4vTDSCpD3gduJBt0Qa6N6CpPK9bQe8F/myw72Vfu7Dd9n1IhQ/oqTieliJpF7AX+Ik20J6XHWaBJWAK+B1Ytr2Sp5Sa7+eAj4BH2e6mPXQbuCrplqT3s6+pPK/bQ6K1ji/uuywQSc8C3wIf2v4nNW1lY/shMCCpC5gEdq83bXOjai2SDgBLtm9JGll1rzO1KN2ZYdsLknqAKUm/NfuBdevQ7wE7G+w+YKGiWKpgUdIOgHxcqjieliCpk1TMv7T9XXa3hXYA28vAj6Q9hC5Jq41Xifk+DLwhaZ60hDpK6thL143thXxcIl3AB2kyz+tW0G8C/XkH/GngHeBKxTFtJleAw3l8GLhcYSwtIa+ffgbM2f6k4a2itUvaljtzJD0DvEzaP/gBeCtPK0637RO2+2zvIp3P12y/S+G6JW2R9NzqGHgF+JUm87x2vxSV9BrpCt4BfG77TMUhtQRJXwMjpL/TXAROAZeACeB54C7wtu21G6e1RtI+4AZwmydrqidJ6+jFape0h7QJ1kFqtCZsn5b0Aqlz3QrMAO/ZflBdpK0jL7kct32gdN1Z32Q2nwK+sn1GUjdN5HntCnoQBEGwPnVbcgmCIAg2IAp6EARBIURBD4IgKIQo6EEQBIUQBT0IgqAQoqAHQRAUQhT0IAiCQngM4MBZY+kbsikAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet18_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E2)Train lastlayer, LR scheduler, 100 epochs, resnet18 \n",
    "----------------------------------\n",
    "\n",
    "Resnet18, train the last layer only\n",
    "\n",
    "Best val Acc: 0.954248\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=2, bias=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "On CPU this will take about half the time compared to previous scenario.\n",
    "This is expected as gradients don't need to be computed for most of the\n",
    "network. However, forward does need to be computed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.1569 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bashturtle/anaconda3/envs/gpuenv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1721 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.2692 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9346 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1631 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9346 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1761 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.0726 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1650 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.1864 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1709 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.1536 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1647 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.1789 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1792 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.1238 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1687 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.1436 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1763 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1876 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1771 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.2249 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1638 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1375 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1780 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.1589 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1616 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.1265 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1788 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.1740 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1590 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1656 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.1411 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1646 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1030 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1731 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1734 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.2132 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1693 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.1072 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1857 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.1354 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1722 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.1452 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1700 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.2052 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1676 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1542 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1662 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.1165 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1693 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.1668 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1653 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.1571 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1838 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.1552 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1939 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.1471 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1918 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.1815 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1690 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1696 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0917 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1613 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1579 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1692 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1404 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1934 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1582 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1774 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0916 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1745 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1345 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1891 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1127 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1750 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1354 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1962 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.2026 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1575 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.1324 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1689 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1672 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1675 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.1179 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1840 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1405 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1632 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.1996 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1745 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0973 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1916 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1534 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1741 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.1245 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1826 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1340 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1434 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1676 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1566 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1709 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1340 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1681 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1874 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1260 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1710 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.1401 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1794 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0824 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1676 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1652 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1741 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1292 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1645 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1167 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1674 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1721 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1887 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1711 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1198 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1639 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.2223 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1621 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.1461 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1781 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1226 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1817 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1485 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1764 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1256 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1631 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.1678 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1924 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.1738 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1757 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1252 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1761 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1716 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.2258 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1657 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.2058 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1740 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.2011 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1653 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1702 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.1360 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1778 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1781 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.1581 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1628 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.1642 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1741 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.1970 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1812 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1208 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1668 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.1615 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1677 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1061 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.0906 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1832 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.1258 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1744 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1959 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1175 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1660 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1626 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1965 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.1423 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1717 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1980 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1736 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1735 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.0925 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1669 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.0808 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1655 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.0895 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1775 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.1681 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.1899 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1661 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1099 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1812 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.1504 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1842 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1816 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1793 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1679 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.1100 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1466 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1807 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.1177 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1997 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.0699 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1612 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.1352 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1694 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1871 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.1588 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1752 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.1164 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1804 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.1204 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1874 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1641 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1678 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.1531 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1779 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1644 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1640 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.1245 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1959 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.1597 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1644 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.1960 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1779 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1843 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.1211 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1655 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1771 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.1574 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.1394 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1851 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1683 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1854 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.2165 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1820 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.1953 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.2036 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.1362 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1935 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.1374 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1819 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.1301 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1832 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1787 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.1518 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1615 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1743 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.1179 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1766 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.1618 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1711 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1922 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1747 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.0857 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1975 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.1938 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1773 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1602 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1191 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1674 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.1212 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1796 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.1325 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1697 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.1073 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1886 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1723 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.1141 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1667 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.1872 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1805 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1793 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1911 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.1781 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.2008 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1758 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.1271 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1682 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1652 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.1640 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1621 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.1002 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1811 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.2064 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1711 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1325 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1673 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.1158 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1618 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.1643 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1700 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.1388 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1688 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.2083 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1617 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1948 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.1189 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1669 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.1987 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1765 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.1642 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1707 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.1304 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1653 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.1492 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1755 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.0841 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.2024 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1812 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.1318 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1737 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.1646 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1784 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.1822 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1736 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.1192 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1666 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1713 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.1945 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1699 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.1449 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1786 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.1501 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.1815 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1959 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.1399 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1698 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.2279 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1659 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.2510 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1732 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.2376 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1847 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1666 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.1828 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.2119 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.2451 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1897 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.1314 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1959 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n",
      "train Loss: 0.1998 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1880 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.1832 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1939 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1633 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1068 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1642 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.1840 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1742 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.1074 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1804 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1880 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1998 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.1450 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1785 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.1466 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1692 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.1381 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1638 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.1554 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1644 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1598 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.1790 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1744 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.2001 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.2030 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.1180 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1760 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.1318 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1697 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.1901 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1772 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.1787 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1815 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.1618 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.2015 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1611 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.1714 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1703 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.1280 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1667 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1761 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.1851 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1757 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.1128 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1728 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1540 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1804 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1660 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1606 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.1109 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1671 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.1580 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1813 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.1312 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1846 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1420 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1717 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1845 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.1569 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1694 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.1105 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1790 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.0947 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1746 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.1118 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1809 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.0864 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1853 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.1484 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.1889 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1900 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.1009 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1682 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.1223 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1589 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.1410 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1705 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.1452 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1640 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.1320 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1944 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.1208 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1968 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1423 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1829 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.1571 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1713 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1633 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.1207 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1679 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1758 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1738 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.0942 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1699 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.1854 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1761 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1739 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.2210 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1874 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.1340 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1646 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.1327 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1690 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.1625 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.2000 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1745 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.2050 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1701 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.1135 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1800 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.1697 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1599 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.1307 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1600 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.1245 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1843 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.1910 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1804 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.1760 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1783 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1776 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.1363 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1758 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.1591 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1815 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1627 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1851 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1855 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1670 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1983 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.2081 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1937 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1638 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.1357 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1760 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.2064 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1680 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.1762 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1684 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1647 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.2003 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1669 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.1634 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1822 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.1235 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1679 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.2100 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1643 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.1746 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1606 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.1581 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1823 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.1039 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1732 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.1726 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1716 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.1029 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1817 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1714 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.1703 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1715 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.1703 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1936 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.2002 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1732 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.1673 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1783 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.1251 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1816 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.1035 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1737 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.0994 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1681 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.1708 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1772 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1731 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1367 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1757 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.1826 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1656 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.1685 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1890 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.1679 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1805 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.0962 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1696 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1813 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.1096 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1642 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.1179 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1651 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.1885 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1676 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1661 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.1250 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1966 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.1597 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1623 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.1095 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1747 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.1390 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1743 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.1637 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1778 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.1221 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1675 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.1067 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1683 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1770 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.1303 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1714 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.1742 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1783 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.0848 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1761 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1179 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1686 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.1843 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1794 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.1409 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1727 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.1625 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1607 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.1421 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1678 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.2656 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1719 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.1677 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1937 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.1683 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1907 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1515 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1794 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1215 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1762 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.1348 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1694 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1558 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.1567 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1678 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.1609 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1646 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.1781 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1813 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.1301 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.1861 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1698 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.1527 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1702 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.1730 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1987 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1468 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1752 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.1941 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1637 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.1472 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1884 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.1668 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.0995 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1667 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1793 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.1493 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1905 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1854 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.1432 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.2064 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.1785 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1727 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.2003 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1687 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.1424 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1631 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1722 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.1876 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1614 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.1890 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1855 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.1596 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1834 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1993 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.1749 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1784 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1625 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1718 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1906 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1227 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1782 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.1376 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1704 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.1792 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1766 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1775 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1674 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.1221 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1736 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.1290 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1714 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.1580 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1756 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1646 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.1562 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1804 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.1564 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1627 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1628 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.1260 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1668 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.1615 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1720 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.1335 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1715 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.1091 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.2036 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1887 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.1311 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1786 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.1455 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1692 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.1523 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1760 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1863 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.1480 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1694 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.1501 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1864 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1633 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1853 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.1570 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1760 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1773 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.1731 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1667 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.0978 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1614 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.1699 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1763 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.1605 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1658 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.2750 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1778 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1722 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.1124 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1895 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.1580 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1762 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.1595 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1735 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.1801 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1888 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.1630 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1676 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1737 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1246 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1647 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.1585 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1810 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.1472 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1652 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.1667 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1813 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.1561 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1717 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.1644 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1720 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.1651 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1916 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.1963 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1762 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.1381 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1717 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.1837 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1629 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.1287 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1639 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.1310 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1746 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.1872 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1799 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.1588 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1573 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.1019 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1631 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1857 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1668 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.1269 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1726 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.1172 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1772 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.1828 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1588 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.1281 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1733 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.1583 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1938 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.1020 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1756 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.1668 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1679 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.2066 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1745 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1710 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1284 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1660 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.1649 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1842 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.1531 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1655 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.1256 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1706 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1073 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1795 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.1838 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1798 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1604 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1713 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.0986 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1764 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1618 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1665 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1740 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1695 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.1098 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1773 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1625 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1704 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.2224 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1663 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.1425 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1647 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.1142 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1692 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.1660 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1728 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.1736 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1679 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.1247 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1892 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.1129 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1639 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.1716 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.1076 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1714 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.1798 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1910 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.1326 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1723 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1930 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.1579 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1650 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1647 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.1387 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1665 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.1280 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1706 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1675 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.2165 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1681 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.1154 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1726 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.1133 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1694 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.1350 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1691 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.1774 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1793 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.1409 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1889 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1670 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1575 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.1380 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1943 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.1091 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1699 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.2039 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1719 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.1781 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1754 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.0973 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1952 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.1560 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1731 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.2033 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1623 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.1224 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1745 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.1265 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1747 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.1299 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1657 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1896 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.1217 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1646 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.1684 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1790 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.2001 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1664 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.1765 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.0952 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1717 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.1332 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1686 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n",
      "train Loss: 0.1851 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1820 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.1177 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1749 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1663 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.0903 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1768 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.0897 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1796 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.1384 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1660 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1946 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1851 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1661 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.1215 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1775 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.1467 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1811 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.2158 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1822 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1774 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.2284 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1959 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1808 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.1563 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.2010 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1780 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.1722 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1828 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.1073 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1856 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1658 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1951 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1728 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1781 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.1584 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1682 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.1698 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1780 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.1393 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1716 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1374 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1812 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.1273 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1778 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.1418 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1912 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.1983 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1604 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1635 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.1214 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1619 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.1422 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1737 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1404 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1625 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1843 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.1286 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1695 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Training complete in 12m 40s\n",
      "Best val Acc: 0.954248\n"
     ]
    }
   ],
   "source": [
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet18_lrscheduler_lastlayer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E3)Train wholenetwork, LR scheduler, 1000 epochs, resnet34 \n",
    "----------------------------------\n",
    "\n",
    "Resnet34, train the whole network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5683 Acc: 0.6967\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6967\n",
      "val Loss: 0.2942 Acc: 0.8693\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.8693\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.2670 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.8693 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1716 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.8693 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.2942 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9346 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1524 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9346 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.2833 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1684 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.1692 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1636 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1614 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.2486 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.2100 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.1933 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1947 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.1666 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1903 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1692 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.1448 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1006 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1702 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.2150 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1870 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.1355 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1933 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.0867 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1905 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.0946 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1671 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.2235 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1954 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1122 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1590 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1035 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1621 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.1589 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1779 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.1227 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1684 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.1165 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1852 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1671 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.0876 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1653 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1686 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1626 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.1534 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1832 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0940 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1737 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1616 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.1721 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1740 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1732 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1590 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1665 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1717 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0743 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1709 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0614 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1615 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1353 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1766 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1576 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1534 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1372 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1657 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1567 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1095 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1776 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.1333 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1679 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.1028 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1680 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.2136 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1589 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.1407 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1934 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1409 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1584 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1737 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.0855 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1687 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.0983 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1640 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.1054 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1651 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1990 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1721 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1070 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1832 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1226 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1577 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1763 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1596 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.1072 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1782 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1339 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1682 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.1370 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1536 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1595 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1391 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1746 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1668 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1813 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1636 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1719 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1100 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1700 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1692 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1715 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1750 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1670 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1181 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1612 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1036 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1621 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.1293 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1612 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.1355 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1658 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1601 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.2119 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1674 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.1141 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.1737 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1600 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.1001 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1651 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.1573 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1666 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.2030 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1778 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.2125 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1570 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.1010 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1624 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.1853 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1597 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.1334 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1688 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1243 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1693 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.0763 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1646 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1766 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1724 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1635 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.1120 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1716 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.0770 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1992 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.1236 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1648 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1271 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1623 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1269 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1659 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.1167 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1581 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1681 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1590 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.1629 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1802 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0793 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1646 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.1040 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1613 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.1952 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1790 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.0602 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1650 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.0841 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1668 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1041 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1640 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1710 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1680 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1036 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1584 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.1362 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1633 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1271 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1530 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.1077 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1551 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1729 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.1238 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1619 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.1040 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1588 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.1888 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1612 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.1576 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1639 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1472 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1650 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.0997 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1526 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.0962 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1609 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.0945 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1654 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1674 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.0932 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1597 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.2168 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1600 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1612 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.0843 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1556 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.0915 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1529 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1568 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.1415 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1611 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.1164 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1624 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1694 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.1135 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1611 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.1023 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1730 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.1236 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1593 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.1299 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1512 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.1690 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1827 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1576 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.1860 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1635 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.1613 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1895 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.1395 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1754 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.1503 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1663 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.1591 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1577 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.1009 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1686 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.0994 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1626 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.1369 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1764 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.1509 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1640 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1559 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.1339 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1650 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1791 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.0946 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1809 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1726 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.1076 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1688 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1623 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.0996 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1614 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.0631 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1667 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.0973 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1726 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.0905 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1623 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1649 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.1275 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1682 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.0993 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1676 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1730 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.1652 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1934 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1447 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1592 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1568 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.1307 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1539 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1621 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.1331 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1770 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.1869 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1744 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1560 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1652 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.1511 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1661 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.1145 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1577 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.1332 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1626 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.1170 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1644 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.0949 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1746 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1622 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.1190 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1567 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.1422 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1629 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.1076 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1669 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.1171 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1671 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.1379 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1601 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.1005 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1688 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.1616 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1631 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1571 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1606 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1599 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1618 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.1198 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1650 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.1109 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1606 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.0866 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1606 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.1727 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1608 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.1978 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1700 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2152 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1702 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.0878 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1924 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.1208 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1632 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1674 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.0591 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1651 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.1096 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1662 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1652 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1567 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1797 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.1485 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1589 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1599 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.1108 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1586 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1521 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.0758 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1619 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.1859 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.1154 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1659 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.1743 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1663 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.1484 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1600 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.0838 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1549 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.1007 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1540 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.1427 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1725 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.1082 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1579 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.1735 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1597 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1657 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.1713 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1646 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.0804 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1690 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1803 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1634 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.1524 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1601 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1696 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.1324 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1599 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.1711 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1600 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1124 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1655 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.1388 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1771 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.1529 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1769 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.1274 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1609 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.1063 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1722 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.1775 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1694 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.1536 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1628 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1719 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.0928 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1815 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.1635 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1600 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1742 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.0912 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1591 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.0894 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1637 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.1431 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1564 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.1124 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1667 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1701 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.0969 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1573 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.1660 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1706 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.1377 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1614 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1090 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1622 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.0676 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1694 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.1766 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1672 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1599 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.1962 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1761 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.1068 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1904 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.0733 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1580 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.1259 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1552 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.0757 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1619 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.1146 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1623 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1703 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1592 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.1289 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1563 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1667 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.1267 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1767 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.0926 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1617 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.1280 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1617 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1575 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.1460 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1694 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.1163 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1679 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.1152 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1660 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1145 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1615 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1395 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1491 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1550 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.1995 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1595 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.1225 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1642 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.0992 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1583 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1626 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.1274 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1650 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.1149 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1657 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.1290 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1673 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.1468 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1574 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1668 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1779 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.1592 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1626 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.1015 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1811 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1605 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.0949 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1686 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.1450 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1605 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.1779 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1845 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.1521 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1998 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.1037 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1662 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2106 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1721 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.1400 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1600 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.1685 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1618 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.0926 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1692 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.1637 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1569 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.0870 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1587 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.1398 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1742 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1011 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1578 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.1441 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1564 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.1129 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1659 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.1085 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1689 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.1755 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1611 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.1388 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1593 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.1391 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1584 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.1016 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1708 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.1106 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1576 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1752 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.0814 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1594 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.1242 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1535 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.1342 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1744 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1708 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.1020 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1500 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.1113 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1629 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.1308 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1715 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.0900 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1703 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.0927 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1685 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.0958 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1602 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.0930 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1632 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1492 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1736 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.1312 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1589 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.2349 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1739 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.1075 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1640 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.1246 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1648 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.1917 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1648 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.2045 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.0827 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1786 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1185 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1638 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1793 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1552 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.0922 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1744 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.1073 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1725 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.0675 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1563 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.1175 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1606 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.1614 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1620 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.1072 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.1056 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1665 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.1453 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1660 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1765 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.0955 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1734 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.1307 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1705 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.1526 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1646 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.1771 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1635 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.1346 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.1003 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1703 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1303 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1762 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.1099 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1654 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.1410 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1547 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1564 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1603 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.1222 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1559 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1718 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.2211 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1645 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.0756 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1652 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.1586 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1756 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1712 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.0952 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1606 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.0932 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.1661 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1693 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1136 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1694 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.1406 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1550 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.0987 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1526 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.1175 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1628 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.0836 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1678 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.1064 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1704 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.1350 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1706 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.1571 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1663 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.0722 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1617 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.1691 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1733 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.1275 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1624 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.0894 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1610 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.1440 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1697 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.1530 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1700 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.0756 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1626 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.1689 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1606 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.1618 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1534 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.1718 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1679 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.1384 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1558 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.0946 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1717 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.1387 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1589 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.0692 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1647 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.0782 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1680 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1443 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1751 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.1530 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1593 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1621 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1653 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1792 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.1312 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1725 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1592 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.1082 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1652 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.1003 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1646 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.0752 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1646 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.2067 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1835 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1630 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.1507 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1916 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.1655 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1578 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.0883 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1658 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.1565 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1618 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.0883 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1657 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.0998 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1844 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.1904 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1735 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1644 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.0889 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1637 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.0722 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1613 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1590 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.1523 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1751 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.1885 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1701 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.1291 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1608 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.1042 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1724 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.1758 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1587 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1643 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.1390 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1554 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1731 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1660 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.1120 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1616 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1662 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1707 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.1378 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1668 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.2005 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1549 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.1630 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1674 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.1021 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1762 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.1538 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1616 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.1846 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1627 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1858 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1553 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.0791 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1542 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.1556 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1618 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.1297 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1754 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1032 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1670 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.1184 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1662 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1493 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1610 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1873 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.1135 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1633 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.1918 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1658 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.1206 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1511 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.1510 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1644 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1683 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1747 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.0872 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1723 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.0749 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1735 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1540 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.1198 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1671 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.0996 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1674 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.0841 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1670 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1688 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1796 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.0639 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1668 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.1477 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1755 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.1522 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1668 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1645 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1049 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1644 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.0555 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1639 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.1427 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1683 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.1782 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1635 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.1453 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1622 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.1295 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1560 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.1732 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1664 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.1092 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1600 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.1009 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1713 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.1148 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1550 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1507 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1649 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.1531 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1641 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1663 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1841 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.1104 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1651 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.0778 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1616 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.0960 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1616 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.1228 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1696 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.1114 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1701 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1706 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.1418 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1631 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.1604 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1585 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.1295 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1884 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.1165 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1515 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.0909 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1659 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.1431 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1752 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.1371 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1677 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1777 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.0939 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1708 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1368 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1648 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.1578 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1637 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1653 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.1074 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1622 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.1045 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1602 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.1276 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1656 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.1926 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1624 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.1041 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1673 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.0965 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1531 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.1700 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1708 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.1127 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1633 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.1155 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1734 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.1008 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1598 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.1428 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1787 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.1392 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1543 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.1293 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1592 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.1714 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1717 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.0867 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1730 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.1740 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1650 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1097 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1615 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1529 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.1391 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1705 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.1258 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1626 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.1459 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1607 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1658 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1224 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1569 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.1366 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1737 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.1371 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1636 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.1612 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1618 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.0805 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1577 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1752 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.1620 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1672 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1823 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1662 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.0981 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1631 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1659 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 15m 40s\n",
      "Best val Acc: 0.960784\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet34_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E4)Train lastlayer, LR scheduler, 100 epochs, resnet34 \n",
    "----------------------------------\n",
    "\n",
    "Resnet18, train the last layer only\n",
    "\n",
    "Best val Acc: 0.954248\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.2349 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1560 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1552 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1531 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.2006 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1479 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1644 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1542 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.2115 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1487 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.2417 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1503 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.1651 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1485 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.2002 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1533 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.2549 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1515 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1698 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1509 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.1431 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1511 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1946 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1492 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.1617 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1486 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.2341 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1491 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.2016 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1498 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.1360 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1499 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.1568 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1509 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1368 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1541 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1728 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1459 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.1673 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1495 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1510 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.2617 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1529 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.1986 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1550 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.2031 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1512 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1682 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1506 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.2259 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1449 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.2349 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1454 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.1633 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1482 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.1643 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1565 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.1582 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1524 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.2674 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1527 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1478 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1859 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1515 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1878 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1520 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1464 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1499 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1955 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1484 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.2239 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1538 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1577 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1595 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1505 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.2182 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1511 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.1470 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1500 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.1850 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1644 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1606 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1512 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.2217 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1539 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1964 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1521 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.1679 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1457 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.2291 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.1929 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1545 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.2255 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1547 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1662 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1558 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1670 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1535 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.2081 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1569 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.1986 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1536 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1941 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1520 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1493 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.2597 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1524 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1881 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1477 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1478 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.2804 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1496 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1811 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1525 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1721 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1500 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.2149 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1515 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1606 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1513 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.1603 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1409 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1864 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1539 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1605 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1502 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1716 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1507 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.1891 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1483 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.1801 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1904 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1447 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.2612 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1455 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.1879 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1442 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.2667 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1510 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.1653 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1594 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.1630 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1509 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.1331 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1478 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.1585 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1464 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.1706 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1551 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.2041 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1522 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.1889 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1496 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1988 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1515 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.1802 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1530 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.1563 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1479 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1925 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1522 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.1939 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1490 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.1880 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1470 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.1491 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1561 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1621 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1872 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1546 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.2160 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1487 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1418 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1453 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.2235 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1524 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1784 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1500 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.1787 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1493 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.1575 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1486 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1534 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.1605 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1423 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1434 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1592 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.2734 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1507 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.1616 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1510 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1457 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1483 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.2088 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1532 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1544 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1492 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.2152 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1432 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.2198 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1537 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.1691 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1644 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.2182 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1483 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.1538 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1483 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.2217 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1605 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1824 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1433 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.1610 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1493 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.1428 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1620 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.1654 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1524 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.1916 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1536 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.2253 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1433 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.2213 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1497 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.2445 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1504 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.1769 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1486 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.1724 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1519 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.1683 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1550 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.1984 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1492 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.1919 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1547 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.1438 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1476 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.2254 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1500 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.1441 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1460 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.2024 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1502 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.2055 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1591 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.2392 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1520 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.2470 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.1626 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1451 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.2221 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1469 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1533 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.2123 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1487 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.1923 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1465 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.1619 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1449 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.1748 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1529 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.2091 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1495 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.1478 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1539 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.1899 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1450 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1507 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.1669 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1681 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.1661 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1468 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.1771 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1469 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1538 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.1695 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1498 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.1858 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1549 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.1858 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1602 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1561 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.1782 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1555 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.2306 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1514 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.1769 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1645 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.2045 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1485 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.2486 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1503 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.1621 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1537 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1655 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1532 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.1574 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1424 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.1779 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1491 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.1739 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1503 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.2220 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1587 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.2481 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1542 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.2263 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1546 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1572 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.1967 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1535 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.1556 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1449 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.1908 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1501 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1464 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.1864 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1589 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1488 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1527 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.2317 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1500 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.1710 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1540 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.1555 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1512 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.1834 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1527 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.1382 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1466 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.2006 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1487 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.1678 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1413 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.1339 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1595 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.2308 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1475 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.1862 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1479 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1519 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.1405 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1484 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.2477 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1477 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.1719 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1530 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.1741 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1561 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1848 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1505 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.1464 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1522 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.2143 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1470 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1975 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1619 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.2248 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1475 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1537 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.1806 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1471 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.2349 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1396 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.1902 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1479 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.2846 Acc: 0.8689\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8689\n",
      "val Loss: 0.1524 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.2010 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1486 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.1915 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1463 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1674 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1469 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.1900 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1542 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.1400 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1494 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.2341 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1618 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1523 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.2303 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1485 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.1723 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1472 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.2066 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1526 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.2176 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1457 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.1705 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1612 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.2071 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1477 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.1812 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1476 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.1642 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1459 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.1624 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1518 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1777 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1585 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.1494 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1495 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.2146 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1488 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.2218 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1475 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.1563 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1488 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.2132 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1508 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1612 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1465 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.2032 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1451 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1531 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.1712 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1474 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.1913 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1490 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.2398 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1507 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.1901 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1484 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.2363 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1459 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.2028 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1458 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.2023 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1455 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.2105 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1481 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.1310 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1491 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.2165 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1483 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.2273 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1452 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.1538 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1511 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.1982 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1532 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.1787 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1436 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.2092 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1531 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1549 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1949 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1558 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.2237 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1507 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.2101 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1474 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.1991 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1476 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1580 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.1619 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1587 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.2049 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1479 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.1582 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1456 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.2005 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1517 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.1722 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1559 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.2146 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1513 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.1900 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1519 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.1864 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1485 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.1554 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1435 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.2109 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1475 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.1373 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1523 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.2134 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1448 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.2060 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1521 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.1859 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1497 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.1163 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1507 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1541 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1512 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1742 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1557 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.1877 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1542 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.1980 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1452 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.2081 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1454 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.1449 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1447 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.2396 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1544 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.2408 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1536 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.2470 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1579 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.1790 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1486 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.1547 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1511 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.1519 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1518 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.2318 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1585 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.1838 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1601 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.2400 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1539 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.2100 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.1912 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1519 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.1911 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1476 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.1529 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1506 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.1573 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1515 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.2279 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1491 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2301 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1411 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.1796 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1437 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.1712 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1567 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.1659 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1545 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.1786 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1518 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.1820 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1590 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.2132 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1529 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1883 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1522 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.2259 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1540 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.1824 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1519 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.2013 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1513 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.1695 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1448 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.2004 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1494 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.2453 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1509 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.2385 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1551 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.2388 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1550 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1504 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1549 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.1753 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1533 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.2535 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1494 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.2006 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1460 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.1645 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1481 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.1612 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1558 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.2021 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1481 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.1754 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1507 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.2030 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1461 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.1728 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1536 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.1689 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1581 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1700 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1441 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.1976 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1484 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.2369 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1581 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1534 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.1629 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1573 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.2113 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1505 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.1902 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1508 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.1559 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1487 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1934 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1540 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1954 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1446 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.1719 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1430 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.1595 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1539 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.2324 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1540 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.1823 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1542 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.2120 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1475 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.1724 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1480 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.1417 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1554 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.2012 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1587 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.1550 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1510 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.2024 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1561 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.1596 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1560 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1474 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.2077 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1561 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.1746 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1490 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.1957 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1465 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.1784 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1542 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1717 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1542 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.1670 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1523 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.1879 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1465 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.1781 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1594 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.2268 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1519 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.1181 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1568 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.2606 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1485 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.1802 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1440 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.1556 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1494 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.1955 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1508 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.1770 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1549 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.1913 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1466 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.2024 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1476 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1561 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1542 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1535 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.1818 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1458 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.1432 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1614 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.1515 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1573 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.1496 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1501 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.1681 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1558 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.2872 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1555 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.1425 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1497 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.1799 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1492 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.1469 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1483 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.1834 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1457 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.1635 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1457 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.2493 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1538 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.1698 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1502 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.1524 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1499 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.1583 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1511 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.2037 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1495 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.1195 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1409 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.1677 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1434 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1496 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.1581 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1475 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.1891 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1467 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.1595 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1543 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1975 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1635 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.2450 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1447 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1713 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1442 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.2111 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1462 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.2155 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1616 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.2090 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1521 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.1696 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1490 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1599 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.2201 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1575 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.1968 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1494 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.1703 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1520 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.1755 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1527 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.2199 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1479 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.1914 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1520 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.1963 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1536 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1477 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.2014 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1458 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.2076 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1467 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.1705 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1503 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.2072 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1474 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.1896 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1554 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.2301 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1438 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.1592 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1515 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.1896 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1538 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1521 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.1791 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1537 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.2195 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1518 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.2264 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1581 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.2064 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1422 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.2025 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1500 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1723 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1532 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.1789 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1638 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.1866 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1458 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.1750 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1525 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.2104 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1495 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.2180 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1464 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.1627 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1481 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1557 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.2216 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1523 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1564 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1892 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1641 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.1616 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1567 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.2083 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1497 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.2073 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1622 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1964 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1480 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.1988 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1577 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1542 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.1350 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1518 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.1673 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1472 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.1838 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1557 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.1728 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1643 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1581 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1915 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1454 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1504 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1524 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.1875 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1514 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.1999 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1541 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.1690 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1415 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1489 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.1978 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1559 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.1455 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1541 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1527 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.1732 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1579 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.2530 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1475 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.1955 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1509 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.2162 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1464 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1838 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1478 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.2128 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1547 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.1798 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1697 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.1801 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1520 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1591 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.1883 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1541 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1631 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.2257 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1484 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.1504 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1441 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.1697 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1499 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1522 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.1767 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1556 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.1761 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1493 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.2074 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1526 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.1503 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.1915 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1530 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.1893 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1535 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1436 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.1534 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1525 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.2378 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1481 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1500 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.2166 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1555 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.1726 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1566 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1542 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.1673 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1496 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.1561 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1540 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.2189 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1548 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.1477 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1527 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.1728 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1557 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2162 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1495 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1509 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.1480 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1551 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.1942 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1515 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.1717 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1525 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.2204 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1474 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.2566 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1453 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.1766 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1496 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.1692 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1454 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.2138 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1457 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.1787 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1502 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.1645 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1507 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.1668 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1474 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.1801 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1482 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.1776 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1511 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.1313 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1551 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.1634 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1516 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.1655 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1568 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.1891 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1432 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1868 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1410 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1701 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1485 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.2209 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1506 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.1838 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1410 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.1746 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1570 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.2187 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1525 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1716 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1495 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.2155 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1442 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.1413 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1480 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.2100 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1530 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.2260 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8975\n",
      "val Loss: 0.1522 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.1542 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1529 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.1795 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1557 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1733 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1639 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.2529 Acc: 0.8770\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8770\n",
      "val Loss: 0.1537 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.1465 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1588 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9608\n",
      "\n",
      "Training complete in 16m 1s\n",
      "Best val Acc: 0.967320\n"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.resnet34(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet34_lrscheduler_lastlayer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E5)Train wholenetwork, LR scheduler, 500 epochs, resnet50 \n",
    "----------------------------------\n",
    "\n",
    "Resnet50, train the whole network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.4558 Acc: 0.8238\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.8238\n",
      "val Loss: 0.2793 Acc: 0.9020\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9020\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.2579 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9020 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1590 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9020 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1199 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1988 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1521 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1693 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.1314 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1302 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.1540 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1629 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.2000 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1800 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.1740 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1913 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.0559 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1586 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.1311 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1599 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1594 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.1175 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1779 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.1351 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1457 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.1473 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1543 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1652 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.1995 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1395 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.0952 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1372 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1234 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1406 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.1152 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1494 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0869 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1693 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.1308 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1560 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.0847 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.2245 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1384 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1347 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1655 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.1726 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1424 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0932 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1689 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0810 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1822 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1370 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1787 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1190 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1495 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1095 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1456 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1782 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0847 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1550 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.1147 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1681 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1150 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1427 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1382 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1441 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1503 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0977 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1571 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0830 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1373 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1412 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1614 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.1194 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1481 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.0665 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1767 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.1167 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.1091 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1377 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.1133 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1602 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.1633 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1569 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1222 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1533 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1213 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1996 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0818 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1716 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1634 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1450 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0982 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1055 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1852 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.1088 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1498 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1621 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1802 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1095 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1439 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1924 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1765 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1427 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1688 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1172 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1807 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1141 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1581 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1045 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1508 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0926 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1361 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1724 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1502 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1610 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1497 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1200 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1580 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.2131 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1463 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1328 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1914 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1412 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1352 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.1201 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1643 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.1084 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1733 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.2103 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1768 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.0977 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1647 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.1765 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1591 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.2060 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1466 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.0951 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1803 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.1268 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1609 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.0812 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1647 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.1296 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1450 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.0595 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.2116 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1461 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.1186 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1720 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.1205 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1474 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.0742 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1720 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1149 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1735 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.1096 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1472 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1500 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.0840 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1623 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0685 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1751 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.1868 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.1452 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1444 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.0561 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1444 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1762 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1607 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1588 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.1317 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1568 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.1486 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1676 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1308 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1365 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.1001 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1467 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1093 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1580 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.1061 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1585 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.1463 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1529 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1602 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.0764 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1470 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.1276 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1566 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.0709 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1728 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1316 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1503 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.1541 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1560 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1433 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.0801 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1522 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.1312 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1661 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.0943 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1688 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.0971 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1372 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.1099 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1635 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.0915 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1371 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.1088 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1562 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.1584 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1789 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.0807 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1910 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.1037 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1634 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.0599 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1341 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.1048 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1510 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1480 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1584 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.1523 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1501 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1830 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.1115 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1405 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.1372 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1504 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.0858 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1417 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.1048 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1451 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.0635 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1724 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.1087 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1547 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.1207 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1706 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.0967 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1583 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.1136 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1398 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.1116 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.1062 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1761 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.0837 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1535 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.1473 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1444 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.1165 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1383 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.0990 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1431 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.1779 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1454 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1338 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.1315 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.2128 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.1492 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1609 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1528 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.2204 Acc: 0.8852\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8852\n",
      "val Loss: 0.1548 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.1057 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1704 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.1086 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1447 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.0998 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1741 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.1805 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1391 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1689 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1379 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.0660 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.1130 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1544 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.1424 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.0889 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1421 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.1661 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1695 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.1105 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1569 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.0805 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1500 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.1232 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1438 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.1279 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1549 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1526 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.1228 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1780 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.0651 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1374 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.1309 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1448 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.1924 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1404 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.1048 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1433 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.1340 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1809 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1774 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.0996 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1492 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.1109 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1363 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.1468 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.1247 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1505 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.1324 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1507 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.0983 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1417 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.0936 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1370 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1423 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.1425 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1511 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.1746 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1698 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.1784 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1788 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1601 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1861 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.1180 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1517 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1267 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1423 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.1383 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1509 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.1119 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1496 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.0996 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1466 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1351 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.1480 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1459 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.1662 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1500 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.0901 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1382 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1054 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1557 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.1475 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1681 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.1079 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1498 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1435 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1489 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1475 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.1722 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1383 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.1904 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1632 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.0973 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1708 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.1042 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1746 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.2732 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1389 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.1132 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1564 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.0856 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1313 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.1215 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1437 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1524 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1488 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.1210 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.0881 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1618 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.1182 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.2580 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1398 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1574 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1720 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1604 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.0959 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1748 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1366 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.1585 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1372 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.1299 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1409 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.1699 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1398 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.0874 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1351 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1496 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.1027 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1433 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.0811 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1532 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.0699 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1588 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.0938 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1386 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.1185 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1369 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1546 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.1021 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1469 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1558 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.1020 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1624 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1575 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.0966 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1061 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1460 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.1181 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1452 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.1245 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1650 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.1608 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1727 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.0944 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1584 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1490 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1444 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.1089 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1311 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1507 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1934 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.2070 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1408 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.0883 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1655 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.0977 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1396 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.0675 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1476 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.1678 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1310 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.2096 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1330 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1551 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.1208 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1358 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.1399 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1496 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.0928 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1361 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.0891 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1704 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1555 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1395 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1889 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1719 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.1711 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1416 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.1520 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1607 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.0746 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1457 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.0603 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1451 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.1042 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1353 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.0959 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1519 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.0710 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1506 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.1733 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1556 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.1746 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1414 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.1773 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1617 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.0868 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1438 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.0853 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1514 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.1042 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1625 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.1306 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1501 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.0961 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1818 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.1889 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1507 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.2438 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1456 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.1011 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1626 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1273 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1401 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.1394 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1360 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.1021 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.0499 Acc: 0.9959\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9959\n",
      "val Loss: 0.1401 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.1262 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1639 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1755 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.1054 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1421 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1349 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1674 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.2170 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1610 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.1107 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.1189 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1579 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.1254 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1514 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.1463 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1918 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.1588 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1776 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.1763 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.2024 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1601 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.1497 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1691 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.1175 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1501 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.1087 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1606 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.1097 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1401 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.1414 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1535 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.1495 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.1636 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1440 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.1203 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1626 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.2446 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1498 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.1016 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1459 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1231 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1555 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.0783 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1732 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.1734 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1524 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.1952 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1574 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.1469 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1372 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1438 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.1066 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1594 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.1358 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1377 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1613 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1441 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1715 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.1751 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1461 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.1118 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1349 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.1013 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1283 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.0901 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1600 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.1155 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1681 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.1657 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.1351 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1633 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.2023 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1469 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.2052 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1343 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.1304 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1626 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1375 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1372 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.1147 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1762 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.1307 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1555 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.1709 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.1540 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1381 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1038 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1274 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.0719 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1634 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.0742 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1442 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.1768 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.1935 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1384 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.0866 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1400 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.1322 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1369 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1414 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.1684 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1384 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.0697 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1764 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.1281 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1442 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.1040 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1641 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.1574 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1520 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.1160 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1633 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1549 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.1035 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1837 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.1050 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1448 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.1293 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1549 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.0771 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1740 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.0752 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1866 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.1307 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1504 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.0689 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1482 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1700 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1392 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.1027 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1440 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.0931 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1420 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1520 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.1206 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1528 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.1203 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1587 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.1065 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1650 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.0843 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1437 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1668 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.1772 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1891 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.1507 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1615 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.0797 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1360 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.0931 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1239 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1374 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.1303 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1532 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1129 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1648 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.0962 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1463 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.1177 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1508 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.1818 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1620 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.0881 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1505 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.1176 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1599 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.1182 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1688 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.1473 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1685 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.1446 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1417 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.0474 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1551 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.0891 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1595 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.0893 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1291 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9959\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9959\n",
      "val Loss: 0.1375 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1270 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1331 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.0900 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1763 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1683 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.0665 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1636 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.0988 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1478 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.1581 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1720 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.1823 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1400 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.0957 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1570 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1783 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.1082 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1557 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.0990 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1382 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.1600 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1508 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1387 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.1120 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1413 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.2020 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1456 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1029 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1354 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.1260 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1911 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.0833 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1658 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.1449 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1428 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.0988 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1732 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.0696 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1572 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.0951 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1503 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.0960 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1602 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.0898 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1777 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1901 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1553 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1668 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.1149 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1726 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.0755 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1486 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.1624 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1529 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1376 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1268 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.1706 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1740 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1550 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.1610 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1832 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.0930 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1497 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.0889 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1538 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1058 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1585 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1722 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.0882 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1741 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1523 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1497 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.0940 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1378 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.0757 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1714 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.1314 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1589 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1511 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.1462 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1494 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.1195 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1673 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.1450 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.1442 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1507 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1428 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1141 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1551 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.1162 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1419 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.0809 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.1490 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1400 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.0874 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1405 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1321 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.1443 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1652 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.1057 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1927 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.0838 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1619 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1022 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1318 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.0648 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1463 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.0659 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1415 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.1036 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1425 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.1592 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1365 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1682 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.1441 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1511 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.0756 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1512 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.1163 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1547 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.1751 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1296 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.1613 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1464 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.1054 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1297 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1833 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1676 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.1131 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1559 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.1137 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1364 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.1920 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1773 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.1923 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1448 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.1640 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1576 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0834 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1402 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.3046 Acc: 0.8811\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8811\n",
      "val Loss: 0.1368 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.1667 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1665 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.1105 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1449 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.1343 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1520 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.1357 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1396 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.1815 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1702 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.0995 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1495 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.1468 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1764 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.0468 Acc: 0.9959\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9959\n",
      "val Loss: 0.1524 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.1173 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1713 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1858 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.0892 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1430 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.0579 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.0877 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1549 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.0741 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1564 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1651 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.1283 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.1386 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1413 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1593 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1649 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1155 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1472 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.1189 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1395 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.0752 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.0889 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1500 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.2105 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1400 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1547 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.1306 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1716 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.1183 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1782 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.1552 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1346 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.1394 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1374 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1418 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.0948 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1575 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1532 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.0948 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1377 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1462 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Training complete in 20m 42s\n",
      "Best val Acc: 0.960784\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet50_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E6)Train lastlayer, LR scheduler, 100 epochs, resnet50 \n",
    "----------------------------------\n",
    "\n",
    "Resnet18, train the last layer only\n",
    "\n",
    "Best val Acc: 0.954248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.1173 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1566 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1781 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9281 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1469 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9281 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.1529 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1459 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.2530 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1616 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.1955 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1414 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.1764 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1343 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.1311 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1454 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.1770 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1338 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9412 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.1194 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1389 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1262 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1251 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9477 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.1799 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1222 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1631 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1534 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.0773 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1435 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.1313 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1383 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.1476 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1450 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.1250 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1527 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.0873 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1305 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1377 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1327 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1552 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1506 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.1448 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1220 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.1290 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1272 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.1400 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1202 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.0962 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1644 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1150 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1373 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.1104 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1387 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.1508 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1462 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.1065 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1457 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.1275 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1521 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0725 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.1462 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1440 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1558 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1463 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1320 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1540 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1033 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1390 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1629 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1525 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1570 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1307 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.1901 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1415 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1859 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1312 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1683 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1338 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1950 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1333 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.1625 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1419 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.1968 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1344 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1745 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1407 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.1656 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1190 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1998 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1431 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.1958 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.1534 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1267 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.1431 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1311 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1303 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1002 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1327 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.2325 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1386 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1058 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1360 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1455 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1231 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0883 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1575 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1345 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1453 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.1946 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1321 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1697 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1397 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1224 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1241 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1065 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1491 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1301 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1342 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1332 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1309 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1741 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1287 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1232 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1291 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1070 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1273 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.1342 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1628 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1267 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1360 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.0886 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1641 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1469 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1514 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0866 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1583 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0887 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1687 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1038 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1607 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.1023 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1359 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.2075 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1238 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.1302 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1219 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1857 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1381 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.0999 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.2508 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1430 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.1292 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1571 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.1198 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.1590 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1257 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1425 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1418 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.2548 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1490 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.1131 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1367 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1615 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1547 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.1322 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1817 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1563 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.1823 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1632 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1558 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1414 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.2222 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1457 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0855 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1414 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1825 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.2010 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1550 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1926 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1311 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1357 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.1195 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1667 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.2215 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1421 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.1683 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1324 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1370 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1504 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.1139 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1299 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.1457 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1306 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1700 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.1114 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1337 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1347 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.1460 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1345 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.1919 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1570 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.1420 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1543 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1524 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.0942 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1312 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.1658 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1333 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.1359 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1373 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1639 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1369 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.1829 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1454 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.1354 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1621 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.1166 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1212 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.0998 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1239 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.1074 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1556 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.1393 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1516 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.1166 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1509 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.2127 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1352 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.1074 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1466 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1488 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.0857 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1413 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.1559 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1513 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.1542 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1437 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.1628 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1179 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.1526 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1255 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.1594 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1122 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.1205 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1407 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.1810 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1459 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.1062 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1558 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.1735 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1746 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1446 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1404 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.0906 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1461 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.1073 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1383 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1383 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.1062 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1452 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.2203 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1642 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.2173 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1635 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.2315 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1345 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.1747 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1318 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.1404 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1383 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.0964 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1373 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.1396 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1475 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.2725 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1838 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.1424 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1538 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.1425 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1549 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.0922 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1383 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.1878 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1506 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.1454 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1448 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.1122 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1372 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.1649 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1615 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.1296 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1967 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.0945 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1346 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.1401 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1355 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1320 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1504 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.1437 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1451 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.1239 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1359 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.1226 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1409 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.1636 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1329 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.1546 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1242 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.1969 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1330 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.1448 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1562 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1367 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.1346 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1388 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.1575 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1427 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.1411 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1478 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.0854 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1554 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.0800 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1637 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.1362 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1482 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.1469 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1500 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.1808 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1714 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.1523 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1329 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.1342 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1394 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.1150 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1523 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.2017 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1302 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.2057 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1402 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.1185 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1401 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.0959 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1354 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.1536 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1227 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.1268 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1323 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1386 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1355 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.1599 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1339 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1621 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1454 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1405 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.1560 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1361 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1377 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.2129 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1857 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.1547 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1369 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1392 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.1663 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1605 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.1022 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.2039 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1398 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.1826 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1474 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.1205 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1548 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1833 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1462 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.0852 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1528 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.1338 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1288 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.1333 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1274 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.1823 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1410 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1620 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.1246 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1562 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.1421 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1475 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1409 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.0874 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1495 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.1482 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1249 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.1388 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1627 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.1878 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1379 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1503 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1704 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.1250 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1397 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.1714 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1657 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.1210 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1384 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.1786 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1273 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.1488 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1224 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1268 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1319 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1505 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.1800 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1895 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.1355 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1340 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1528 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.1265 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1414 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.1508 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1388 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1502 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1600 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.1297 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1682 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.2227 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1359 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.2009 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1421 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.2815 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.0678 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1548 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.1090 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1298 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.1321 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1479 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.1906 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1686 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.1751 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1416 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1587 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1990 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1493 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1343 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1256 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1449 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.2718 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.0929 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1238 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.1931 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1378 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.1071 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1667 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1608 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.1363 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1556 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.1608 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1517 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.1740 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1463 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.1533 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1182 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1517 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.1701 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1389 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1365 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.1540 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1576 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.2614 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1535 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.1057 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1545 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.1327 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1445 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.0986 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1256 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1944 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1162 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1234 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1438 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.1712 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1301 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.1980 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1441 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.1845 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1380 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.2732 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1403 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1365 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.1259 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1567 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.2333 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1239 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.1318 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1653 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.1169 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1381 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.1133 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1337 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.1354 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1480 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.1083 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1508 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.1847 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1359 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1493 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1621 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.1080 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1628 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.2010 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1417 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.1741 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1392 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.1243 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1588 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0918 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1397 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.1457 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1434 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1354 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.0845 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1412 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.0869 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1435 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1388 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.1367 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1660 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1368 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1432 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.1459 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1375 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1510 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.1244 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1214 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.1383 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1348 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.1212 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1454 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.1554 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1523 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.1719 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1462 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.0939 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1373 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1589 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.1230 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1241 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.1286 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1422 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.0743 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1401 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.1776 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1448 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.1540 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1355 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.1216 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1501 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.0911 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1350 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1467 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.1006 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1322 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1328 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.1704 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1406 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1289 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1767 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.1616 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1459 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.1487 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1414 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.1375 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1325 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.1529 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1297 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.1949 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1494 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1445 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1395 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1329 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1594 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1481 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.1981 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1644 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.2019 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1505 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1629 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.1372 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1374 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1444 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.2201 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1445 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.0796 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1383 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.1316 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1421 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.1582 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1279 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1524 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.1813 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1335 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1438 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1536 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.1303 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1417 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.1775 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1393 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.1510 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1318 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1692 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1410 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1292 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1638 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1226 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.1561 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1424 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.1604 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1388 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.1420 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1618 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.1671 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1513 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.1836 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1607 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.1076 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1274 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1387 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.1209 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1306 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1325 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.2042 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1273 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1589 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1342 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1277 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.1206 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1389 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.2136 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1272 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.1265 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1381 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.1410 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1425 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.1423 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1508 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.1367 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1912 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1610 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.2318 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1206 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.1528 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1253 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.1534 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1634 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.1776 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1515 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1390 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.1566 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1395 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.0995 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1454 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.0773 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1412 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1692 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1393 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.2379 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1395 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.1767 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1469 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.1119 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1241 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.1105 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1756 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1431 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.1913 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1405 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1478 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1506 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1471 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.1986 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1573 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1298 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.1216 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1432 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.1422 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1244 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.1345 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1320 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.1774 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1557 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.1211 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1378 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.1619 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1272 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.2088 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1455 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.0986 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1594 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.1449 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1330 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1905 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1672 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1293 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.1300 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1466 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.1093 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1509 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.1424 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1610 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1545 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1492 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.1086 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1424 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.1770 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1409 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1372 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.1141 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1398 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.0893 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1484 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.0971 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1640 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.2012 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1401 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1633 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1403 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.1516 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1309 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.0876 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1514 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.2121 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1422 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1392 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.2308 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9057\n",
      "val Loss: 0.2013 Acc: 0.9150\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9150\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.1170 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.1540 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1522 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.0876 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1661 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1516 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1547 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1378 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1298 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.1192 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1382 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1267 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1657 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1482 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.1603 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1246 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1692 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.1981 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1439 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.1496 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1480 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.1565 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1400 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.1495 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1555 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.1512 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1348 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1577 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.2026 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1353 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.1659 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1366 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.1789 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1831 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.2024 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1398 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.1461 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1575 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.1857 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1410 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.1167 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1380 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1482 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.1341 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1514 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.1780 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1334 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.1401 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1652 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.0776 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1499 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1225 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1285 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.1375 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1323 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.1015 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1565 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1360 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1641 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.1504 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1376 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.1351 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1401 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.1422 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1327 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1381 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.1759 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1634 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1653 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1502 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.1400 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1982 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.1383 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1558 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.1725 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1387 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.1327 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.1331 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1324 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.1037 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1319 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.1134 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1320 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.1321 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1153 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.1154 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1256 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.2128 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1359 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.2042 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1271 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.2519 Acc: 0.9016\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9016\n",
      "val Loss: 0.1417 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.0914 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1403 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.1600 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1378 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.1339 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1308 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.1684 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1397 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.1217 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1385 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1684 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1273 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.1481 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1329 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.1192 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1411 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.1817 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1394 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.2276 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1294 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1328 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.1587 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1492 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.2252 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1488 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.1682 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1348 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.2151 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.1086 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1148 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.1467 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1340 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.1353 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1350 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1278 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.1699 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1379 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.1136 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1440 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.1369 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1448 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1394 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.1057 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1504 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1184 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1300 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1152 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1306 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.2064 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1385 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1510 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1559 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.1406 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1376 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1283 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1376 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1384 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.1572 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1712 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.1368 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1408 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.1355 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1403 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.1123 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1583 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.1428 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1614 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1543 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.1487 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1534 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.1802 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1426 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9608 Epoch_Acc: 0.9412\n",
      "\n",
      "Training complete in 21m 4s\n",
      "Best val Acc: 0.960784\n"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet50_lrscheduler_lastlayer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E7)Train WholeNetwork, LR scheduler, 100 epochs, resnet101\n",
    "----------------------------------\n",
    "\n",
    "Resnet101, train the whole network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5421 Acc: 0.6598\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6598\n",
      "val Loss: 0.1619 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.3195 Acc: 0.8607\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8607\n",
      "val Loss: 0.1127 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.2412 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9057\n",
      "val Loss: 0.3002 Acc: 0.8758\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.8758\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.2054 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1306 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.1656 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1881 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.1984 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1370 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.1092 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1963 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1749 Acc: 0.9216\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9216\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.0744 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1795 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1088 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1570 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.0875 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1624 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1308 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1551 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.1431 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1484 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.1917 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1470 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.0952 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1698 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.0973 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1647 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1455 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1361 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1217 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1559 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.1009 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1422 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0989 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1503 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.1336 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1386 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1703 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.0968 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1359 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.0859 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1595 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.1464 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1583 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0758 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1517 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0846 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1376 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0748 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1503 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.1049 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1571 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1259 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1589 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.0951 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1407 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1595 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1134 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1620 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1579 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1370 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.1227 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1362 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1115 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1372 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0894 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1521 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1456 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1518 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0805 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1347 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1431 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1424 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1399 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.1289 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1541 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1511 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1658 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.1856 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1546 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.1069 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1744 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.1274 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1494 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.0885 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1478 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.0918 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1486 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1512 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1565 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1568 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1524 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1110 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1535 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.0676 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1523 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1523 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1395 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1417 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.1217 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1430 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.0817 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1522 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1019 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1522 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1027 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1415 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.1758 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1006 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1435 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1334 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1472 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.0676 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1401 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1041 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1565 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1475 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1402 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1044 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1490 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1473 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.1133 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1588 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1645 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.1234 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1501 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.1382 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1474 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.1384 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1553 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1370 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1492 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.0877 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1413 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1480 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.1178 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1420 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.0716 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1559 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1032 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1498 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.0912 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1528 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.1525 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1436 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1413 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1381 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.0778 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1423 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.0909 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1473 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.1280 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1763 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1128 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1465 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1235 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1498 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0839 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1900 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1519 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1474 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.1258 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1762 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1072 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1448 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.1475 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1391 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.0670 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1379 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.2089 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1322 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.0897 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1494 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1649 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1630 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.0898 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1489 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.0696 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1524 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.0985 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1433 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.1040 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1486 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1363 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1625 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.1404 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1420 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.1007 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1400 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.1666 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1553 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.0755 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1452 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.0763 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1447 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.1132 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1567 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.0929 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1463 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.0997 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1475 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.0947 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1407 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.1604 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1558 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.1094 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1436 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.1041 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1507 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.1032 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1408 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.0938 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1526 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.1021 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1407 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.1854 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1486 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.1983 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1500 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.1057 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1519 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1589 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.1200 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1465 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.1190 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1444 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.0869 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1488 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1450 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.1087 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1607 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.1580 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1588 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.1684 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1323 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.1293 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.1217 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1501 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.0757 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1443 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.0938 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.1236 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1602 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.1037 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1493 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.1071 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1537 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.0911 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1487 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.0676 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1534 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.1001 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1375 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.0818 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.0494 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.1093 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1409 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.0608 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1597 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.1312 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1402 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.0867 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1604 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.1000 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1434 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1505 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.0925 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1520 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1467 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.0669 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1585 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.0918 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1504 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.0882 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1616 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1473 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1924 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1599 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.0802 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1397 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.1721 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.1512 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1453 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.1732 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1390 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1630 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.1239 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1580 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1508 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.0505 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1574 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.0823 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1597 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.0659 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1473 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.1154 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1485 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.1050 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1365 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1550 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.0941 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1407 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.0694 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1474 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.1579 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.1752 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1726 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.1745 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1464 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.1348 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1497 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.1823 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1441 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1704 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.0922 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1366 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.0986 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1482 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1362 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.1184 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1417 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.1148 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1468 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.1043 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1527 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1385 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.1721 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1515 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1268 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1400 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.1130 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1485 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.0857 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1502 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1331 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1565 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1525 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.0548 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1514 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.0905 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1577 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.1113 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.1745 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1452 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.1286 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1443 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.1292 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1585 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1645 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1559 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.2176 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1445 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.1798 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1426 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.0973 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1597 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.1796 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1375 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.0934 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1509 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.1387 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1594 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.1031 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1630 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.1022 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1700 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.0985 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1554 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.0703 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1513 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.2030 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1542 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.1410 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1520 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.1388 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1612 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1856 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1436 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.1340 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1451 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.1476 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1659 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.1121 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1890 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.1043 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1538 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.1135 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1341 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1065 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1593 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1666 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.0747 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1487 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.0825 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1565 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.0992 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1423 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.0731 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1384 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.1220 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1593 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.0577 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1402 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.1410 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1421 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.1355 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1541 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.0677 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1587 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.1045 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1473 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.1025 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1504 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.1880 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1412 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.1082 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.1063 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1589 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.1129 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1491 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.0440 Acc: 0.9918\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9918\n",
      "val Loss: 0.1464 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.0830 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1596 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1082 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1545 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.2228 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1738 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.1023 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1494 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.0466 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1517 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.1045 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1493 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1443 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.0954 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1590 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.1046 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1432 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.1227 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1559 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.0832 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1562 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.1635 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1649 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.1358 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1596 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.1571 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1567 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.0900 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1617 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.0611 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1557 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1420 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1455 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.0689 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1641 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1373 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.0729 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1593 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.1476 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1508 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1180 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1557 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1406 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.1025 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1561 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.1661 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1455 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.0685 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.1171 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1593 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.0701 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1564 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.1387 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1463 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1614 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.1379 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1509 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.0957 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1365 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.1420 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1520 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.0806 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1452 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.1582 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1632 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1575 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.1476 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1508 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.0953 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1579 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1607 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.1405 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.0963 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1444 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.0855 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1557 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1593 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1545 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.1752 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1555 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.0822 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1471 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.1033 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1636 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1503 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.2259 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1502 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.1869 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1771 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1733 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1515 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1547 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.0890 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1539 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1310 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1514 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.0735 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1437 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.1069 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.1029 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1476 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.1826 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1428 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.0895 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1559 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.1720 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1455 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.0667 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.0683 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1515 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.1244 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1514 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1506 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1443 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1589 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1546 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.1551 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1530 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.1307 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1309 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.0770 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1479 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1245 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.1010 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1505 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.0905 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1594 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.1175 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1451 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.1568 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1433 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.1128 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1643 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.1050 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1530 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.1267 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1349 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1155 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1376 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1520 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1518 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.1279 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1576 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.1816 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1706 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.1235 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1688 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.1264 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1570 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.0779 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.1416 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1470 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.1475 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1561 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.1473 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1484 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.0846 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1548 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.1080 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1451 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.1106 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1463 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.1596 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1488 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.0843 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1487 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.0633 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1590 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.0969 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1448 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.0943 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1474 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.0732 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1734 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.1701 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.0969 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1552 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.0550 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1436 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.1151 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.1517 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1419 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.0854 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1549 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1742 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.1095 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1505 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.1211 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1583 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.1863 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1685 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1573 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.1247 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1446 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1544 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.1152 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1523 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.0910 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1719 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.1289 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1491 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.1197 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1560 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.0955 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1502 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.1195 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1561 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1691 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.1140 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1566 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1561 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.0790 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1512 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.0877 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1469 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.1001 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.0999 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1573 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.0963 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1484 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.1400 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1471 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.0779 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.0861 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1494 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.1302 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1608 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.1799 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1469 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.0863 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1347 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.1279 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1691 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.1016 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1540 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1754 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1511 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1409 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0653 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1437 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.1121 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1530 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.1507 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1565 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.0949 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1557 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.1359 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1521 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.1179 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1500 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.0996 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1504 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.1018 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1401 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.1132 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1376 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.1256 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1576 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1539 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.1105 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1541 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.1506 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1586 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1170 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1563 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1506 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.1465 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1445 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.0790 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1429 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1483 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1485 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1568 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.0866 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1449 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.0931 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1505 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.1312 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1516 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.0761 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1555 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.1029 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1585 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.0640 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1540 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.1670 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1598 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.0855 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1738 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1488 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.0717 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1569 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.1380 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1511 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.1070 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1672 Acc: 0.9281\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9281\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.0805 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1489 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.0927 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1619 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1505 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.0868 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1522 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.0703 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1430 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.0968 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1473 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1400 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.1840 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1404 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.1200 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1439 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1357 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1523 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.0863 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1612 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1449 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.1148 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1503 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.0705 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1566 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.1337 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1403 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.0929 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1572 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.0735 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1655 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1163 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1527 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.1135 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1495 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.1885 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1560 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.1279 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1465 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1779 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.0730 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1543 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.1625 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1551 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.1625 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1441 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.1143 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1777 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.0825 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1724 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.0640 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1423 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.0983 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1447 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.0608 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1452 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1398 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1065 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1464 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.1246 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1464 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.0988 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1420 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.0709 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1566 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.1315 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1616 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1461 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.1311 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1433 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.0775 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1479 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1713 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.1371 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1359 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1352 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1373 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1503 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.1318 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1586 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.1251 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1504 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.1754 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1553 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.1001 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.1193 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1639 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1492 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.1149 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1526 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1609 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.1337 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1536 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1472 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.0938 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1547 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.1281 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1550 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.0828 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1698 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.0998 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1578 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.0839 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1538 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.0577 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1412 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.1093 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1424 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0851 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1522 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.1081 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1501 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.0763 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1541 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.1046 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1558 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.1247 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1521 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1564 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.1544 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1368 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.0809 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1511 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.1109 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1490 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.1271 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1527 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.1244 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1430 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.1276 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1505 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.1414 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1454 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.0823 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1551 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.1397 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1513 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.0622 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1481 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.1534 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1488 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.1049 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1545 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.0925 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1418 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1516 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1392 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1571 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.1437 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1518 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.1587 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1543 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.1620 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1477 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.1158 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1600 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1779 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1495 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.0754 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1604 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.1120 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1565 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.1672 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1561 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.1372 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1377 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1550 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.0603 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1570 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1187 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1534 Acc: 0.9346\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9346\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1395 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.1118 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1524 Acc: 0.9412\n",
      "val Rajat Best_Acc: 0.9542 Epoch_Acc: 0.9412\n",
      "\n",
      "Training complete in 33m 5s\n",
      "Best val Acc: 0.954248\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet101(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet101_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E8)Train lastlayer, LR scheduler, 100 epochs, resnet101\n",
    "----------------------------------\n",
    "\n",
    "Resnet101, train the last layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f85a73fba8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Decay LR by a factor of 0.1 every 7 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m     20\u001b[0m                        num_epochs=500)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_ft' is not defined"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.resnet101(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet101_lrscheduler_lastlayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.5699 Acc: 0.6926\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.6926\n",
      "val Loss: 0.1458 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.3013 Acc: 0.8525\n",
      "train Rajat Best_Acc: 0.9673 Epoch_Acc: 0.8525\n",
      "val Loss: 0.0995 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9673 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.2139 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.0724 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0747 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.0988 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1340 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.1348 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1073 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.2111 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9057\n",
      "val Loss: 0.2013 Acc: 0.9085\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9085\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.2485 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0817 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0830 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1457 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0902 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.1020 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0971 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.1421 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0811 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.1081 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0997 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.0696 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0935 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.1284 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0970 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.0893 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1059 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.0917 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0998 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0859 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.1147 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0918 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.0875 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0886 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.0921 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0849 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.0957 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0893 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.2068 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0867 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.1069 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0862 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1145 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0856 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.0871 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1027 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.0940 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0927 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.0725 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0973 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.0845 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0864 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.0900 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0939 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.0507 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0900 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1556 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0925 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1372 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0942 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.0853 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1074 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.1304 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0919 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0957 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.0891 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0983 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1881 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0862 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0910 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1018 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0972 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.1249 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0936 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1619 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0858 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.0915 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0907 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1194 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0931 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.0920 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0959 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0859 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.1385 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0848 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.1716 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0969 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1609 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0924 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0895 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0941 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.0790 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0958 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.1180 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0893 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0869 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.0892 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1006 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.0658 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0903 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.0653 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0864 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1131 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0913 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0870 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.0939 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0911 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.0534 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1027 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1043 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0917 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1373 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0948 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.1097 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0879 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1167 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1015 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1104 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0824 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1353 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0946 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.0892 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0928 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.0898 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0800 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.0704 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0950 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.1242 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0845 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.1005 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0887 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.0780 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0936 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.0742 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0910 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.1062 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0889 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.0778 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0947 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.0810 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0889 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.0777 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1062 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.0548 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1050 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.0917 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0865 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1458 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0851 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.0377 Acc: 0.9918\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9918\n",
      "val Loss: 0.0913 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.0860 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0860 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0963 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.0745 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0815 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0883 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.0633 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0960 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0891 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.1036 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0945 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.0984 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0872 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.0808 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0929 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.1157 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0916 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1452 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0985 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0919 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.0916 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1029 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.0859 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0873 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.9918\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9918\n",
      "val Loss: 0.0876 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0886 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.0833 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0904 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.1093 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0805 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1810 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0878 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.0860 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1024 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.0923 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0937 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.0860 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0958 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.1314 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0880 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.0885 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0875 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.0894 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0940 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0852 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.0722 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0995 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.1347 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0902 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1085 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0893 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0884 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 113/499\n",
      "----------\n",
      "train Loss: 0.0875 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1231 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 114/499\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0955 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 115/499\n",
      "----------\n",
      "train Loss: 0.0650 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0838 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 116/499\n",
      "----------\n",
      "train Loss: 0.0865 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0824 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 117/499\n",
      "----------\n",
      "train Loss: 0.0711 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0952 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 118/499\n",
      "----------\n",
      "train Loss: 0.1189 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0918 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 119/499\n",
      "----------\n",
      "train Loss: 0.1347 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0894 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 120/499\n",
      "----------\n",
      "train Loss: 0.0624 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0921 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 121/499\n",
      "----------\n",
      "train Loss: 0.0761 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0916 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 122/499\n",
      "----------\n",
      "train Loss: 0.1110 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0916 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 123/499\n",
      "----------\n",
      "train Loss: 0.0943 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0931 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 124/499\n",
      "----------\n",
      "train Loss: 0.1449 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0757 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 125/499\n",
      "----------\n",
      "train Loss: 0.0882 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0898 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 126/499\n",
      "----------\n",
      "train Loss: 0.0982 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1058 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 127/499\n",
      "----------\n",
      "train Loss: 0.0648 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0907 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 128/499\n",
      "----------\n",
      "train Loss: 0.1189 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0858 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 129/499\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0990 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 130/499\n",
      "----------\n",
      "train Loss: 0.0871 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0932 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 131/499\n",
      "----------\n",
      "train Loss: 0.1249 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0982 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 132/499\n",
      "----------\n",
      "train Loss: 0.0769 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0953 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 133/499\n",
      "----------\n",
      "train Loss: 0.1142 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1117 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 134/499\n",
      "----------\n",
      "train Loss: 0.1240 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0857 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 135/499\n",
      "----------\n",
      "train Loss: 0.1161 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1073 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 136/499\n",
      "----------\n",
      "train Loss: 0.0918 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0915 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 137/499\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0835 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 138/499\n",
      "----------\n",
      "train Loss: 0.1161 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0857 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 139/499\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0922 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 140/499\n",
      "----------\n",
      "train Loss: 0.1008 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0926 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 141/499\n",
      "----------\n",
      "train Loss: 0.1129 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0906 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 142/499\n",
      "----------\n",
      "train Loss: 0.1443 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0997 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 143/499\n",
      "----------\n",
      "train Loss: 0.1054 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0906 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 144/499\n",
      "----------\n",
      "train Loss: 0.1350 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0866 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 145/499\n",
      "----------\n",
      "train Loss: 0.0854 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0907 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 146/499\n",
      "----------\n",
      "train Loss: 0.1455 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0908 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 147/499\n",
      "----------\n",
      "train Loss: 0.1073 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0929 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 148/499\n",
      "----------\n",
      "train Loss: 0.0516 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1038 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 149/499\n",
      "----------\n",
      "train Loss: 0.0914 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0904 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 150/499\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0957 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 151/499\n",
      "----------\n",
      "train Loss: 0.1955 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0824 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 152/499\n",
      "----------\n",
      "train Loss: 0.0711 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0892 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 153/499\n",
      "----------\n",
      "train Loss: 0.1440 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0873 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 154/499\n",
      "----------\n",
      "train Loss: 0.1082 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0912 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 155/499\n",
      "----------\n",
      "train Loss: 0.0681 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0934 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 156/499\n",
      "----------\n",
      "train Loss: 0.1036 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0929 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 157/499\n",
      "----------\n",
      "train Loss: 0.1141 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0949 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 158/499\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0828 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 159/499\n",
      "----------\n",
      "train Loss: 0.0838 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0897 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 160/499\n",
      "----------\n",
      "train Loss: 0.1246 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0981 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 161/499\n",
      "----------\n",
      "train Loss: 0.0709 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0970 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 162/499\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0935 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 163/499\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0941 Acc: 0.9477\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9477\n",
      "\n",
      "Epoch 164/499\n",
      "----------\n",
      "train Loss: 0.0700 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0896 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 165/499\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0909 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 166/499\n",
      "----------\n",
      "train Loss: 0.0618 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0926 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 167/499\n",
      "----------\n",
      "train Loss: 0.1069 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0859 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 168/499\n",
      "----------\n",
      "train Loss: 0.1283 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0887 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 169/499\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0910 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 170/499\n",
      "----------\n",
      "train Loss: 0.1270 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0885 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 171/499\n",
      "----------\n",
      "train Loss: 0.0741 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0922 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 172/499\n",
      "----------\n",
      "train Loss: 0.1588 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0981 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 173/499\n",
      "----------\n",
      "train Loss: 0.0733 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0920 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 174/499\n",
      "----------\n",
      "train Loss: 0.0393 Acc: 0.9959\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9959\n",
      "val Loss: 0.0987 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 175/499\n",
      "----------\n",
      "train Loss: 0.1474 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1025 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 176/499\n",
      "----------\n",
      "train Loss: 0.0639 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0876 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 177/499\n",
      "----------\n",
      "train Loss: 0.1478 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0944 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 178/499\n",
      "----------\n",
      "train Loss: 0.0604 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0954 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 179/499\n",
      "----------\n",
      "train Loss: 0.0632 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0839 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 180/499\n",
      "----------\n",
      "train Loss: 0.0736 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0965 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 181/499\n",
      "----------\n",
      "train Loss: 0.0825 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0849 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 182/499\n",
      "----------\n",
      "train Loss: 0.0897 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0910 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 183/499\n",
      "----------\n",
      "train Loss: 0.1137 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0960 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 184/499\n",
      "----------\n",
      "train Loss: 0.1121 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0876 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 185/499\n",
      "----------\n",
      "train Loss: 0.0862 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0996 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 186/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1258 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0875 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 187/499\n",
      "----------\n",
      "train Loss: 0.0885 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0942 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 188/499\n",
      "----------\n",
      "train Loss: 0.1064 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0992 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 189/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0897 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 190/499\n",
      "----------\n",
      "train Loss: 0.0904 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0882 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 191/499\n",
      "----------\n",
      "train Loss: 0.0564 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0924 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 192/499\n",
      "----------\n",
      "train Loss: 0.1091 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0866 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 193/499\n",
      "----------\n",
      "train Loss: 0.1269 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0861 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 194/499\n",
      "----------\n",
      "train Loss: 0.0714 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0866 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 195/499\n",
      "----------\n",
      "train Loss: 0.0992 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0869 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 196/499\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1025 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 197/499\n",
      "----------\n",
      "train Loss: 0.0988 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0921 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 198/499\n",
      "----------\n",
      "train Loss: 0.1149 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0846 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 199/499\n",
      "----------\n",
      "train Loss: 0.0608 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0883 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 200/499\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0919 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 201/499\n",
      "----------\n",
      "train Loss: 0.0881 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1003 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 202/499\n",
      "----------\n",
      "train Loss: 0.0666 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0837 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 203/499\n",
      "----------\n",
      "train Loss: 0.0566 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0863 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 204/499\n",
      "----------\n",
      "train Loss: 0.0817 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0829 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 205/499\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0840 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 206/499\n",
      "----------\n",
      "train Loss: 0.0933 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0902 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 207/499\n",
      "----------\n",
      "train Loss: 0.0725 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0851 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 208/499\n",
      "----------\n",
      "train Loss: 0.0612 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0932 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 209/499\n",
      "----------\n",
      "train Loss: 0.1054 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1009 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 210/499\n",
      "----------\n",
      "train Loss: 0.0495 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0907 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 211/499\n",
      "----------\n",
      "train Loss: 0.0874 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0992 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 212/499\n",
      "----------\n",
      "train Loss: 0.1200 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0935 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 213/499\n",
      "----------\n",
      "train Loss: 0.0924 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0878 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 214/499\n",
      "----------\n",
      "train Loss: 0.1399 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0843 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 215/499\n",
      "----------\n",
      "train Loss: 0.1308 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0805 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 216/499\n",
      "----------\n",
      "train Loss: 0.0801 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0918 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 217/499\n",
      "----------\n",
      "train Loss: 0.0823 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0997 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 218/499\n",
      "----------\n",
      "train Loss: 0.1513 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1009 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 219/499\n",
      "----------\n",
      "train Loss: 0.1454 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0822 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 220/499\n",
      "----------\n",
      "train Loss: 0.1151 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0977 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 221/499\n",
      "----------\n",
      "train Loss: 0.0576 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0995 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 222/499\n",
      "----------\n",
      "train Loss: 0.0867 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0867 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 223/499\n",
      "----------\n",
      "train Loss: 0.0761 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0850 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 224/499\n",
      "----------\n",
      "train Loss: 0.0474 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0926 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 225/499\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0938 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 226/499\n",
      "----------\n",
      "train Loss: 0.0534 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0948 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 227/499\n",
      "----------\n",
      "train Loss: 0.1209 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0904 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 228/499\n",
      "----------\n",
      "train Loss: 0.0683 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0905 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 229/499\n",
      "----------\n",
      "train Loss: 0.0911 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0860 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 230/499\n",
      "----------\n",
      "train Loss: 0.0751 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0838 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 231/499\n",
      "----------\n",
      "train Loss: 0.0744 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0842 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 232/499\n",
      "----------\n",
      "train Loss: 0.0902 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0942 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 233/499\n",
      "----------\n",
      "train Loss: 0.0979 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0911 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 234/499\n",
      "----------\n",
      "train Loss: 0.0785 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0832 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 235/499\n",
      "----------\n",
      "train Loss: 0.1168 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0819 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 236/499\n",
      "----------\n",
      "train Loss: 0.0832 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0974 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 237/499\n",
      "----------\n",
      "train Loss: 0.1151 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0890 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 238/499\n",
      "----------\n",
      "train Loss: 0.0830 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0970 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 239/499\n",
      "----------\n",
      "train Loss: 0.0804 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0991 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 240/499\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0992 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 241/499\n",
      "----------\n",
      "train Loss: 0.0978 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1025 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 242/499\n",
      "----------\n",
      "train Loss: 0.0699 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0909 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 243/499\n",
      "----------\n",
      "train Loss: 0.0652 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1067 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 244/499\n",
      "----------\n",
      "train Loss: 0.0635 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0910 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 245/499\n",
      "----------\n",
      "train Loss: 0.0649 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0912 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 246/499\n",
      "----------\n",
      "train Loss: 0.0895 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0890 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 247/499\n",
      "----------\n",
      "train Loss: 0.0922 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0899 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 248/499\n",
      "----------\n",
      "train Loss: 0.1213 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0980 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 249/499\n",
      "----------\n",
      "train Loss: 0.1250 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0821 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 250/499\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0903 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 251/499\n",
      "----------\n",
      "train Loss: 0.0682 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0953 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 252/499\n",
      "----------\n",
      "train Loss: 0.0862 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0941 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 253/499\n",
      "----------\n",
      "train Loss: 0.1431 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0839 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 254/499\n",
      "----------\n",
      "train Loss: 0.1072 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0904 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 255/499\n",
      "----------\n",
      "train Loss: 0.1219 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1126 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 256/499\n",
      "----------\n",
      "train Loss: 0.1194 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0915 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 257/499\n",
      "----------\n",
      "train Loss: 0.1033 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0860 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 258/499\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1020 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 259/499\n",
      "----------\n",
      "train Loss: 0.1005 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0937 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 260/499\n",
      "----------\n",
      "train Loss: 0.0567 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0911 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 261/499\n",
      "----------\n",
      "train Loss: 0.0765 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0987 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 262/499\n",
      "----------\n",
      "train Loss: 0.0619 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0870 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 263/499\n",
      "----------\n",
      "train Loss: 0.1196 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0866 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 264/499\n",
      "----------\n",
      "train Loss: 0.0964 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0895 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 265/499\n",
      "----------\n",
      "train Loss: 0.0726 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0784 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 266/499\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0878 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 267/499\n",
      "----------\n",
      "train Loss: 0.0840 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0927 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 268/499\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0878 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 269/499\n",
      "----------\n",
      "train Loss: 0.1128 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0988 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 270/499\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0887 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 271/499\n",
      "----------\n",
      "train Loss: 0.0693 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0926 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 272/499\n",
      "----------\n",
      "train Loss: 0.1058 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0866 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 273/499\n",
      "----------\n",
      "train Loss: 0.0640 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0918 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 274/499\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0849 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 275/499\n",
      "----------\n",
      "train Loss: 0.0807 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0859 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 276/499\n",
      "----------\n",
      "train Loss: 0.0653 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0886 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 277/499\n",
      "----------\n",
      "train Loss: 0.1108 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0949 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 278/499\n",
      "----------\n",
      "train Loss: 0.0982 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0779 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 279/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1710 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0876 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 280/499\n",
      "----------\n",
      "train Loss: 0.0934 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0951 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 281/499\n",
      "----------\n",
      "train Loss: 0.0718 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.1072 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 282/499\n",
      "----------\n",
      "train Loss: 0.0705 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0905 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 283/499\n",
      "----------\n",
      "train Loss: 0.0745 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0996 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 284/499\n",
      "----------\n",
      "train Loss: 0.0882 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0877 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 285/499\n",
      "----------\n",
      "train Loss: 0.0920 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1012 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 286/499\n",
      "----------\n",
      "train Loss: 0.1529 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0903 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 287/499\n",
      "----------\n",
      "train Loss: 0.0852 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0906 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 288/499\n",
      "----------\n",
      "train Loss: 0.1084 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0899 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 289/499\n",
      "----------\n",
      "train Loss: 0.1360 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0942 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 290/499\n",
      "----------\n",
      "train Loss: 0.0716 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0850 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 291/499\n",
      "----------\n",
      "train Loss: 0.0944 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0916 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 292/499\n",
      "----------\n",
      "train Loss: 0.0521 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0939 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 293/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0854 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 294/499\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1034 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 295/499\n",
      "----------\n",
      "train Loss: 0.0774 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0955 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 296/499\n",
      "----------\n",
      "train Loss: 0.0955 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0950 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 297/499\n",
      "----------\n",
      "train Loss: 0.0935 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0933 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 298/499\n",
      "----------\n",
      "train Loss: 0.0854 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0989 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 299/499\n",
      "----------\n",
      "train Loss: 0.0862 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0906 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 300/499\n",
      "----------\n",
      "train Loss: 0.1511 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0956 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 301/499\n",
      "----------\n",
      "train Loss: 0.0946 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0974 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 302/499\n",
      "----------\n",
      "train Loss: 0.0612 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0869 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 303/499\n",
      "----------\n",
      "train Loss: 0.1071 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0893 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 304/499\n",
      "----------\n",
      "train Loss: 0.0649 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0885 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 305/499\n",
      "----------\n",
      "train Loss: 0.0528 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0836 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 306/499\n",
      "----------\n",
      "train Loss: 0.0883 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0864 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 307/499\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0918 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 308/499\n",
      "----------\n",
      "train Loss: 0.1123 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0856 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 309/499\n",
      "----------\n",
      "train Loss: 0.0704 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0934 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 310/499\n",
      "----------\n",
      "train Loss: 0.0931 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0898 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 311/499\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1012 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 312/499\n",
      "----------\n",
      "train Loss: 0.1149 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0935 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 313/499\n",
      "----------\n",
      "train Loss: 0.0924 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1013 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 314/499\n",
      "----------\n",
      "train Loss: 0.0873 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0947 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 315/499\n",
      "----------\n",
      "train Loss: 0.1191 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0920 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 316/499\n",
      "----------\n",
      "train Loss: 0.1229 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0896 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 317/499\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0836 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 318/499\n",
      "----------\n",
      "train Loss: 0.0740 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0958 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 319/499\n",
      "----------\n",
      "train Loss: 0.0905 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0875 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 320/499\n",
      "----------\n",
      "train Loss: 0.0616 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0901 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 321/499\n",
      "----------\n",
      "train Loss: 0.1119 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0874 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 322/499\n",
      "----------\n",
      "train Loss: 0.0658 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1131 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 323/499\n",
      "----------\n",
      "train Loss: 0.1399 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0914 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 324/499\n",
      "----------\n",
      "train Loss: 0.0750 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0909 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 325/499\n",
      "----------\n",
      "train Loss: 0.0813 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1055 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 326/499\n",
      "----------\n",
      "train Loss: 0.1332 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0899 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 327/499\n",
      "----------\n",
      "train Loss: 0.0822 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0915 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 328/499\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0915 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 329/499\n",
      "----------\n",
      "train Loss: 0.1033 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0904 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 330/499\n",
      "----------\n",
      "train Loss: 0.1058 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0918 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 331/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1000 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 332/499\n",
      "----------\n",
      "train Loss: 0.0955 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0911 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 333/499\n",
      "----------\n",
      "train Loss: 0.1632 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0999 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 334/499\n",
      "----------\n",
      "train Loss: 0.1457 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1094 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 335/499\n",
      "----------\n",
      "train Loss: 0.0529 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0996 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 336/499\n",
      "----------\n",
      "train Loss: 0.1069 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0966 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 337/499\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1053 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 338/499\n",
      "----------\n",
      "train Loss: 0.2070 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0955 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 339/499\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0942 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 340/499\n",
      "----------\n",
      "train Loss: 0.0717 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0996 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 341/499\n",
      "----------\n",
      "train Loss: 0.0938 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0885 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 342/499\n",
      "----------\n",
      "train Loss: 0.0802 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0867 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 343/499\n",
      "----------\n",
      "train Loss: 0.0802 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0916 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 344/499\n",
      "----------\n",
      "train Loss: 0.1076 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0975 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 345/499\n",
      "----------\n",
      "train Loss: 0.0468 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0930 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 346/499\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1023 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 347/499\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0970 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 348/499\n",
      "----------\n",
      "train Loss: 0.0871 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0895 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 349/499\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0878 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 350/499\n",
      "----------\n",
      "train Loss: 0.1709 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0876 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 351/499\n",
      "----------\n",
      "train Loss: 0.1162 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0858 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 352/499\n",
      "----------\n",
      "train Loss: 0.0678 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0896 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 353/499\n",
      "----------\n",
      "train Loss: 0.0608 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0839 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 354/499\n",
      "----------\n",
      "train Loss: 0.0863 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0922 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 355/499\n",
      "----------\n",
      "train Loss: 0.1023 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0965 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 356/499\n",
      "----------\n",
      "train Loss: 0.1174 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0856 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 357/499\n",
      "----------\n",
      "train Loss: 0.0782 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1018 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 358/499\n",
      "----------\n",
      "train Loss: 0.0641 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0896 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 359/499\n",
      "----------\n",
      "train Loss: 0.0761 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0860 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 360/499\n",
      "----------\n",
      "train Loss: 0.0726 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0932 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 361/499\n",
      "----------\n",
      "train Loss: 0.0576 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0938 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 362/499\n",
      "----------\n",
      "train Loss: 0.0544 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1040 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 363/499\n",
      "----------\n",
      "train Loss: 0.1076 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0973 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 364/499\n",
      "----------\n",
      "train Loss: 0.0920 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0920 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 365/499\n",
      "----------\n",
      "train Loss: 0.0917 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0833 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 366/499\n",
      "----------\n",
      "train Loss: 0.1235 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0920 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 367/499\n",
      "----------\n",
      "train Loss: 0.1822 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0914 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 368/499\n",
      "----------\n",
      "train Loss: 0.0894 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0926 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 369/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0888 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 370/499\n",
      "----------\n",
      "train Loss: 0.1303 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0917 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 371/499\n",
      "----------\n",
      "train Loss: 0.0590 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.1029 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 372/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1563 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0955 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 373/499\n",
      "----------\n",
      "train Loss: 0.1031 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0851 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 374/499\n",
      "----------\n",
      "train Loss: 0.0768 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0925 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 375/499\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0898 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 376/499\n",
      "----------\n",
      "train Loss: 0.1033 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0989 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 377/499\n",
      "----------\n",
      "train Loss: 0.0537 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0917 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 378/499\n",
      "----------\n",
      "train Loss: 0.0619 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1109 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 379/499\n",
      "----------\n",
      "train Loss: 0.0532 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0817 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 380/499\n",
      "----------\n",
      "train Loss: 0.0847 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0958 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 381/499\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1152 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 382/499\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0870 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 383/499\n",
      "----------\n",
      "train Loss: 0.0699 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0938 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 384/499\n",
      "----------\n",
      "train Loss: 0.1154 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0944 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 385/499\n",
      "----------\n",
      "train Loss: 0.1103 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0869 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 386/499\n",
      "----------\n",
      "train Loss: 0.1220 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0868 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 387/499\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0970 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 388/499\n",
      "----------\n",
      "train Loss: 0.0878 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0900 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 389/499\n",
      "----------\n",
      "train Loss: 0.0817 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0885 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 390/499\n",
      "----------\n",
      "train Loss: 0.1287 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0830 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 391/499\n",
      "----------\n",
      "train Loss: 0.1064 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0885 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 392/499\n",
      "----------\n",
      "train Loss: 0.0993 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0922 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 393/499\n",
      "----------\n",
      "train Loss: 0.1242 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0935 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 394/499\n",
      "----------\n",
      "train Loss: 0.0743 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0954 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 395/499\n",
      "----------\n",
      "train Loss: 0.0850 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0987 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 396/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0974 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 397/499\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0910 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 398/499\n",
      "----------\n",
      "train Loss: 0.1461 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0946 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 399/499\n",
      "----------\n",
      "train Loss: 0.1110 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0879 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 400/499\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0957 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 401/499\n",
      "----------\n",
      "train Loss: 0.0570 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0905 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 402/499\n",
      "----------\n",
      "train Loss: 0.1505 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0916 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 403/499\n",
      "----------\n",
      "train Loss: 0.1765 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1036 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 404/499\n",
      "----------\n",
      "train Loss: 0.0496 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0860 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 405/499\n",
      "----------\n",
      "train Loss: 0.0866 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0984 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 406/499\n",
      "----------\n",
      "train Loss: 0.0686 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0912 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 407/499\n",
      "----------\n",
      "train Loss: 0.0674 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0900 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 408/499\n",
      "----------\n",
      "train Loss: 0.0744 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0918 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 409/499\n",
      "----------\n",
      "train Loss: 0.0862 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0857 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 410/499\n",
      "----------\n",
      "train Loss: 0.1376 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0962 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 411/499\n",
      "----------\n",
      "train Loss: 0.0861 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0875 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 412/499\n",
      "----------\n",
      "train Loss: 0.1488 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1094 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 413/499\n",
      "----------\n",
      "train Loss: 0.1283 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0900 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 414/499\n",
      "----------\n",
      "train Loss: 0.1088 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1093 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 415/499\n",
      "----------\n",
      "train Loss: 0.0562 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0868 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 416/499\n",
      "----------\n",
      "train Loss: 0.1509 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0987 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 417/499\n",
      "----------\n",
      "train Loss: 0.0948 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0898 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 418/499\n",
      "----------\n",
      "train Loss: 0.1131 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0904 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 419/499\n",
      "----------\n",
      "train Loss: 0.1008 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0981 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 420/499\n",
      "----------\n",
      "train Loss: 0.0733 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.1011 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 421/499\n",
      "----------\n",
      "train Loss: 0.1110 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0947 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 422/499\n",
      "----------\n",
      "train Loss: 0.1000 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0830 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 423/499\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.0835 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 424/499\n",
      "----------\n",
      "train Loss: 0.0853 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1085 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 425/499\n",
      "----------\n",
      "train Loss: 0.1120 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0943 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 426/499\n",
      "----------\n",
      "train Loss: 0.0938 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0895 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 427/499\n",
      "----------\n",
      "train Loss: 0.1265 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0934 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 428/499\n",
      "----------\n",
      "train Loss: 0.1058 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0915 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 429/499\n",
      "----------\n",
      "train Loss: 0.1638 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0835 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 430/499\n",
      "----------\n",
      "train Loss: 0.0856 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0881 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 431/499\n",
      "----------\n",
      "train Loss: 0.0777 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.0999 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 432/499\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0879 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 433/499\n",
      "----------\n",
      "train Loss: 0.1096 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0968 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 434/499\n",
      "----------\n",
      "train Loss: 0.0978 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0920 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 435/499\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0947 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 436/499\n",
      "----------\n",
      "train Loss: 0.1311 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0930 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 437/499\n",
      "----------\n",
      "train Loss: 0.0599 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1033 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 438/499\n",
      "----------\n",
      "train Loss: 0.1815 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0867 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 439/499\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0898 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 440/499\n",
      "----------\n",
      "train Loss: 0.0509 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0987 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 441/499\n",
      "----------\n",
      "train Loss: 0.0910 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0914 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 442/499\n",
      "----------\n",
      "train Loss: 0.0847 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0859 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 443/499\n",
      "----------\n",
      "train Loss: 0.0857 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0968 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 444/499\n",
      "----------\n",
      "train Loss: 0.0943 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0954 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 445/499\n",
      "----------\n",
      "train Loss: 0.1420 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1043 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 446/499\n",
      "----------\n",
      "train Loss: 0.1441 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0864 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 447/499\n",
      "----------\n",
      "train Loss: 0.1027 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0812 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 448/499\n",
      "----------\n",
      "train Loss: 0.1151 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0890 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 449/499\n",
      "----------\n",
      "train Loss: 0.1023 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0915 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 450/499\n",
      "----------\n",
      "train Loss: 0.0627 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0870 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 451/499\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0898 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 452/499\n",
      "----------\n",
      "train Loss: 0.1069 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0889 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 453/499\n",
      "----------\n",
      "train Loss: 0.0740 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1069 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 454/499\n",
      "----------\n",
      "train Loss: 0.0631 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1018 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 455/499\n",
      "----------\n",
      "train Loss: 0.1884 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.0987 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 456/499\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9877\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9877\n",
      "val Loss: 0.0898 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 457/499\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0957 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 458/499\n",
      "----------\n",
      "train Loss: 0.0861 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0975 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 459/499\n",
      "----------\n",
      "train Loss: 0.0764 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1125 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 460/499\n",
      "----------\n",
      "train Loss: 0.1178 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0858 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 461/499\n",
      "----------\n",
      "train Loss: 0.1538 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0895 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 462/499\n",
      "----------\n",
      "train Loss: 0.1056 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0856 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 463/499\n",
      "----------\n",
      "train Loss: 0.1080 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0921 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 464/499\n",
      "----------\n",
      "train Loss: 0.0786 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0906 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 465/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1059 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.0853 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 466/499\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0928 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 467/499\n",
      "----------\n",
      "train Loss: 0.1143 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0908 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 468/499\n",
      "----------\n",
      "train Loss: 0.0843 Acc: 0.9713\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9713\n",
      "val Loss: 0.1015 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 469/499\n",
      "----------\n",
      "train Loss: 0.1039 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0917 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 470/499\n",
      "----------\n",
      "train Loss: 0.1137 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1037 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 471/499\n",
      "----------\n",
      "train Loss: 0.0785 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0845 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 472/499\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1027 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 473/499\n",
      "----------\n",
      "train Loss: 0.1070 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0872 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 474/499\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0996 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 475/499\n",
      "----------\n",
      "train Loss: 0.0612 Acc: 0.9836\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9836\n",
      "val Loss: 0.1052 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 476/499\n",
      "----------\n",
      "train Loss: 0.0767 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0970 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 477/499\n",
      "----------\n",
      "train Loss: 0.0997 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0911 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 478/499\n",
      "----------\n",
      "train Loss: 0.1937 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0912 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 479/499\n",
      "----------\n",
      "train Loss: 0.1338 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0977 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 480/499\n",
      "----------\n",
      "train Loss: 0.1318 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0934 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 481/499\n",
      "----------\n",
      "train Loss: 0.1136 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0959 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 482/499\n",
      "----------\n",
      "train Loss: 0.1430 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0915 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 483/499\n",
      "----------\n",
      "train Loss: 0.1187 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0904 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 484/499\n",
      "----------\n",
      "train Loss: 0.1788 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0957 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 485/499\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0842 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 486/499\n",
      "----------\n",
      "train Loss: 0.1282 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0862 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 487/499\n",
      "----------\n",
      "train Loss: 0.0901 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1051 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 488/499\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0889 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 489/499\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0997 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 490/499\n",
      "----------\n",
      "train Loss: 0.1274 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0936 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 491/499\n",
      "----------\n",
      "train Loss: 0.1095 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0903 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 492/499\n",
      "----------\n",
      "train Loss: 0.0662 Acc: 0.9754\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9754\n",
      "val Loss: 0.0963 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 493/499\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9590\n",
      "val Loss: 0.1002 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 494/499\n",
      "----------\n",
      "train Loss: 0.0898 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0990 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 495/499\n",
      "----------\n",
      "train Loss: 0.0681 Acc: 0.9795\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9795\n",
      "val Loss: 0.0997 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 496/499\n",
      "----------\n",
      "train Loss: 0.1586 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1091 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 497/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0893 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 498/499\n",
      "----------\n",
      "train Loss: 0.0940 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0900 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 499/499\n",
      "----------\n",
      "train Loss: 0.0950 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9672\n",
      "val Loss: 0.0902 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9542\n",
      "\n",
      "Training complete in 59m 38s\n",
      "Best val Acc: 0.973856\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet152_lrscheduler_wholenetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.2284 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bashturtle/anaconda3/envs/gpuenv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1006 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.0000 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.1821 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.0993 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.1701 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9180\n",
      "val Loss: 0.0956 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.1348 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1074 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.1227 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1008 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9549\n",
      "val Loss: 0.0947 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.1893 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1094 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.1788 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1088 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.1452 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0989 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.1664 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0997 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.2126 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.0990 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.2345 Acc: 0.8730\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.8730\n",
      "val Loss: 0.1082 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1045 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.2148 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1017 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.1821 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0957 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.1727 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1118 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.1627 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1111 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.1600 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1128 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.2050 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1002 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.1913 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9098\n",
      "val Loss: 0.1172 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.1720 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0984 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.1422 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1054 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.1865 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1055 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.1643 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1024 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.1483 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1119 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.2289 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9139\n",
      "val Loss: 0.0970 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9739 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.2167 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.0901 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.1860 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0972 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.2167 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.0969 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.1954 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0974 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.2087 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0936 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.1617 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1020 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.1736 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1057 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.1892 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.0954 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.2135 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1003 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.1665 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1049 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.1949 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1095 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.1704 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1006 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.1697 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.1014 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.1665 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1134 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.2266 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.0911 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.1732 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1031 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.1523 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0961 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.2362 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1122 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.1466 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1022 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.1596 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1044 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.1907 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.0998 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 47/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1615 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1077 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.1840 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1066 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.1864 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1068 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.2067 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1245 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.1758 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1079 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.1969 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0945 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.1937 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.1350 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1042 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.1904 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1228 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.1998 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1084 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.2023 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1052 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.1662 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1039 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.1300 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1022 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.1460 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0991 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.2003 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1093 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.1769 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1010 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.1789 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0965 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.2217 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1244 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.1711 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1062 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.1563 Acc: 0.9467\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9467\n",
      "val Loss: 0.0951 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.1715 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.0960 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.1861 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1119 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 69/499\n",
      "----------\n",
      "train Loss: 0.1627 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1138 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 70/499\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9631\n",
      "val Loss: 0.1054 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 71/499\n",
      "----------\n",
      "train Loss: 0.1612 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1018 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 72/499\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9180\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9180\n",
      "val Loss: 0.1003 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 73/499\n",
      "----------\n",
      "train Loss: 0.1577 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0961 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 74/499\n",
      "----------\n",
      "train Loss: 0.2356 Acc: 0.8934\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8934\n",
      "val Loss: 0.1039 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 75/499\n",
      "----------\n",
      "train Loss: 0.2450 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1069 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 76/499\n",
      "----------\n",
      "train Loss: 0.1893 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1109 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 77/499\n",
      "----------\n",
      "train Loss: 0.1663 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1039 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 78/499\n",
      "----------\n",
      "train Loss: 0.2052 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.0977 Acc: 0.9542\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9542\n",
      "\n",
      "Epoch 79/499\n",
      "----------\n",
      "train Loss: 0.1659 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1001 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 80/499\n",
      "----------\n",
      "train Loss: 0.1667 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.1007 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 81/499\n",
      "----------\n",
      "train Loss: 0.1637 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1091 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 82/499\n",
      "----------\n",
      "train Loss: 0.2574 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.0995 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 83/499\n",
      "----------\n",
      "train Loss: 0.1910 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.0874 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 84/499\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9590\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9590\n",
      "val Loss: 0.0962 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 85/499\n",
      "----------\n",
      "train Loss: 0.1938 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0888 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 86/499\n",
      "----------\n",
      "train Loss: 0.2080 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1005 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 87/499\n",
      "----------\n",
      "train Loss: 0.1396 Acc: 0.9549\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9549\n",
      "val Loss: 0.1120 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 88/499\n",
      "----------\n",
      "train Loss: 0.1968 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0974 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 89/499\n",
      "----------\n",
      "train Loss: 0.2552 Acc: 0.8975\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8975\n",
      "val Loss: 0.0983 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 90/499\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9672\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9672\n",
      "val Loss: 0.1042 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 91/499\n",
      "----------\n",
      "train Loss: 0.1813 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0993 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 92/499\n",
      "----------\n",
      "train Loss: 0.1520 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.1072 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 93/499\n",
      "----------\n",
      "train Loss: 0.1836 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0944 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 94/499\n",
      "----------\n",
      "train Loss: 0.2599 Acc: 0.8893\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.8893\n",
      "val Loss: 0.1071 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 95/499\n",
      "----------\n",
      "train Loss: 0.2220 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1047 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 96/499\n",
      "----------\n",
      "train Loss: 0.1802 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.0952 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 97/499\n",
      "----------\n",
      "train Loss: 0.1566 Acc: 0.9385\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9385\n",
      "val Loss: 0.0976 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 98/499\n",
      "----------\n",
      "train Loss: 0.1959 Acc: 0.9221\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9221\n",
      "val Loss: 0.1142 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 99/499\n",
      "----------\n",
      "train Loss: 0.2111 Acc: 0.9098\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9098\n",
      "val Loss: 0.0995 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 100/499\n",
      "----------\n",
      "train Loss: 0.2289 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.1063 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 101/499\n",
      "----------\n",
      "train Loss: 0.1666 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1087 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 102/499\n",
      "----------\n",
      "train Loss: 0.1651 Acc: 0.9426\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9426\n",
      "val Loss: 0.1079 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 103/499\n",
      "----------\n",
      "train Loss: 0.1612 Acc: 0.9344\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9344\n",
      "val Loss: 0.1010 Acc: 0.9673\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9673\n",
      "\n",
      "Epoch 104/499\n",
      "----------\n",
      "train Loss: 0.1386 Acc: 0.9631\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9631\n",
      "val Loss: 0.0978 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 105/499\n",
      "----------\n",
      "train Loss: 0.1910 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0944 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 106/499\n",
      "----------\n",
      "train Loss: 0.1785 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.1015 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 107/499\n",
      "----------\n",
      "train Loss: 0.2172 Acc: 0.9057\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9057\n",
      "val Loss: 0.1161 Acc: 0.9608\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9608\n",
      "\n",
      "Epoch 108/499\n",
      "----------\n",
      "train Loss: 0.1813 Acc: 0.9139\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9139\n",
      "val Loss: 0.0982 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 109/499\n",
      "----------\n",
      "train Loss: 0.1727 Acc: 0.9262\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9262\n",
      "val Loss: 0.1064 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 110/499\n",
      "----------\n",
      "train Loss: 0.1842 Acc: 0.9303\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9303\n",
      "val Loss: 0.0961 Acc: 0.9739\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9739\n",
      "\n",
      "Epoch 111/499\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9508\n",
      "train Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9508\n",
      "val Loss: 0.0971 Acc: 0.9804\n",
      "val Rajat Best_Acc: 0.9804 Epoch_Acc: 0.9804\n",
      "\n",
      "Epoch 112/499\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.resnet152(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "model_ft,train_losses,val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=500)\n",
    "dump_output(model_ft,train_losses[0:50],val_losses[0:50],'resnet152_lrscheduler_lastlayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
